{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1981b-3c94-4e33-b026-c383da881db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Core regime classification components\n",
    "Includes RollingRegimeClassifier, RegimeSmoother, and regime definitions\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from config.settings import (\n",
    "    DEFAULT_WINDOW_HOURS, REGIME_SMOOTHING_PERIODS,\n",
    "    INDICATOR_WEIGHTS, DEFAULT_DIMENSION_THRESHOLDS,\n",
    "    TIMEFRAMES, LOG_LEVEL, LOG_FORMAT\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=getattr(logging, LOG_LEVEL), format=LOG_FORMAT)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# =============================================================================\n",
    "# REGIME TYPE DEFINITIONS - 5 DIMENSIONS\n",
    "# =============================================================================\n",
    "\n",
    "class DirectionRegime:\n",
    "    \"\"\"Direction regime classifications\"\"\"\n",
    "    UP_TRENDING = \"Up_Trending\"\n",
    "    DOWN_TRENDING = \"Down_Trending\"\n",
    "    SIDEWAYS = \"Sideways\"\n",
    "    UNDEFINED = \"Undefined\"\n",
    "\n",
    "class TrendStrengthRegime:\n",
    "    \"\"\"Trend strength regime classifications\"\"\"\n",
    "    STRONG = \"Strong\"\n",
    "    MODERATE = \"Moderate\"\n",
    "    WEAK = \"Weak\"\n",
    "    UNDEFINED = \"Undefined\"\n",
    "\n",
    "class VelocityRegime:\n",
    "    \"\"\"Velocity regime classifications\"\"\"\n",
    "    ACCELERATING = \"Accelerating\"\n",
    "    DECELERATING = \"Decelerating\"\n",
    "    STABLE = \"Stable\"\n",
    "    UNDEFINED = \"Undefined\"\n",
    "\n",
    "class VolatilityRegime:\n",
    "    \"\"\"Volatility regime classifications\"\"\"\n",
    "    LOW_VOL = \"Low_Vol\"\n",
    "    MEDIUM_VOL = \"Medium_Vol\"\n",
    "    HIGH_VOL = \"High_Vol\"\n",
    "    EXTREME_VOL = \"Extreme_Vol\"\n",
    "    UNDEFINED = \"Undefined\"\n",
    "\n",
    "class MicrostructureRegime:\n",
    "    \"\"\"Market microstructure regime classifications\"\"\"\n",
    "    INSTITUTIONAL_FLOW = \"Institutional_Flow\"\n",
    "    RETAIL_FLOW = \"Retail_Flow\"\n",
    "    BALANCED_FLOW = \"Balanced_Flow\"\n",
    "    LOW_PARTICIPATION = \"Low_Participation\"\n",
    "    UNDEFINED = \"Undefined\"\n",
    "\n",
    "# =============================================================================\n",
    "# DATA CLASSES\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class DimensionalVote:\n",
    "    \"\"\"Vote for a specific regime dimension\"\"\"\n",
    "    dimension: str\n",
    "    indicator_name: str\n",
    "    regime_vote: str\n",
    "    confidence: float\n",
    "    value: float\n",
    "    threshold_info: Dict[str, Any] = None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.dimension}Vote({self.indicator_name}: {self.regime_vote} @ {self.confidence:.2f})\"\n",
    "\n",
    "@dataclass\n",
    "class MultiDimensionalClassification:\n",
    "    \"\"\"Complete multi-dimensional regime classification\"\"\"\n",
    "    timestamp: pd.Timestamp\n",
    "    direction_regime: str\n",
    "    direction_confidence: float\n",
    "    trend_strength_regime: str\n",
    "    trend_strength_confidence: float\n",
    "    velocity_regime: str\n",
    "    velocity_confidence: float\n",
    "    volatility_regime: str\n",
    "    volatility_confidence: float\n",
    "    microstructure_regime: str\n",
    "    microstructure_confidence: float\n",
    "    composite_regime: str\n",
    "    composite_confidence: float\n",
    "    all_votes: List[DimensionalVote]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"MultiRegime({self.composite_regime} @ {self.composite_confidence:.2f})\"\n",
    "\n",
    "@dataclass\n",
    "class InstrumentRegimeParameters:\n",
    "    \"\"\"Store instrument-specific regime parameters\"\"\"\n",
    "    symbol: str\n",
    "    direction_thresholds: Dict[str, float]\n",
    "    trend_strength_thresholds: Dict[str, float]\n",
    "    velocity_thresholds: Dict[str, float]\n",
    "    volatility_thresholds: Dict[str, float]\n",
    "    microstructure_thresholds: Dict[str, float]\n",
    "    last_update: pd.Timestamp\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"Convert to dictionary for storage\"\"\"\n",
    "        return {\n",
    "            'symbol': self.symbol,\n",
    "            'direction_thresholds': self.direction_thresholds,\n",
    "            'trend_strength_thresholds': self.trend_strength_thresholds,\n",
    "            'velocity_thresholds': self.velocity_thresholds,\n",
    "            'volatility_thresholds': self.volatility_thresholds,\n",
    "            'microstructure_thresholds': self.microstructure_thresholds,\n",
    "            'last_update': self.last_update.isoformat()\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# REGIME SMOOTHER\n",
    "# =============================================================================\n",
    "\n",
    "class RegimeSmoother:\n",
    "    \"\"\"Smooth regime transitions to prevent whipsaws\"\"\"\n",
    "    \n",
    "    def __init__(self, confirmation_periods: int = REGIME_SMOOTHING_PERIODS):\n",
    "        self.confirmation_periods = confirmation_periods\n",
    "        self.regime_counters = {}\n",
    "        self.current_regimes = {}\n",
    "        \n",
    "    def smooth_regime(self, dimension: str, new_regime: str, \n",
    "                     timestamp: pd.Timestamp) -> Tuple[str, bool]:\n",
    "        \"\"\"\n",
    "        Apply regime smoothing logic\n",
    "        Returns: (regime_to_use, regime_changed)\n",
    "        \"\"\"\n",
    "        if dimension not in self.current_regimes:\n",
    "            # First time seeing this dimension\n",
    "            self.current_regimes[dimension] = new_regime\n",
    "            self.regime_counters[dimension] = 0\n",
    "            return new_regime, True\n",
    "            \n",
    "        current_regime = self.current_regimes[dimension]\n",
    "        \n",
    "        if new_regime == current_regime:\n",
    "            # Same regime, reset counter\n",
    "            self.regime_counters[dimension] = 0\n",
    "            return current_regime, False\n",
    "        else:\n",
    "            # Different regime, increment counter\n",
    "            self.regime_counters[dimension] += 1\n",
    "            \n",
    "            if self.regime_counters[dimension] >= self.confirmation_periods:\n",
    "                # Enough confirmations, switch regime\n",
    "                self.current_regimes[dimension] = new_regime\n",
    "                self.regime_counters[dimension] = 0\n",
    "                return new_regime, True\n",
    "            else:\n",
    "                # Not enough confirmations yet\n",
    "                return current_regime, False\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset all counters and regimes\"\"\"\n",
    "        self.regime_counters = {}\n",
    "        self.current_regimes = {}\n",
    "\n",
    "# =============================================================================\n",
    "# ROLLING REGIME CLASSIFIER\n",
    "# =============================================================================\n",
    "\n",
    "class RollingRegimeClassifier:\n",
    "    \"\"\"\n",
    "    Point-in-time regime classification with rolling windows\n",
    "    Eliminates forward-looking bias\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 window_hours: float = DEFAULT_WINDOW_HOURS,\n",
    "                 timeframe: str = '15min'):\n",
    "        \"\"\"\n",
    "        Initialize rolling classifier\n",
    "        \n",
    "        Args:\n",
    "            window_hours: Rolling window size in hours\n",
    "            timeframe: Data timeframe for bar calculations\n",
    "        \"\"\"\n",
    "        self.window_hours = window_hours\n",
    "        self.timeframe = timeframe\n",
    "        \n",
    "        # Calculate window size in bars\n",
    "        bars_per_day = TIMEFRAMES.get(timeframe, 26)\n",
    "        self.window_bars = int((window_hours / 24) * bars_per_day)\n",
    "        self.min_periods = max(self.window_bars // 2, 50)\n",
    "        \n",
    "        # Initialize components\n",
    "        self.regime_smoother = RegimeSmoother()\n",
    "        self.indicator_weights = INDICATOR_WEIGHTS\n",
    "        self.dimension_thresholds = DEFAULT_DIMENSION_THRESHOLDS.copy()\n",
    "        \n",
    "        # Pre-calculated statistics storage\n",
    "        self.rolling_stats = {}\n",
    "        \n",
    "        logger.info(f\"Initialized RollingRegimeClassifier with {window_hours}h window ({self.window_bars} bars)\")\n",
    "    \n",
    "    def update_window_size(self, new_window_hours: float):\n",
    "        \"\"\"Update the rolling window size\"\"\"\n",
    "        self.window_hours = new_window_hours\n",
    "        bars_per_day = TIMEFRAMES.get(self.timeframe, 26)\n",
    "        self.window_bars = int((new_window_hours / 24) * bars_per_day)\n",
    "        self.min_periods = max(self.window_bars // 2, 50)\n",
    "        logger.info(f\"Updated window size to {new_window_hours}h ({self.window_bars} bars)\")\n",
    "    \n",
    "    def pre_calculate_rolling_statistics(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Pre-calculate all rolling statistics for efficiency\n",
    "        This is the key to avoiding repeated calculations\n",
    "        \"\"\"\n",
    "        logger.info(\"Pre-calculating rolling statistics...\")\n",
    "        \n",
    "        # Direction indicators\n",
    "        if 'SMA_Signal' in data.columns:\n",
    "            self.rolling_stats['SMA_pct_rank'] = data['SMA_Signal'].rolling(\n",
    "                self.window_bars).rank(pct=True)\n",
    "        \n",
    "        if 'EMA_Signal' in data.columns:\n",
    "            self.rolling_stats['EMA_pct_rank'] = data['EMA_Signal'].rolling(\n",
    "                self.window_bars).rank(pct=True)\n",
    "            \n",
    "        if 'MACD_Signal' in data.columns:\n",
    "            self.rolling_stats['MACD_pct_rank'] = data['MACD_Signal'].rolling(\n",
    "                self.window_bars).rank(pct=True)\n",
    "        \n",
    "        # Trend strength indicators\n",
    "        if 'ADX' in data.columns:\n",
    "            self.rolling_stats['ADX_pct_rank'] = data['ADX'].rolling(\n",
    "                self.window_bars).rank(pct=True)\n",
    "        \n",
    "        # Velocity indicators\n",
    "        if 'ROC' in data.columns:\n",
    "            self.rolling_stats['ROC_pct_rank'] = data['ROC'].rolling(\n",
    "                self.window_bars).rank(pct=True)\n",
    "            \n",
    "        if 'Acceleration' in data.columns:\n",
    "            self.rolling_stats['Acceleration_pct_rank'] = data['Acceleration'].rolling(\n",
    "                self.window_bars).rank(pct=True)\n",
    "        \n",
    "        # Volatility indicators - using actual percentiles\n",
    "        if 'ATR' in data.columns:\n",
    "            self.rolling_stats['ATR_percentile'] = data['ATR'].rolling(\n",
    "                self.window_bars).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100)\n",
    "            \n",
    "        if 'Historical_Vol' in data.columns:\n",
    "            self.rolling_stats['Historical_Vol_percentile'] = data['Historical_Vol'].rolling(\n",
    "                self.window_bars).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100)\n",
    "        \n",
    "        # Volume indicators\n",
    "        if 'volume' in data.columns:\n",
    "            self.rolling_stats['volume_ratio'] = data['volume'] / data['volume'].rolling(\n",
    "                self.window_bars).mean()\n",
    "            \n",
    "        logger.info(f\"Pre-calculated {len(self.rolling_stats)} rolling statistics\")\n",
    "    \n",
    "    def classify_direction_dimension(self, data: pd.DataFrame, votes: List[DimensionalVote], \n",
    "                                   index: int) -> Tuple[str, float]:\n",
    "        \"\"\"Classify direction regime for a specific point in time\"\"\"\n",
    "        try:\n",
    "            direction_scores = {\n",
    "                'Up_Trending': 0.0,\n",
    "                'Down_Trending': 0.0,\n",
    "                'Sideways': 0.0\n",
    "            }\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            # Use pre-calculated rolling statistics\n",
    "            if 'SMA_pct_rank' in self.rolling_stats and index < len(self.rolling_stats['SMA_pct_rank']):\n",
    "                pct_rank = self.rolling_stats['SMA_pct_rank'].iloc[index]\n",
    "                if pd.notna(pct_rank):\n",
    "                    weight = self.indicator_weights['direction'].get('SMA', 1.0)\n",
    "                    \n",
    "                    if pct_rank > self.dimension_thresholds['direction']['strong_trend_threshold']:\n",
    "                        direction_scores['Up_Trending'] += weight\n",
    "                        regime_vote = 'Up_Trending'\n",
    "                    elif pct_rank < self.dimension_thresholds['direction']['weak_trend_threshold']:\n",
    "                        direction_scores['Down_Trending'] += weight\n",
    "                        regime_vote = 'Down_Trending'\n",
    "                    else:\n",
    "                        direction_scores['Sideways'] += weight\n",
    "                        regime_vote = 'Sideways'\n",
    "                    \n",
    "                    vote = DimensionalVote(\n",
    "                        dimension='direction',\n",
    "                        indicator_name='SMA',\n",
    "                        regime_vote=regime_vote,\n",
    "                        confidence=weight,\n",
    "                        value=pct_rank\n",
    "                    )\n",
    "                    votes.append(vote)\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Add more indicators as available\n",
    "            if 'MACD_pct_rank' in self.rolling_stats and index < len(self.rolling_stats['MACD_pct_rank']):\n",
    "                pct_rank = self.rolling_stats['MACD_pct_rank'].iloc[index]\n",
    "                if pd.notna(pct_rank):\n",
    "                    weight = self.indicator_weights['direction'].get('MACD', 1.2)\n",
    "                    \n",
    "                    if pct_rank > 0.65:\n",
    "                        direction_scores['Up_Trending'] += weight\n",
    "                        regime_vote = 'Up_Trending'\n",
    "                    elif pct_rank < 0.35:\n",
    "                        direction_scores['Down_Trending'] += weight\n",
    "                        regime_vote = 'Down_Trending'\n",
    "                    else:\n",
    "                        direction_scores['Sideways'] += weight\n",
    "                        regime_vote = 'Sideways'\n",
    "                    \n",
    "                    vote = DimensionalVote(\n",
    "                        dimension='direction',\n",
    "                        indicator_name='MACD',\n",
    "                        regime_vote=regime_vote,\n",
    "                        confidence=weight,\n",
    "                        value=pct_rank\n",
    "                    )\n",
    "                    votes.append(vote)\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Determine regime\n",
    "            if total_weight > 0:\n",
    "                for regime in direction_scores:\n",
    "                    direction_scores[regime] /= total_weight\n",
    "                \n",
    "                best_regime = max(direction_scores, key=direction_scores.get)\n",
    "                confidence = direction_scores[best_regime]\n",
    "                return best_regime, confidence\n",
    "            else:\n",
    "                return DirectionRegime.UNDEFINED, 0.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in direction classification: {e}\")\n",
    "            return DirectionRegime.UNDEFINED, 0.0\n",
    "    \n",
    "    def classify_trend_strength_dimension(self, data: pd.DataFrame, votes: List[DimensionalVote], \n",
    "                                        index: int) -> Tuple[str, float]:\n",
    "        \"\"\"Classify trend strength regime\"\"\"\n",
    "        try:\n",
    "            strength_scores = {\n",
    "                'Strong': 0.0,\n",
    "                'Moderate': 0.0,\n",
    "                'Weak': 0.0\n",
    "            }\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            # ADX-based strength\n",
    "            if 'ADX_pct_rank' in self.rolling_stats and index < len(self.rolling_stats['ADX_pct_rank']):\n",
    "                pct_rank = self.rolling_stats['ADX_pct_rank'].iloc[index]\n",
    "                if pd.notna(pct_rank):\n",
    "                    weight = self.indicator_weights['trend_strength'].get('ADX', 1.2)\n",
    "                    \n",
    "                    if pct_rank > self.dimension_thresholds['trend_strength']['strong_alignment']:\n",
    "                        strength_scores['Strong'] += weight\n",
    "                        regime_vote = 'Strong'\n",
    "                    elif pct_rank > self.dimension_thresholds['trend_strength']['moderate_alignment']:\n",
    "                        strength_scores['Moderate'] += weight\n",
    "                        regime_vote = 'Moderate'\n",
    "                    else:\n",
    "                        strength_scores['Weak'] += weight\n",
    "                        regime_vote = 'Weak'\n",
    "                    \n",
    "                    vote = DimensionalVote(\n",
    "                        dimension='trend_strength',\n",
    "                        indicator_name='ADX',\n",
    "                        regime_vote=regime_vote,\n",
    "                        confidence=weight,\n",
    "                        value=pct_rank\n",
    "                    )\n",
    "                    votes.append(vote)\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Determine regime\n",
    "            if total_weight > 0:\n",
    "                for regime in strength_scores:\n",
    "                    strength_scores[regime] /= total_weight\n",
    "                \n",
    "                best_regime = max(strength_scores, key=strength_scores.get)\n",
    "                confidence = strength_scores[best_regime]\n",
    "                return best_regime, confidence\n",
    "            else:\n",
    "                return TrendStrengthRegime.UNDEFINED, 0.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in trend strength classification: {e}\")\n",
    "            return TrendStrengthRegime.UNDEFINED, 0.0\n",
    "    \n",
    "    def classify_velocity_dimension(self, data: pd.DataFrame, votes: List[DimensionalVote], \n",
    "                                  index: int) -> Tuple[str, float]:\n",
    "        \"\"\"Classify velocity regime\"\"\"\n",
    "        try:\n",
    "            velocity_scores = {\n",
    "                'Accelerating': 0.0,\n",
    "                'Decelerating': 0.0,\n",
    "                'Stable': 0.0\n",
    "            }\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            # ROC-based velocity\n",
    "            if 'ROC_pct_rank' in self.rolling_stats and index < len(self.rolling_stats['ROC_pct_rank']):\n",
    "                pct_rank = self.rolling_stats['ROC_pct_rank'].iloc[index]\n",
    "                if pd.notna(pct_rank):\n",
    "                    weight = self.indicator_weights['velocity'].get('ROC', 1.0)\n",
    "                    \n",
    "                    if pct_rank > self.dimension_thresholds['velocity']['acceleration_threshold']:\n",
    "                        velocity_scores['Accelerating'] += weight\n",
    "                        regime_vote = 'Accelerating'\n",
    "                    elif pct_rank < self.dimension_thresholds['velocity']['stable_range']:\n",
    "                        velocity_scores['Decelerating'] += weight\n",
    "                        regime_vote = 'Decelerating'\n",
    "                    else:\n",
    "                        velocity_scores['Stable'] += weight\n",
    "                        regime_vote = 'Stable'\n",
    "                    \n",
    "                    vote = DimensionalVote(\n",
    "                        dimension='velocity',\n",
    "                        indicator_name='ROC',\n",
    "                        regime_vote=regime_vote,\n",
    "                        confidence=weight,\n",
    "                        value=pct_rank\n",
    "                    )\n",
    "                    votes.append(vote)\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Determine regime\n",
    "            if total_weight > 0:\n",
    "                for regime in velocity_scores:\n",
    "                    velocity_scores[regime] /= total_weight\n",
    "                \n",
    "                best_regime = max(velocity_scores, key=velocity_scores.get)\n",
    "                confidence = velocity_scores[best_regime]\n",
    "                return best_regime, confidence\n",
    "            else:\n",
    "                return VelocityRegime.UNDEFINED, 0.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in velocity classification: {e}\")\n",
    "            return VelocityRegime.UNDEFINED, 0.0\n",
    "    \n",
    "    def classify_volatility_dimension(self, data: pd.DataFrame, votes: List[DimensionalVote], \n",
    "                                    index: int) -> Tuple[str, float]:\n",
    "        \"\"\"Classify volatility regime\"\"\"\n",
    "        try:\n",
    "            vol_scores = {\n",
    "                'Low_Vol': 0.0,\n",
    "                'Medium_Vol': 0.0,\n",
    "                'High_Vol': 0.0,\n",
    "                'Extreme_Vol': 0.0\n",
    "            }\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            # ATR-based volatility\n",
    "            if 'ATR_percentile' in self.rolling_stats and index < len(self.rolling_stats['ATR_percentile']):\n",
    "                percentile = self.rolling_stats['ATR_percentile'].iloc[index]\n",
    "                if pd.notna(percentile):\n",
    "                    weight = self.indicator_weights['volatility'].get('ATR', 1.0)\n",
    "                    \n",
    "                    if percentile > 90:\n",
    "                        vol_scores['Extreme_Vol'] += weight\n",
    "                        regime_vote = 'Extreme_Vol'\n",
    "                    elif percentile > self.dimension_thresholds['volatility']['high_vol_percentile']:\n",
    "                        vol_scores['High_Vol'] += weight\n",
    "                        regime_vote = 'High_Vol'\n",
    "                    elif percentile < self.dimension_thresholds['volatility']['low_vol_percentile']:\n",
    "                        vol_scores['Low_Vol'] += weight\n",
    "                        regime_vote = 'Low_Vol'\n",
    "                    else:\n",
    "                        vol_scores['Medium_Vol'] += weight\n",
    "                        regime_vote = 'Medium_Vol'\n",
    "                    \n",
    "                    vote = DimensionalVote(\n",
    "                        dimension='volatility',\n",
    "                        indicator_name='ATR',\n",
    "                        regime_vote=regime_vote,\n",
    "                        confidence=weight,\n",
    "                        value=percentile\n",
    "                    )\n",
    "                    votes.append(vote)\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Determine regime\n",
    "            if total_weight > 0:\n",
    "                for regime in vol_scores:\n",
    "                    vol_scores[regime] /= total_weight\n",
    "                \n",
    "                best_regime = max(vol_scores, key=vol_scores.get)\n",
    "                confidence = vol_scores[best_regime]\n",
    "                return best_regime, confidence\n",
    "            else:\n",
    "                return VolatilityRegime.UNDEFINED, 0.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in volatility classification: {e}\")\n",
    "            return VolatilityRegime.UNDEFINED, 0.0\n",
    "    \n",
    "    def classify_microstructure_dimension(self, data: pd.DataFrame, votes: List[DimensionalVote], \n",
    "                                        index: int) -> Tuple[str, float]:\n",
    "        \"\"\"Classify microstructure regime\"\"\"\n",
    "        try:\n",
    "            micro_scores = {\n",
    "                'Institutional_Flow': 0.0,\n",
    "                'Retail_Flow': 0.0,\n",
    "                'Balanced_Flow': 0.0,\n",
    "                'Low_Participation': 0.0\n",
    "            }\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            # Volume-based microstructure\n",
    "            if 'volume_ratio' in self.rolling_stats and index < len(self.rolling_stats['volume_ratio']):\n",
    "                vol_ratio = self.rolling_stats['volume_ratio'].iloc[index]\n",
    "                if pd.notna(vol_ratio):\n",
    "                    weight = self.indicator_weights['microstructure'].get('Volume', 1.0)\n",
    "                    \n",
    "                    if vol_ratio > self.dimension_thresholds['microstructure']['institutional_volume_threshold']:\n",
    "                        micro_scores['Institutional_Flow'] += weight\n",
    "                        regime_vote = 'Institutional_Flow'\n",
    "                    elif vol_ratio < self.dimension_thresholds['microstructure']['retail_volume_threshold']:\n",
    "                        micro_scores['Low_Participation'] += weight\n",
    "                        regime_vote = 'Low_Participation'\n",
    "                    else:\n",
    "                        micro_scores['Balanced_Flow'] += weight\n",
    "                        regime_vote = 'Balanced_Flow'\n",
    "                    \n",
    "                    vote = DimensionalVote(\n",
    "                        dimension='microstructure',\n",
    "                        indicator_name='Volume',\n",
    "                        regime_vote=regime_vote,\n",
    "                        confidence=weight,\n",
    "                        value=vol_ratio\n",
    "                    )\n",
    "                    votes.append(vote)\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Determine regime\n",
    "            if total_weight > 0:\n",
    "                for regime in micro_scores:\n",
    "                    micro_scores[regime] /= total_weight\n",
    "                \n",
    "                best_regime = max(micro_scores, key=micro_scores.get)\n",
    "                confidence = micro_scores[best_regime]\n",
    "                return best_regime, confidence\n",
    "            else:\n",
    "                return MicrostructureRegime.UNDEFINED, 0.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in microstructure classification: {e}\")\n",
    "            return MicrostructureRegime.UNDEFINED, 0.0\n",
    "    \n",
    "    def classify_regimes(self, data: pd.DataFrame, \n",
    "                        show_progress: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Main method to classify all regimes\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame with calculated indicators\n",
    "            show_progress: Whether to show progress bar\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with regime classifications\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting regime classification...\")\n",
    "        \n",
    "        # Pre-calculate all rolling statistics\n",
    "        self.pre_calculate_rolling_statistics(data)\n",
    "        \n",
    "        # Reset smoother\n",
    "        self.regime_smoother.reset()\n",
    "        \n",
    "        # Initialize results\n",
    "        results = pd.DataFrame(index=data.index)\n",
    "        \n",
    "        # Initialize columns\n",
    "        for dim in ['Direction', 'TrendStrength', 'Velocity', 'Volatility', 'Microstructure']:\n",
    "            results[f'{dim}_Regime'] = 'Undefined'\n",
    "            results[f'{dim}_Confidence'] = 0.0\n",
    "        results['Composite_Regime'] = 'Undefined'\n",
    "        results['Composite_Confidence'] = 0.0\n",
    "        \n",
    "        # Progress bar setup\n",
    "        iterator = range(len(data))\n",
    "        if show_progress:\n",
    "            iterator = tqdm(iterator, desc=\"Classifying regimes\")\n",
    "        \n",
    "        # Process each time period\n",
    "        for i in iterator:\n",
    "            if i < self.min_periods:\n",
    "                continue\n",
    "            \n",
    "            votes = []\n",
    "            \n",
    "            # Classify each dimension\n",
    "            direction_regime, direction_conf = self.classify_direction_dimension(data, votes, i)\n",
    "            trend_strength_regime, trend_strength_conf = self.classify_trend_strength_dimension(data, votes, i)\n",
    "            velocity_regime, velocity_conf = self.classify_velocity_dimension(data, votes, i)\n",
    "            volatility_regime, volatility_conf = self.classify_volatility_dimension(data, votes, i)\n",
    "            microstructure_regime, microstructure_conf = self.classify_microstructure_dimension(data, votes, i)\n",
    "            \n",
    "            # Apply smoothing\n",
    "            smoothed_direction, _ = self.regime_smoother.smooth_regime('direction', direction_regime, data.index[i])\n",
    "            smoothed_trend_strength, _ = self.regime_smoother.smooth_regime('trend_strength', trend_strength_regime, data.index[i])\n",
    "            smoothed_velocity, _ = self.regime_smoother.smooth_regime('velocity', velocity_regime, data.index[i])\n",
    "            smoothed_volatility, _ = self.regime_smoother.smooth_regime('volatility', volatility_regime, data.index[i])\n",
    "            smoothed_microstructure, _ = self.regime_smoother.smooth_regime('microstructure', microstructure_regime, data.index[i])\n",
    "            \n",
    "            # Store results\n",
    "            results.loc[data.index[i], 'Direction_Regime'] = smoothed_direction\n",
    "            results.loc[data.index[i], 'Direction_Confidence'] = direction_conf\n",
    "            results.loc[data.index[i], 'TrendStrength_Regime'] = smoothed_trend_strength\n",
    "            results.loc[data.index[i], 'TrendStrength_Confidence'] = trend_strength_conf\n",
    "            results.loc[data.index[i], 'Velocity_Regime'] = smoothed_velocity\n",
    "            results.loc[data.index[i], 'Velocity_Confidence'] = velocity_conf\n",
    "            results.loc[data.index[i], 'Volatility_Regime'] = smoothed_volatility\n",
    "            results.loc[data.index[i], 'Volatility_Confidence'] = volatility_conf\n",
    "            results.loc[data.index[i], 'Microstructure_Regime'] = smoothed_microstructure\n",
    "            results.loc[data.index[i], 'Microstructure_Confidence'] = microstructure_conf\n",
    "            \n",
    "            # Create composite regime\n",
    "            composite = f\"{smoothed_direction}_{smoothed_trend_strength}_{smoothed_velocity}_{smoothed_volatility}_{smoothed_microstructure}\"\n",
    "            composite_conf = np.mean([direction_conf, trend_strength_conf, velocity_conf, \n",
    "                                     volatility_conf, microstructure_conf])\n",
    "            \n",
    "            results.loc[data.index[i], 'Composite_Regime'] = composite\n",
    "            results.loc[data.index[i], 'Composite_Confidence'] = composite_conf\n",
    "        \n",
    "        logger.info(f\"Regime classification complete for {len(results)} periods\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_regime_statistics(self, regimes: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate statistics about regime classifications\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        # For each dimension\n",
    "        for dim in ['Direction', 'TrendStrength', 'Velocity', 'Volatility', 'Microstructure']:\n",
    "            col = f'{dim}_Regime'\n",
    "            if col in regimes.columns:\n",
    "                # Value counts\n",
    "                counts = regimes[col].value_counts()\n",
    "                total = len(regimes[regimes[col] != 'Undefined'])\n",
    "                \n",
    "                # Percentages\n",
    "                percentages = (counts / total * 100).round(1) if total > 0 else counts * 0\n",
    "                \n",
    "                # Average confidence\n",
    "                conf_col = f'{dim}_Confidence'\n",
    "                avg_conf = regimes[conf_col].mean() if conf_col in regimes.columns else 0\n",
    "                \n",
    "                stats[dim] = {\n",
    "                    'counts': counts.to_dict(),\n",
    "                    'percentages': percentages.to_dict(),\n",
    "                    'average_confidence': avg_conf,\n",
    "                    'undefined_count': len(regimes[regimes[col] == 'Undefined'])\n",
    "                }\n",
    "        \n",
    "        # Composite regime stats\n",
    "        if 'Composite_Regime' in regimes.columns:\n",
    "            composite_counts = regimes['Composite_Regime'].value_counts()\n",
    "            stats['Composite'] = {\n",
    "                'unique_regimes': len(composite_counts),\n",
    "                'top_10_regimes': composite_counts.head(10).to_dict(),\n",
    "                'average_confidence': regimes['Composite_Confidence'].mean()\n",
    "            }\n",
    "        \n",
    "        return stats"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
