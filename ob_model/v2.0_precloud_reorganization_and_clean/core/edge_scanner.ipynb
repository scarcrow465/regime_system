{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Edge Scanner for Fingerprint Detection\n",
    "Scans for asymmetries (edges) across taxonomy—broad first (low threshold to flag potentials), then conditional (subsets like low-vol for latent edges e.g., RSI2 post-1983).\n",
    "Why: Avoids missing multiples/conditionals—tests all scopes (scalping to position) on historical returns.\n",
    "How it ties to vision: Extracts \"why\" behind OB (e.g., trending edge reliable >5 days), scaling to multi-asset.\n",
    "Use: Run on data, output edge_map dict for classifier.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats  # For t-tests/p-values\n",
    "from utils.logger import get_logger, log_execution_time, log_errors\n",
    "from utils.debug_utils import check_data_sanity, log_var_state\n",
    "from config.edge_taxonomy import PRIMARY_CATEGORIES, SUB_CLASSIFIERS, THRESHOLDS\n",
    "import logging  # For logging.WARNING\n",
    "from config.settings import VERBOSE\n",
    "\n",
    "logger = get_logger('edge_scanner')  # Define logger first\n",
    "\n",
    "if not VERBOSE:\n",
    "    logger.setLevel(logging.WARNING)  # Suppress INFO if not VERBOSE\n",
    "\n",
    "logger = get_logger('edge_scanner')\n",
    "\n",
    "@log_execution_time(logger)\n",
    "@log_errors(logger)\n",
    "def scan_for_edges(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Main scan function—broad tests for each primary category, conditional subsets.\n",
    "    - Input: df with 'returns' column (from data_loader.py).\n",
    "    - Output: edge_map = {'behavioral': {'score': 0.45, 'details': ...}, ...}—multiples OK.\n",
    "    - Why visual: Dict structure easy for heatmaps (rows=primary, columns=scopes).\n",
    "    \"\"\"\n",
    "    df = check_data_sanity(df, logger, 'edge_scanner')  # Debug check\n",
    "    edge_map = {}\n",
    "    \n",
    "    for category, desc in PRIMARY_CATEGORIES.items():\n",
    "        logger.info(f\"Scanning {category}: {desc}\")\n",
    "        \n",
    "        # Broad test: Basic stat on returns (e.g., mean >0 for directional)\n",
    "        broad_score, broad_p = basic_asymmetry_test(df['returns'], category)\n",
    "        log_var_state('broad_results', {'score': broad_score, 'p': broad_p}, logger)\n",
    "        \n",
    "        # Always create entry, even if broad low—conditionals might unlock\n",
    "        edge_map[category] = {'broad_score': broad_score, 'broad_p': broad_p}\n",
    "        \n",
    "        # Conditional: Subset tests (e.g., low-vol)\n",
    "        conditional_score = conditional_subset_test(df, category)\n",
    "        edge_map[category]['conditional_score'] = conditional_score  # Add always—0 if no boost\n",
    "        \n",
    "        # Test scopes: Simulate holds per your definitions\n",
    "        scope_results = test_scopes(df, category)\n",
    "        edge_map[category]['scopes'] = scope_results\n",
    "        \n",
    "        # Check if all low—warning but continue (avoids missing latents)\n",
    "        if broad_score <= THRESHOLDS['min_edge_score'] and conditional_score <= THRESHOLDS['min_edge_score']:\n",
    "            logger.warning(f\"{category} low globally/conditionally—check if latent in other filters\")\n",
    "    \n",
    "    logger.info(f\"Scan complete: {len(edge_map)} potential edges found\")\n",
    "    return edge_map\n",
    "\n",
    "def basic_asymmetry_test(returns: pd.Series, category: str) -> tuple:\n",
    "    \"\"\"Basic test per category—e.g., positive mean for directional.\"\"\"\n",
    "    if category == 'directional':\n",
    "        mean_ret = returns.mean()\n",
    "        t_stat, p_val = stats.ttest_1samp(returns, 0)  # Test >0\n",
    "        score = mean_ret if p_val < 0.05 else 0\n",
    "    elif category == 'behavioral':\n",
    "        # Autocorr for trend (positive) vs reversion (negative)\n",
    "        autocorr = returns.autocorr(lag=1)\n",
    "        score = abs(autocorr) if abs(autocorr) > 0.1 else 0\n",
    "        p_val = 0.05  # Placeholder—use proper test\n",
    "    # Add for other categories (e.g., temporal: groupby day, test diffs)\n",
    "    else:\n",
    "        score, p_val = 0, 1  # Placeholder—expand per category\n",
    "    \n",
    "    return score, p_val\n",
    "\n",
    "def conditional_subset_test(df: pd.DataFrame, category: str) -> float:\n",
    "    \"\"\"Subset tests for latent edges—e.g., reversion in high-vol.\"\"\"\n",
    "    low_vol_df = df[df['vol'] < df['vol'].quantile(0.3)]\n",
    "    cond_score, _ = basic_asymmetry_test(low_vol_df['returns'], category)\n",
    "    return cond_score\n",
    "\n",
    "def test_scopes(df: pd.DataFrame, category: str) -> dict:\n",
    "    \"\"\"Test holds per your scopes—simulate returns for each range.\"\"\"\n",
    "    scope_results = {}\n",
    "    for scope, desc in SUB_CLASSIFIERS['scopes'].items():\n",
    "        if '1 day' in desc:\n",
    "            hold_ret = df['returns'].shift(-1)\n",
    "            score, _ = basic_asymmetry_test(hold_ret.dropna(), category)\n",
    "            scope_results[scope] = score\n",
    "        # Expand for other scopes (e.g., scalping: Intraday holds—need LTF data)\n",
    "    return scope_results\n",
    "\n",
    "# Example Test (run this in console to see)\n",
    "if __name__ == \"__main__\":\n",
    "    # Fake data for test\n",
    "    fake_df = pd.DataFrame({'returns': np.random.normal(0.001, 0.02, 100), 'vol': np.random.normal(0.01, 0.005, 100)}, index=pd.date_range('2020-01-01', periods=100))\n",
    "    edges = scan_for_edges(fake_df)\n",
    "    print(edges)  # See map in terminal"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
