{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e25d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class MarketProfile:\n",
    "    \"\"\"Stores market behavioral characteristics\"\"\"\n",
    "    instrument: str\n",
    "    timeframe: str\n",
    "    long_edge: float\n",
    "    short_edge: float\n",
    "    directional_bias: str\n",
    "    trend_persistence: float\n",
    "    mean_reversion: float\n",
    "    volatility_expansion: float\n",
    "    primary_behavior: str\n",
    "    optimal_holding_period: int\n",
    "    edge_half_life: int\n",
    "    random_long_sharpe: float\n",
    "    random_short_sharpe: float\n",
    "    sample_size: int\n",
    "    confidence_level: float\n",
    "\n",
    "class MarketCharacterizer:\n",
    "    \"\"\"Characterizes market behavior for trading strategies\"\"\"\n",
    "    \n",
    "    def __init__(self, transaction_cost: float = 0.0001, trend_period: int = 20, \n",
    "                 rsi_period: int = 14, rsi_buy_threshold: float = 30, \n",
    "                 rsi_sell_threshold: float = 70, breakout_period: int = 20, \n",
    "                 holding_period: int = 1):\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.trend_period = trend_period\n",
    "        self.rsi_period = rsi_period\n",
    "        self.rsi_buy_threshold = rsi_buy_threshold\n",
    "        self.rsi_sell_threshold = rsi_sell_threshold\n",
    "        self.breakout_period = breakout_period\n",
    "        self.holding_period = holding_period\n",
    "    \n",
    "    def characterize_market(self, data: pd.DataFrame, \n",
    "                          instrument: str, \n",
    "                          timeframe: str) -> MarketProfile:\n",
    "        \"\"\"Complete market characterization\"\"\"\n",
    "        logger.info(f\"Characterizing {instrument} {timeframe}\")\n",
    "        \n",
    "        long_edge, short_edge, bias = self._test_directional_bias(data)\n",
    "        trend_score = self._test_trend_persistence(data)\n",
    "        mr_score = self._test_mean_reversion(data)\n",
    "        breakout_score = self._test_volatility_expansion(data)\n",
    "        \n",
    "        behaviors = {\n",
    "            'trending': trend_score,\n",
    "            'mean_reverting': mr_score,\n",
    "            'breakout': breakout_score\n",
    "        }\n",
    "        primary_behavior = max(behaviors, key=behaviors.get)\n",
    "        \n",
    "        optimal_period = self._find_optimal_holding_period(data, bias)\n",
    "        edge_half_life = self._test_edge_decay(data, primary_behavior)\n",
    "        random_long, random_short = self._test_random_baseline(data)\n",
    "        confidence = self._calculate_confidence(data, behaviors[primary_behavior])\n",
    "        \n",
    "        return MarketProfile(\n",
    "            instrument=instrument,\n",
    "            timeframe=timeframe,\n",
    "            long_edge=long_edge,\n",
    "            short_edge=short_edge,\n",
    "            directional_bias=bias,\n",
    "            trend_persistence=trend_score,\n",
    "            mean_reversion=mr_score,\n",
    "            volatility_expansion=breakout_score,\n",
    "            primary_behavior=primary_behavior,\n",
    "            optimal_holding_period=optimal_period,\n",
    "            edge_half_life=edge_half_life,\n",
    "            random_long_sharpe=random_long,\n",
    "            random_short_sharpe=random_short,\n",
    "            sample_size=len(data),\n",
    "            confidence_level=confidence\n",
    "        )\n",
    "    \n",
    "    def _test_directional_bias(self, data: pd.DataFrame) -> Tuple[float, float, str]:\n",
    "        \"\"\"Test if market has inherent directional bias\"\"\"\n",
    "        returns = data['close'].pct_change().dropna()\n",
    "        long_sharpe = self._calculate_sharpe(returns)\n",
    "        short_sharpe = self._calculate_sharpe(-returns)\n",
    "        \n",
    "        if long_sharpe > 0.5 and long_sharpe > short_sharpe + 0.3:\n",
    "            bias = 'long'\n",
    "        elif short_sharpe > 0.5 and short_sharpe > long_sharpe + 0.3:\n",
    "            bias = 'short'\n",
    "        else:\n",
    "            bias = 'neutral'\n",
    "        \n",
    "        logger.info(f\"Directional bias: {bias} (Long: {long_sharpe:.3f}, Short: {short_sharpe:.3f})\")\n",
    "        return long_sharpe, short_sharpe, bias\n",
    "    \n",
    "    def _simulate_strategy(self, data, long_entries, short_entries, holding_period):\n",
    "        positions = pd.Series(0, index=data.index)\n",
    "        for entry_date in long_entries:\n",
    "            if entry_date in data.index:\n",
    "                exit_idx = min(data.index.get_loc(entry_date) + holding_period, len(data) - 1)\n",
    "                exit_date = data.index[exit_idx]\n",
    "                positions.loc[entry_date:exit_date] += 1\n",
    "        for entry_date in short_entries:\n",
    "            if entry_date in data.index:\n",
    "                exit_idx = min(data.index.get_loc(entry_date) + holding_period, len(data) - 1)\n",
    "                exit_date = data.index[exit_idx]\n",
    "                positions.loc[entry_date:exit_date] -= 1\n",
    "\n",
    "        returns = positions.shift(1).fillna(0) * data['close'].pct_change()\n",
    "        \n",
    "        # Combine long and short entries and count occurrences\n",
    "        all_entries = list(long_entries) + list(short_entries)\n",
    "        if all_entries:\n",
    "            entries_count = pd.Series(all_entries).value_counts()\n",
    "            entries = entries_count.reindex(data.index, fill_value=0)\n",
    "        else:\n",
    "            entries = pd.Series(0, index=data.index)\n",
    "        \n",
    "        transaction_costs = entries * self.transaction_cost\n",
    "        net_returns = returns - transaction_costs\n",
    "        \n",
    "        return net_returns.mean() / net_returns.std() if net_returns.std() != 0 else 0\n",
    "    \n",
    "    def _test_trend_persistence(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Test trend persistence with configurable SMA period\"\"\"\n",
    "        sma = data['close'].rolling(self.trend_period).mean()\n",
    "        long_entries = data.index[data['close'] > sma]\n",
    "        short_entries = data.index[data['close'] < sma]\n",
    "        \n",
    "        return self._simulate_strategy(data, long_entries, short_entries, self.holding_period)\n",
    "    \n",
    "    def _test_mean_reversion(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Test mean reversion with configurable RSI\"\"\"\n",
    "        delta = data['close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(self.rsi_period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(self.rsi_period).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        long_entries = data.index[rsi < self.rsi_buy_threshold]\n",
    "        short_entries = data.index[rsi > self.rsi_sell_threshold]\n",
    "        \n",
    "        return self._simulate_strategy(data, long_entries, short_entries, self.holding_period)\n",
    "    \n",
    "    def _test_volatility_expansion(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Test volatility breakouts with configurable period\"\"\"\n",
    "        high_n = data['high'].rolling(self.breakout_period).max() if 'high' in data.columns else data['close'].rolling(self.breakout_period).max()\n",
    "        low_n = data['low'].rolling(self.breakout_period).min() if 'low' in data.columns else data['close'].rolling(self.breakout_period).min()\n",
    "        \n",
    "        long_entries = data.index[data['close'] > high_n.shift(1)]\n",
    "        short_entries = data.index[data['close'] < low_n.shift(1)]\n",
    "        \n",
    "        return self._simulate_strategy(data, long_entries, short_entries, self.holding_period)\n",
    "    \n",
    "    def _find_optimal_holding_period(self, data: pd.DataFrame, bias: str) -> int:\n",
    "        \"\"\"Find optimal holding period with focus on short-term\"\"\"\n",
    "        best_sharpe = -999\n",
    "        best_period = 1\n",
    "        test_periods = [1, 2, 3, 5]\n",
    "        \n",
    "        for period in test_periods:\n",
    "            if period > len(data) / 10:\n",
    "                continue\n",
    "                \n",
    "            if bias == 'long' or bias == 'neutral':\n",
    "                signal = data['close'] > data['close'].shift(period)\n",
    "            else:\n",
    "                signal = data['close'] < data['close'].shift(period)\n",
    "            \n",
    "            returns = signal.shift(period) * data['close'].pct_change().rolling(period).sum()\n",
    "            sharpe = self._calculate_sharpe(returns.dropna())\n",
    "            \n",
    "            if sharpe > best_sharpe:\n",
    "                best_sharpe = sharpe\n",
    "                best_period = period\n",
    "        \n",
    "        logger.info(f\"Optimal holding period: {best_period} bars (Sharpe: {best_sharpe:.3f})\")\n",
    "        return best_period\n",
    "    \n",
    "    def _test_edge_decay(self, data: pd.DataFrame, behavior: str) -> int:\n",
    "        \"\"\"Test edge decay over time\"\"\"\n",
    "        chunk_size = max(1000, len(data) // 10)\n",
    "        sharpes = []\n",
    "        \n",
    "        for i in range(min(10, len(data) // chunk_size)):\n",
    "            chunk = data.iloc[i*chunk_size:(i+1)*chunk_size]\n",
    "            if len(chunk) < 100:\n",
    "                continue\n",
    "                \n",
    "            if behavior == 'trending':\n",
    "                sharpe = self._test_trend_persistence(chunk)\n",
    "            elif behavior == 'mean_reverting':\n",
    "                sharpe = self._test_mean_reversion(chunk)\n",
    "            else:\n",
    "                sharpe = self._test_volatility_expansion(chunk)\n",
    "            sharpes.append(sharpe)\n",
    "        \n",
    "        if not sharpes:\n",
    "            return len(data) // 2\n",
    "        \n",
    "        peak_sharpe = max(sharpes)\n",
    "        half_sharpe = peak_sharpe / 2\n",
    "        half_life_chunks = next((i + 1 for i, s in enumerate(sharpes) if s < half_sharpe), len(sharpes))\n",
    "        half_life_bars = half_life_chunks * chunk_size\n",
    "        logger.info(f\"Edge half-life: {half_life_bars} bars\")\n",
    "        return half_life_bars\n",
    "    \n",
    "    def _test_random_baseline(self, data: pd.DataFrame) -> Tuple[float, float]:\n",
    "        \"\"\"Establish random entry baseline\"\"\"\n",
    "        np.random.seed(42)\n",
    "        random_long = np.random.choice([0, 1], size=len(data), p=[0.5, 0.5])\n",
    "        long_returns = random_long * data['close'].pct_change()\n",
    "        long_returns = long_returns - abs(np.diff(random_long, prepend=0)) * self.transaction_cost\n",
    "        random_long_sharpe = self._calculate_sharpe(long_returns)\n",
    "        \n",
    "        random_short = np.random.choice([0, -1], size=len(data), p=[0.5, 0.5])\n",
    "        short_returns = random_short * data['close'].pct_change()\n",
    "        short_returns = short_returns - abs(np.diff(random_short, prepend=0)) * self.transaction_cost\n",
    "        random_short_sharpe = self._calculate_sharpe(short_returns)\n",
    "        \n",
    "        logger.info(f\"Random baseline - Long: {random_long_sharpe:.3f}, Short: {random_short_sharpe:.3f}\")\n",
    "        return random_long_sharpe, random_short_sharpe\n",
    "    \n",
    "    def _calculate_sharpe(self, returns: pd.Series) -> float:\n",
    "        \"\"\"Calculate Sharpe ratio\"\"\"\n",
    "        if len(returns) < 20:\n",
    "            return -999\n",
    "        \n",
    "        clean_returns = returns.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if len(clean_returns) == 0 or clean_returns.std() == 0:\n",
    "            return -999\n",
    "        \n",
    "        periods_per_year = 252  # Daily data\n",
    "        sharpe = clean_returns.mean() / clean_returns.std() * np.sqrt(periods_per_year)\n",
    "        return sharpe\n",
    "    \n",
    "    def _calculate_confidence(self, data: pd.DataFrame, score: float) -> float:\n",
    "        \"\"\"Calculate statistical confidence\"\"\"\n",
    "        sample_factor = min(1.0, len(data) / 10000)\n",
    "        score_factor = min(1.0, abs(score) / 0.5)\n",
    "        return sample_factor * score_factor"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
