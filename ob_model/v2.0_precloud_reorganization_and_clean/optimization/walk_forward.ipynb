{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7facd90-b4e5-4337-b5e0-0bf6bdba40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Walk-forward optimization module\n",
    "Implements walk-forward validation to prevent overfitting\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from config.settings import (\n",
    "    WALK_FORWARD_WINDOWS, WALK_FORWARD_TRAIN_RATIO,\n",
    "    OPTIMIZATION_ITERATIONS, RESULTS_DIR\n",
    ")\n",
    "from core.regime_classifier import RollingRegimeClassifier\n",
    "from core.indicators import calculate_all_indicators\n",
    "from optimization.multi_objective import (\n",
    "    MultiObjectiveRegimeOptimizer, OptimizationResults\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# =============================================================================\n",
    "# WALK-FORWARD OPTIMIZER\n",
    "# =============================================================================\n",
    "\n",
    "class WalkForwardOptimizer:\n",
    "    \"\"\"\n",
    "    Walk-forward optimization to validate regime parameters\n",
    "    Prevents overfitting by testing on out-of-sample data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_windows: int = WALK_FORWARD_WINDOWS,\n",
    "                 train_ratio: float = WALK_FORWARD_TRAIN_RATIO):\n",
    "        \"\"\"\n",
    "        Initialize walk-forward optimizer\n",
    "        \n",
    "        Args:\n",
    "            n_windows: Number of walk-forward windows\n",
    "            train_ratio: Ratio of data for training (rest for testing)\n",
    "        \"\"\"\n",
    "        self.n_windows = n_windows\n",
    "        self.train_ratio = train_ratio\n",
    "        self.window_results = []\n",
    "        \n",
    "        logger.info(f\"Initialized walk-forward optimizer with {n_windows} windows, \"\n",
    "                   f\"{train_ratio:.1%} train ratio\")\n",
    "    \n",
    "    def split_data_windows(self, data: pd.DataFrame) -> List[Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Split data into walk-forward windows\n",
    "        \n",
    "        Returns:\n",
    "            List of (train_data, test_data) tuples\n",
    "        \"\"\"\n",
    "        total_len = len(data)\n",
    "        window_size = total_len // self.n_windows\n",
    "        train_size = int(window_size * self.train_ratio)\n",
    "        test_size = window_size - train_size\n",
    "        \n",
    "        windows = []\n",
    "        \n",
    "        for i in range(self.n_windows):\n",
    "            start_idx = i * test_size\n",
    "            train_end_idx = start_idx + train_size\n",
    "            test_end_idx = min(train_end_idx + test_size, total_len)\n",
    "            \n",
    "            # Skip if not enough data for test\n",
    "            if test_end_idx <= train_end_idx:\n",
    "                break\n",
    "            \n",
    "            train_data = data.iloc[start_idx:train_end_idx]\n",
    "            test_data = data.iloc[train_end_idx:test_end_idx]\n",
    "            \n",
    "            windows.append((train_data, test_data))\n",
    "            \n",
    "            logger.info(f\"Window {i+1}: Train {train_data.index[0]} to {train_data.index[-1]} \"\n",
    "                       f\"({len(train_data)} periods), Test {test_data.index[0]} to {test_data.index[-1]} \"\n",
    "                       f\"({len(test_data)} periods)\")\n",
    "        \n",
    "        return windows\n",
    "    \n",
    "    def run_single_window(self, \n",
    "                         train_data: pd.DataFrame,\n",
    "                         test_data: pd.DataFrame,\n",
    "                         window_hours: float,\n",
    "                         timeframe: str,\n",
    "                         max_iterations: int) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Run optimization on single window\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with train and test results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create classifier for this window\n",
    "            classifier = RollingRegimeClassifier(window_hours=window_hours, timeframe=timeframe)\n",
    "            \n",
    "            # Optimize on training data\n",
    "            optimizer = MultiObjectiveRegimeOptimizer(classifier, train_data)\n",
    "            train_results = optimizer.optimize_regime_thresholds(\n",
    "                method='differential_evolution',\n",
    "                max_iterations=max_iterations\n",
    "            )\n",
    "            \n",
    "            # Apply best parameters to test data\n",
    "            classifier_test = RollingRegimeClassifier(window_hours=window_hours, timeframe=timeframe)\n",
    "            optimizer_test = MultiObjectiveRegimeOptimizer(classifier_test, test_data)\n",
    "            \n",
    "            # Update test classifier with trained parameters\n",
    "            optimizer_test.update_classifier_thresholds(train_results.best_params)\n",
    "            \n",
    "            # Evaluate on test data\n",
    "            test_performance, test_regimes = optimizer_test.evaluate_performance(\n",
    "                np.array(list(train_results.best_params.values()))\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'train_sharpe': train_results.sharpe_ratio,\n",
    "                'test_sharpe': test_performance['sharpe_ratio'],\n",
    "                'train_drawdown': train_results.max_drawdown,\n",
    "                'test_drawdown': test_performance['max_drawdown'],\n",
    "                'train_return': train_results.total_return,\n",
    "                'test_return': test_performance['total_return'],\n",
    "                'train_persistence': train_results.regime_persistence,\n",
    "                'test_persistence': test_performance['regime_persistence'],\n",
    "                'best_params': train_results.best_params,\n",
    "                'overfit_ratio': (train_results.sharpe_ratio - test_performance['sharpe_ratio']) / \n",
    "                                abs(train_results.sharpe_ratio) if train_results.sharpe_ratio != 0 else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in window optimization: {e}\")\n",
    "            return {\n",
    "                'train_sharpe': 0,\n",
    "                'test_sharpe': 0,\n",
    "                'train_drawdown': -1,\n",
    "                'test_drawdown': -1,\n",
    "                'train_return': -1,\n",
    "                'test_return': -1,\n",
    "                'train_persistence': 0,\n",
    "                'test_persistence': 0,\n",
    "                'best_params': {},\n",
    "                'overfit_ratio': 1.0\n",
    "            }\n",
    "    \n",
    "    def run_walk_forward(self,\n",
    "                        data: pd.DataFrame,\n",
    "                        window_hours: float,\n",
    "                        timeframe: str = '15min',\n",
    "                        max_iterations: int = OPTIMIZATION_ITERATIONS) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Run complete walk-forward optimization\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with aggregated results\n",
    "        \"\"\"\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"STARTING WALK-FORWARD OPTIMIZATION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        # Split data into windows\n",
    "        windows = self.split_data_windows(data)\n",
    "        logger.info(f\"Created {len(windows)} walk-forward windows\")\n",
    "        \n",
    "        # Run optimization on each window\n",
    "        self.window_results = []\n",
    "        \n",
    "        for i, (train_data, test_data) in enumerate(windows):\n",
    "            logger.info(f\"\\n--- Window {i+1}/{len(windows)} ---\")\n",
    "            logger.info(f\"Training: {train_data.index[0]} to {train_data.index[-1]} ({len(train_data)} periods)\")\n",
    "            logger.info(f\"Testing: {test_data.index[0]} to {test_data.index[-1]} ({len(test_data)} periods)\")\n",
    "            \n",
    "            window_result = self.run_single_window(\n",
    "                train_data, test_data, window_hours, timeframe, max_iterations\n",
    "            )\n",
    "            \n",
    "            window_result['window_id'] = i + 1\n",
    "            self.window_results.append(window_result)\n",
    "            \n",
    "            # Log results\n",
    "            logger.info(f\"Window {i+1} Results:\")\n",
    "            logger.info(f\"  Train Sharpe: {window_result['train_sharpe']:.4f}\")\n",
    "            logger.info(f\"  Test Sharpe: {window_result['test_sharpe']:.4f}\")\n",
    "            logger.info(f\"  Overfit Ratio: {window_result['overfit_ratio']:.2%}\")\n",
    "        \n",
    "        # Aggregate results\n",
    "        aggregated = self.aggregate_results()\n",
    "        \n",
    "        # Print summary\n",
    "        self.print_summary(aggregated)\n",
    "        \n",
    "        return aggregated\n",
    "    \n",
    "    def aggregate_results(self) -> Dict[str, any]:\n",
    "        \"\"\"Aggregate results across all windows\"\"\"\n",
    "        if not self.window_results:\n",
    "            return {}\n",
    "        \n",
    "        # Calculate averages\n",
    "        avg_train_sharpe = np.mean([r['train_sharpe'] for r in self.window_results])\n",
    "        avg_test_sharpe = np.mean([r['test_sharpe'] for r in self.window_results])\n",
    "        avg_train_drawdown = np.mean([r['train_drawdown'] for r in self.window_results])\n",
    "        avg_test_drawdown = np.mean([r['test_drawdown'] for r in self.window_results])\n",
    "        avg_train_return = np.mean([r['train_return'] for r in self.window_results])\n",
    "        avg_test_return = np.mean([r['test_return'] for r in self.window_results])\n",
    "        avg_overfit_ratio = np.mean([r['overfit_ratio'] for r in self.window_results])\n",
    "        \n",
    "        # Find most consistent parameters (appear most frequently)\n",
    "        all_params = {}\n",
    "        for result in self.window_results:\n",
    "            for param, value in result['best_params'].items():\n",
    "                if param not in all_params:\n",
    "                    all_params[param] = []\n",
    "                all_params[param].append(value)\n",
    "        \n",
    "        # Use median of each parameter\n",
    "        median_params = {param: np.median(values) for param, values in all_params.items()}\n",
    "        \n",
    "        return {\n",
    "            'n_windows': len(self.window_results),\n",
    "            'avg_train_sharpe': avg_train_sharpe,\n",
    "            'avg_test_sharpe': avg_test_sharpe,\n",
    "            'avg_train_drawdown': avg_train_drawdown,\n",
    "            'avg_test_drawdown': avg_test_drawdown,\n",
    "            'avg_train_return': avg_train_return,\n",
    "            'avg_test_return': avg_test_return,\n",
    "            'avg_overfit_ratio': avg_overfit_ratio,\n",
    "            'sharpe_degradation': (avg_train_sharpe - avg_test_sharpe) / abs(avg_train_sharpe) if avg_train_sharpe != 0 else 0,\n",
    "            'median_params': median_params,\n",
    "            'window_results': self.window_results,\n",
    "            'is_overfit': avg_overfit_ratio > 0.3,  # Flag if >30% degradation\n",
    "            'best_score': avg_test_sharpe,  # Use test sharpe as score\n",
    "            'sharpe_ratio': avg_test_sharpe,\n",
    "            'max_drawdown': avg_test_drawdown,\n",
    "            'total_return': avg_test_return,\n",
    "            'regime_persistence': np.mean([r['test_persistence'] for r in self.window_results]),\n",
    "            'best_params': median_params  # For compatibility\n",
    "        }\n",
    "    \n",
    "    def print_summary(self, results: Dict[str, any]):\n",
    "        \"\"\"Print walk-forward summary\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"WALK-FORWARD OPTIMIZATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nWindows analyzed: {results['n_windows']}\")\n",
    "        \n",
    "        print(\"\\nAverage Performance:\")\n",
    "        print(f\"  Train Sharpe: {results['avg_train_sharpe']:.4f}\")\n",
    "        print(f\"  Test Sharpe: {results['avg_test_sharpe']:.4f}\")\n",
    "        print(f\"  Sharpe Degradation: {results['sharpe_degradation']:.1%}\")\n",
    "        \n",
    "        print(f\"\\n  Train Drawdown: {results['avg_train_drawdown']:.2%}\")\n",
    "        print(f\"  Test Drawdown: {results['avg_test_drawdown']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n  Train Return: {results['avg_train_return']:.2%}\")\n",
    "        print(f\"  Test Return: {results['avg_test_return']:.2%}\")\n",
    "        \n",
    "        print(f\"\\nOverfitting Analysis:\")\n",
    "        print(f\"  Average Overfit Ratio: {results['avg_overfit_ratio']:.1%}\")\n",
    "        print(f\"  Is Overfit: {'YES' if results['is_overfit'] else 'NO'}\")\n",
    "        \n",
    "        print(\"\\nMedian Optimized Parameters:\")\n",
    "        for param, value in results['median_params'].items():\n",
    "            print(f\"  {param}: {value:.4f}\")\n",
    "        \n",
    "        print(\"\\nIndividual Window Results:\")\n",
    "        for window in results['window_results']:\n",
    "            print(f\"  Window {window['window_id']}: \"\n",
    "                  f\"Train Sharpe={window['train_sharpe']:.3f}, \"\n",
    "                  f\"Test Sharpe={window['test_sharpe']:.3f}, \"\n",
    "                  f\"Overfit={window['overfit_ratio']:.1%}\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    def save_results(self, results: Dict[str, any], filename: Optional[str] = None):\n",
    "        \"\"\"Save walk-forward results\"\"\"\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"walk_forward_results_{timestamp}.csv\"\n",
    "        \n",
    "        filepath = os.path.join(RESULTS_DIR, filename)\n",
    "        \n",
    "        # Convert window results to DataFrame\n",
    "        window_df = pd.DataFrame(results['window_results'])\n",
    "        window_df.to_csv(filepath, index=False)\n",
    "        \n",
    "        # Save summary\n",
    "        summary_file = filepath.replace('.csv', '_summary.txt')\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(\"WALK-FORWARD OPTIMIZATION SUMMARY\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "            f.write(f\"Windows: {results['n_windows']}\\n\")\n",
    "            f.write(f\"Avg Train Sharpe: {results['avg_train_sharpe']:.4f}\\n\")\n",
    "            f.write(f\"Avg Test Sharpe: {results['avg_test_sharpe']:.4f}\\n\")\n",
    "            f.write(f\"Sharpe Degradation: {results['sharpe_degradation']:.1%}\\n\")\n",
    "            f.write(f\"Is Overfit: {'YES' if results['is_overfit'] else 'NO'}\\n\")\n",
    "            f.write(\"\\nMedian Parameters:\\n\")\n",
    "            for param, value in results['median_params'].items():\n",
    "                f.write(f\"  {param}: {value:.4f}\\n\")\n",
    "        \n",
    "        logger.info(f\"Walk-forward results saved to: {filepath}\")\n",
    "        logger.info(f\"Summary saved to: {summary_file}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATION UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def validate_no_forward_bias(data: pd.DataFrame, \n",
    "                           regimes: pd.DataFrame,\n",
    "                           window_bars: int) -> bool:\n",
    "    \"\"\"\n",
    "    Validate that regime classifications don't use future data\n",
    "    \n",
    "    Returns:\n",
    "        True if no forward bias detected\n",
    "    \"\"\"\n",
    "    logger.info(\"Validating no forward-looking bias...\")\n",
    "    \n",
    "    # Check that early periods have undefined regimes\n",
    "    undefined_count = (regimes.iloc[:window_bars]['Direction_Regime'] == 'Undefined').sum()\n",
    "    \n",
    "    if undefined_count < window_bars * 0.8:  # Should be mostly undefined\n",
    "        logger.warning(f\"Potential forward bias: Only {undefined_count}/{window_bars} \"\n",
    "                      f\"undefined regimes in initial window\")\n",
    "        return False\n",
    "    \n",
    "    # Check regime stability\n",
    "    for col in regimes.columns:\n",
    "        if 'Regime' in col and col != 'Composite_Regime':\n",
    "            # Check if regimes are too stable (might indicate using full data)\n",
    "            regime_changes = (regimes[col] != regimes[col].shift()).sum()\n",
    "            if regime_changes < len(regimes) * 0.01:  # Less than 1% changes\n",
    "                logger.warning(f\"Potential forward bias in {col}: \"\n",
    "                              f\"Only {regime_changes} regime changes\")\n",
    "                return False\n",
    "    \n",
    "    logger.info(\"No forward-looking bias detected\")\n",
    "    return True\n",
    "\n",
    "def calculate_stability_metrics(window_results: List[Dict]) -> Dict[str, float]:\n",
    "    \"\"\"Calculate stability metrics across walk-forward windows\"\"\"\n",
    "    \n",
    "    # Parameter stability (std dev of each parameter)\n",
    "    param_stability = {}\n",
    "    all_params = {}\n",
    "    \n",
    "    for result in window_results:\n",
    "        for param, value in result['best_params'].items():\n",
    "            if param not in all_params:\n",
    "                all_params[param] = []\n",
    "            all_params[param].append(value)\n",
    "    \n",
    "    for param, values in all_params.items():\n",
    "        param_stability[param] = np.std(values) / np.mean(values) if np.mean(values) != 0 else 0\n",
    "    \n",
    "    # Performance stability\n",
    "    train_sharpes = [r['train_sharpe'] for r in window_results]\n",
    "    test_sharpes = [r['test_sharpe'] for r in window_results]\n",
    "    \n",
    "    return {\n",
    "        'param_stability': param_stability,\n",
    "        'avg_param_stability': np.mean(list(param_stability.values())),\n",
    "        'train_sharpe_std': np.std(train_sharpes),\n",
    "        'test_sharpe_std': np.std(test_sharpes),\n",
    "        'performance_consistency': 1 - (np.std(test_sharpes) / np.mean(test_sharpes)) \n",
    "                                  if np.mean(test_sharpes) != 0 else 0\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
