{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5883bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test script for the reorganized regime system\n",
    "Run this to verify all components work correctly\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import traceback\n",
    "\n",
    "# Add regime_system to path\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "# Track test results\n",
    "test_results = {\n",
    "    'passed': 0,\n",
    "    'failed': 0,\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "def test_function(test_name):\n",
    "    \"\"\"Decorator for test functions\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Testing: {test_name}\")\n",
    "            print('='*60)\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                test_results['passed'] += 1\n",
    "                print(f\"✓ {test_name} PASSED\")\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                test_results['failed'] += 1\n",
    "                test_results['errors'].append({\n",
    "                    'test': test_name,\n",
    "                    'error': str(e),\n",
    "                    'traceback': traceback.format_exc()\n",
    "                })\n",
    "                print(f\"✗ {test_name} FAILED: {e}\")\n",
    "                return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# =============================================================================\n",
    "# TEST DATA GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "def generate_test_data(n_periods=1000):\n",
    "    \"\"\"Generate synthetic test data\"\"\"\n",
    "    # Create date range\n",
    "    dates = pd.date_range(end=datetime.now(), periods=n_periods, freq='15min')\n",
    "    \n",
    "    # Generate synthetic price data\n",
    "    np.random.seed(42)\n",
    "    returns = np.random.normal(0.0001, 0.01, n_periods)\n",
    "    close = 100 * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    # Generate OHLC\n",
    "    high = close * (1 + np.abs(np.random.normal(0, 0.002, n_periods)))\n",
    "    low = close * (1 - np.abs(np.random.normal(0, 0.002, n_periods)))\n",
    "    open_ = np.roll(close, 1)\n",
    "    open_[0] = close[0]\n",
    "    \n",
    "    # Generate volume\n",
    "    volume = np.random.lognormal(10, 0.5, n_periods)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'open': open_,\n",
    "        'high': high,\n",
    "        'low': low,\n",
    "        'close': close,\n",
    "        'volume': volume\n",
    "    }, index=dates)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# =============================================================================\n",
    "# COMPONENT TESTS\n",
    "# =============================================================================\n",
    "\n",
    "@test_function(\"Core Imports\")\n",
    "def test_core_imports():\n",
    "    \"\"\"Test that core modules can be imported\"\"\"\n",
    "    from regime_system.core.data_loader import load_csv_data\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    from regime_system.core.regime_classifier import RollingRegimeClassifier\n",
    "    print(\"All core imports successful\")\n",
    "\n",
    "@test_function(\"Data Loader\")\n",
    "def test_data_loader():\n",
    "    \"\"\"Test data loading functionality\"\"\"\n",
    "    from regime_system.core.data_loader import (\n",
    "        prepare_data_for_analysis, \n",
    "        get_data_info,\n",
    "        check_data_quality\n",
    "    )\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_test_data(1000)\n",
    "    \n",
    "    # Prepare data\n",
    "    prepared_data = prepare_data_for_analysis(data)\n",
    "    assert 'returns' in prepared_data.columns\n",
    "    assert 'log_returns' in prepared_data.columns\n",
    "    \n",
    "    # Get data info\n",
    "    info = get_data_info(prepared_data)\n",
    "    assert info['rows'] == 1000\n",
    "    assert 'timeframe' in info\n",
    "    \n",
    "    # Check quality\n",
    "    quality = check_data_quality(prepared_data)\n",
    "    assert 'quality_score' in quality\n",
    "    \n",
    "    print(f\"Data prepared with {len(prepared_data)} rows\")\n",
    "    print(f\"Data quality score: {quality['quality_score']:.2f}\")\n",
    "\n",
    "@test_function(\"Indicator Calculations\")\n",
    "def test_indicators():\n",
    "    \"\"\"Test indicator calculation\"\"\"\n",
    "    from regime_system.core.indicators import (\n",
    "        calculate_all_indicators,\n",
    "        validate_indicators,\n",
    "        get_indicator_info\n",
    "    )\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_test_data(500)\n",
    "    \n",
    "    # Calculate indicators\n",
    "    data_with_indicators = calculate_all_indicators(data, verbose=False)\n",
    "    \n",
    "    # Validate\n",
    "    validation = validate_indicators(data_with_indicators)\n",
    "    \n",
    "    # Get info\n",
    "    info = get_indicator_info()\n",
    "    \n",
    "    print(f\"Calculated {len(data_with_indicators.columns) - len(data.columns)} indicators\")\n",
    "    print(f\"Valid indicators: {len(validation['valid'])}\")\n",
    "    print(f\"Missing indicators: {len(validation['missing'])}\")\n",
    "    print(f\"Total indicators in system: {info['total_indicators']}\")\n",
    "    \n",
    "    assert len(validation['valid']) > 50  # Should have many valid indicators\n",
    "\n",
    "@test_function(\"Regime Classification\")\n",
    "def test_regime_classification():\n",
    "    \"\"\"Test regime classification\"\"\"\n",
    "    from regime_system.core.regime_classifier import RollingRegimeClassifier\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_test_data(1000)\n",
    "    data_with_indicators = calculate_all_indicators(data)\n",
    "    \n",
    "    # Create classifier\n",
    "    classifier = RollingRegimeClassifier(window_hours=24, timeframe='15min')\n",
    "    \n",
    "    # Classify regimes\n",
    "    regimes = classifier.classify_regimes(data_with_indicators, show_progress=False)\n",
    "    \n",
    "    # Check results\n",
    "    assert 'Direction_Regime' in regimes.columns\n",
    "    assert 'TrendStrength_Regime' in regimes.columns\n",
    "    assert 'Volatility_Regime' in regimes.columns\n",
    "    assert 'Composite_Regime' in regimes.columns\n",
    "    \n",
    "    # Get statistics\n",
    "    stats = classifier.get_regime_statistics(regimes)\n",
    "    \n",
    "    print(f\"Classified {len(regimes)} periods\")\n",
    "    print(f\"Unique composite regimes: {stats['Composite']['unique_regimes']}\")\n",
    "    \n",
    "    # Print distribution for one dimension\n",
    "    if 'Direction' in stats:\n",
    "        print(\"\\nDirection regime distribution:\")\n",
    "        for regime, pct in stats['Direction']['percentages'].items():\n",
    "            print(f\"  {regime}: {pct:.1f}%\")\n",
    "\n",
    "@test_function(\"Optimization\")\n",
    "def test_optimization():\n",
    "    \"\"\"Test optimization functionality\"\"\"\n",
    "    from regime_system.core.regime_classifier import RollingRegimeClassifier\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    from regime_system.optimization.multi_objective import MultiObjectiveRegimeOptimizer\n",
    "    \n",
    "    # Generate test data (smaller for faster test)\n",
    "    data = generate_test_data(500)\n",
    "    data_with_indicators = calculate_all_indicators(data)\n",
    "    \n",
    "    # Create classifier\n",
    "    classifier = RollingRegimeClassifier(window_hours=24, timeframe='15min')\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = MultiObjectiveRegimeOptimizer(classifier, data_with_indicators)\n",
    "    \n",
    "    # Run short optimization\n",
    "    results = optimizer.optimize_regime_thresholds(\n",
    "        method='differential_evolution',\n",
    "        max_iterations=5  # Very short for testing\n",
    "    )\n",
    "    \n",
    "    print(f\"Optimization complete\")\n",
    "    print(f\"Best score: {results.best_score:.4f}\")\n",
    "    print(f\"Sharpe ratio: {results.sharpe_ratio:.4f}\")\n",
    "    print(f\"Max drawdown: {results.max_drawdown:.2%}\")\n",
    "    \n",
    "    assert hasattr(results, 'best_params')\n",
    "    assert hasattr(results, 'optimization_history')\n",
    "\n",
    "@test_function(\"Backtesting\")\n",
    "def test_backtesting():\n",
    "    \"\"\"Test backtesting functionality\"\"\"\n",
    "    from regime_system.core.regime_classifier import RollingRegimeClassifier\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    from regime_system.backtesting.strategies import (\n",
    "        EnhancedRegimeStrategyBacktester,\n",
    "        compare_strategies\n",
    "    )\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_test_data(1000)\n",
    "    data_with_indicators = calculate_all_indicators(data)\n",
    "    \n",
    "    # Create classifier and get regimes\n",
    "    classifier = RollingRegimeClassifier(window_hours=24, timeframe='15min')\n",
    "    regimes = classifier.classify_regimes(data_with_indicators, show_progress=False)\n",
    "    \n",
    "    # Create backtester\n",
    "    backtester = EnhancedRegimeStrategyBacktester()\n",
    "    \n",
    "    # Test adaptive strategy\n",
    "    returns = backtester.adaptive_regime_strategy_enhanced(data_with_indicators, regimes)\n",
    "    metrics = backtester.calculate_performance_metrics(returns)\n",
    "    \n",
    "    print(f\"Backtesting complete\")\n",
    "    print(f\"Total return: {metrics['total_return']:.2%}\")\n",
    "    print(f\"Sharpe ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "    print(f\"Max drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"Win rate: {metrics['win_rate']:.2%}\")\n",
    "    \n",
    "    # Compare strategies\n",
    "    comparison = compare_strategies(data_with_indicators, regimes)\n",
    "    print(f\"\\nStrategy comparison completed for {len(comparison)} strategies\")\n",
    "\n",
    "@test_function(\"Walk-Forward Validation\")\n",
    "def test_walk_forward():\n",
    "    \"\"\"Test walk-forward validation\"\"\"\n",
    "    from regime_system.optimization.walk_forward import WalkForwardOptimizer\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_test_data(1000)\n",
    "    data_with_indicators = calculate_all_indicators(data)\n",
    "    \n",
    "    # Create walk-forward optimizer\n",
    "    wf_optimizer = WalkForwardOptimizer(n_windows=3, train_ratio=0.7)\n",
    "    \n",
    "    # Test data splitting\n",
    "    windows = wf_optimizer.split_data_windows(data_with_indicators)\n",
    "    \n",
    "    print(f\"Created {len(windows)} walk-forward windows\")\n",
    "    for i, (train, test) in enumerate(windows):\n",
    "        print(f\"  Window {i+1}: Train={len(train)}, Test={len(test)}\")\n",
    "    \n",
    "    assert len(windows) == 3\n",
    "\n",
    "@test_function(\"Window Optimization\")\n",
    "def test_window_optimization():\n",
    "    \"\"\"Test window size optimization\"\"\"\n",
    "    from regime_system.optimization.window_optimizer import (\n",
    "        optimize_window_size,\n",
    "        get_recommended_window_range,\n",
    "        calculate_effective_lookback\n",
    "    )\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_test_data(1000)\n",
    "    data_with_indicators = calculate_all_indicators(data)\n",
    "    \n",
    "    # Get recommended range\n",
    "    min_window, max_window = get_recommended_window_range('15min')\n",
    "    print(f\"Recommended window range for 15min: {min_window}-{max_window} hours\")\n",
    "    \n",
    "    # Calculate effective lookback\n",
    "    lookback = calculate_effective_lookback(24, '15min')\n",
    "    print(f\"24-hour window = {lookback['window_bars']} bars\")\n",
    "    \n",
    "    # Note: Full window optimization takes time, so we skip it in quick test\n",
    "    print(\"Window optimization functions verified\")\n",
    "\n",
    "@test_function(\"Checkpointing\")\n",
    "def test_checkpointing():\n",
    "    \"\"\"Test checkpoint functionality\"\"\"\n",
    "    from regime_system.utils.checkpoint import (\n",
    "        OptimizationCheckpoint,\n",
    "        OptimizationStateManager,\n",
    "        CloudCostMonitor\n",
    "    )\n",
    "    \n",
    "    # Test checkpoint manager\n",
    "    checkpoint_mgr = OptimizationCheckpoint()\n",
    "    \n",
    "    # Test state manager\n",
    "    state_mgr = OptimizationStateManager(checkpoint_interval=10)\n",
    "    \n",
    "    # Update state\n",
    "    state_mgr.update_state(\n",
    "        iteration=1,\n",
    "        best_params={'test': 0.5},\n",
    "        best_score=1.0,\n",
    "        history=[{'iteration': 1, 'score': 1.0}]\n",
    "    )\n",
    "    \n",
    "    # Test cost monitor\n",
    "    cost_monitor = CloudCostMonitor(max_cost_usd=50)\n",
    "    should_stop, reason = cost_monitor.should_stop(1, 1.0)\n",
    "    \n",
    "    print(\"Checkpoint system verified\")\n",
    "    print(f\"Cost monitoring active (limit: ${cost_monitor.max_cost_usd})\")\n",
    "\n",
    "@test_function(\"Validation Tools\")\n",
    "def test_validation():\n",
    "    \"\"\"Test validation functionality\"\"\"\n",
    "    from regime_system.core.regime_classifier import RollingRegimeClassifier\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    from regime_system.validation.indicator_analysis import run_indicator_analysis\n",
    "    from regime_system.validation.regime_distribution import validate_regime_distributions\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_test_data(1000)\n",
    "    data_with_indicators = calculate_all_indicators(data)\n",
    "    \n",
    "    # Get regimes\n",
    "    classifier = RollingRegimeClassifier(window_hours=24, timeframe='15min')\n",
    "    regimes = classifier.classify_regimes(data_with_indicators, show_progress=False)\n",
    "    \n",
    "    # Run indicator analysis (without saving)\n",
    "    indicator_results = run_indicator_analysis(\n",
    "        data_with_indicators, regimes, save_report=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {indicator_results['correlation_analysis']['redundant_count']} \"\n",
    "          f\"redundant indicator pairs\")\n",
    "    \n",
    "    # Run regime validation (without saving)\n",
    "    regime_results = validate_regime_distributions(\n",
    "        regimes, data_with_indicators, save_report=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Regime validation: {'PASSED' if regime_results['validation_passed'] else 'FAILED'}\")\n",
    "    print(f\"Issues found: {len(regime_results['issues'])}\")\n",
    "\n",
    "@test_function(\"Logging System\")\n",
    "def test_logging():\n",
    "    \"\"\"Test logging functionality\"\"\"\n",
    "    from regime_system.utils.logger import (\n",
    "        get_logger,\n",
    "        PerformanceLogger,\n",
    "        TradingLogger\n",
    "    )\n",
    "    \n",
    "    # Test basic logger\n",
    "    logger = get_logger('test_module')\n",
    "    logger.info(\"Test log message\")\n",
    "    \n",
    "    # Test performance logger\n",
    "    perf_logger = PerformanceLogger('test_performance')\n",
    "    perf_logger.log_metric('test_metric', 1.5, {'context': 'test'})\n",
    "    \n",
    "    # Test trading logger\n",
    "    trade_logger = TradingLogger('test_trading')\n",
    "    trade_logger.log_trade('BUY', 'NQ', 1, 15000, 'Test trade')\n",
    "    \n",
    "    print(\"Logging system verified\")\n",
    "\n",
    "@test_function(\"Main Entry Points\")\n",
    "def test_main_entry_points():\n",
    "    \"\"\"Test main entry point functions\"\"\"\n",
    "    from regime_system import (\n",
    "        run_regime_analysis,\n",
    "        run_optimization,\n",
    "        run_backtesting\n",
    "    )\n",
    "    \n",
    "    print(\"Main entry points imported successfully\")\n",
    "    print(\"Available functions:\")\n",
    "    print(\"  - run_regime_analysis()\")\n",
    "    print(\"  - run_optimization()\")\n",
    "    print(\"  - run_backtesting()\")\n",
    "\n",
    "# =============================================================================\n",
    "# INTEGRATION TESTS\n",
    "# =============================================================================\n",
    "\n",
    "@test_function(\"End-to-End Workflow\")\n",
    "def test_end_to_end_workflow():\n",
    "    \"\"\"Test complete workflow\"\"\"\n",
    "    from regime_system.core.data_loader import prepare_data_for_analysis\n",
    "    from regime_system.core.indicators import calculate_all_indicators\n",
    "    from regime_system.core.regime_classifier import RollingRegimeClassifier\n",
    "    from regime_system.optimization.multi_objective import MultiObjectiveRegimeOptimizer\n",
    "    from regime_system.backtesting.strategies import EnhancedRegimeStrategyBacktester\n",
    "    \n",
    "    # 1. Generate data\n",
    "    data = generate_test_data(500)\n",
    "    \n",
    "    # 2. Prepare data\n",
    "    data = prepare_data_for_analysis(data)\n",
    "    \n",
    "    # 3. Calculate indicators\n",
    "    data_with_indicators = calculate_all_indicators(data, verbose=False)\n",
    "    \n",
    "    # 4. Classify regimes\n",
    "    classifier = RollingRegimeClassifier(window_hours=24, timeframe='15min')\n",
    "    regimes = classifier.classify_regimes(data_with_indicators, show_progress=False)\n",
    "    \n",
    "    # 5. Optimize (very short)\n",
    "    optimizer = MultiObjectiveRegimeOptimizer(classifier, data_with_indicators)\n",
    "    results = optimizer.optimize_regime_thresholds(max_iterations=2)\n",
    "    \n",
    "    # 6. Backtest\n",
    "    backtester = EnhancedRegimeStrategyBacktester()\n",
    "    returns = backtester.adaptive_regime_strategy_enhanced(data_with_indicators, regimes)\n",
    "    metrics = backtester.calculate_performance_metrics(returns)\n",
    "    \n",
    "    print(\"Complete workflow executed successfully!\")\n",
    "    print(f\"Final Sharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN TEST RUNNER\n",
    "# =============================================================================\n",
    "\n",
    "def run_all_tests():\n",
    "    \"\"\"Run all tests\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"REGIME SYSTEM TEST SUITE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Testing reorganized package structure\")\n",
    "    print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Run tests\n",
    "    test_core_imports()\n",
    "    test_data_loader()\n",
    "    test_indicators()\n",
    "    test_regime_classification()\n",
    "    test_optimization()\n",
    "    test_backtesting()\n",
    "    test_walk_forward()\n",
    "    test_window_optimization()\n",
    "    test_checkpointing()\n",
    "    test_validation()\n",
    "    test_logging()\n",
    "    test_main_entry_points()\n",
    "    test_end_to_end_workflow()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total tests: {test_results['passed'] + test_results['failed']}\")\n",
    "    print(f\"Passed: {test_results['passed']} ✓\")\n",
    "    print(f\"Failed: {test_results['failed']} ✗\")\n",
    "    \n",
    "    if test_results['failed'] > 0:\n",
    "        print(\"\\nFAILED TESTS:\")\n",
    "        for error in test_results['errors']:\n",
    "            print(f\"\\n{error['test']}:\")\n",
    "            print(f\"  Error: {error['error']}\")\n",
    "            if 'traceback' in error:\n",
    "                print(f\"  Traceback:\\n{error['traceback']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    if test_results['failed'] == 0:\n",
    "        print(\"ALL TESTS PASSED! ✓\")\n",
    "        print(\"The regime system is working correctly.\")\n",
    "    else:\n",
    "        print(\"SOME TESTS FAILED! ✗\")\n",
    "        print(\"Please check the errors above.\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return test_results['failed'] == 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = run_all_tests()\n",
    "    sys.exit(0 if success else 1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
