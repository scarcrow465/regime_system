{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aac1a8-8e2a-4e8f-ba5d-e7c48bf16b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main entry point for the Regime System\n",
    "Demonstrates usage of the reorganized package structure\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Add regime_system to path\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "# Import from our organized modules\n",
    "from core.data_loader import load_csv_data, prepare_data_for_analysis, get_data_info\n",
    "from core.indicators import calculate_all_indicators, validate_indicators\n",
    "from core.regime_classifier import RollingRegimeClassifier\n",
    "from config.settings import (\n",
    "    DEFAULT_WINDOW_HOURS, OPTIMIZATION_ITERATIONS, \n",
    "    RESULTS_DIR, LOG_FILE, SYMBOLS, TIMEFRAMES,\n",
    "    WALK_FORWARD_WINDOWS, OBJECTIVE_WEIGHTS\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(LOG_FILE),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN ANALYSIS FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def run_regime_analysis(filepath: str, \n",
    "                       window_hours: float = DEFAULT_WINDOW_HOURS,\n",
    "                       timeframe: str = '15min',\n",
    "                       save_results: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run complete regime analysis on data\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to CSV data file\n",
    "        window_hours: Rolling window size in hours\n",
    "        timeframe: Data timeframe\n",
    "        save_results: Whether to save results to file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with regime classifications\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"STARTING REGIME ANALYSIS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Data file: {filepath}\")\n",
    "    logger.info(f\"Window: {window_hours} hours\")\n",
    "    logger.info(f\"Timeframe: {timeframe}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load data\n",
    "        logger.info(\"\\nStep 1: Loading data...\")\n",
    "        data = load_csv_data(filepath, timeframe=timeframe)\n",
    "        data = prepare_data_for_analysis(data)\n",
    "        \n",
    "        data_info = get_data_info(data)\n",
    "        logger.info(f\"Loaded {data_info['rows']} rows from {data_info['start_date']} to {data_info['end_date']}\")\n",
    "        \n",
    "        # Step 2: Calculate indicators\n",
    "        logger.info(\"\\nStep 2: Calculating indicators...\")\n",
    "        data_with_indicators = calculate_all_indicators(data, verbose=True)\n",
    "        \n",
    "        # Validate indicators\n",
    "        validation = validate_indicators(data_with_indicators)\n",
    "        logger.info(f\"Valid indicators: {len(validation['valid'])}\")\n",
    "        if validation['missing']:\n",
    "            logger.warning(f\"Missing indicators: {validation['missing']}\")\n",
    "        \n",
    "        # Step 3: Classify regimes\n",
    "        logger.info(\"\\nStep 3: Classifying regimes...\")\n",
    "        classifier = RollingRegimeClassifier(window_hours=window_hours, timeframe=timeframe)\n",
    "        regimes = classifier.classify_regimes(data_with_indicators, show_progress=True)\n",
    "        \n",
    "        # Get regime statistics\n",
    "        stats = classifier.get_regime_statistics(regimes)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"REGIME CLASSIFICATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for dimension, dim_stats in stats.items():\n",
    "            if dimension != 'Composite':\n",
    "                print(f\"\\n{dimension} Dimension:\")\n",
    "                for regime, pct in dim_stats['percentages'].items():\n",
    "                    if regime != 'Undefined':\n",
    "                        print(f\"  {regime}: {pct:.1f}%\")\n",
    "                print(f\"  Average Confidence: {dim_stats['average_confidence']:.3f}\")\n",
    "        \n",
    "        if 'Composite' in stats:\n",
    "            print(f\"\\nComposite Regimes: {stats['Composite']['unique_regimes']} unique combinations\")\n",
    "            print(\"Top 5 Composite Regimes:\")\n",
    "            for regime, count in list(stats['Composite']['top_10_regimes'].items())[:5]:\n",
    "                pct = (count / len(regimes)) * 100\n",
    "                print(f\"  {regime}: {pct:.1f}%\")\n",
    "        \n",
    "        # Step 4: Save results\n",
    "        if save_results:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = os.path.join(RESULTS_DIR, f\"regime_analysis_{timestamp}.csv\")\n",
    "            \n",
    "            # Combine data with regimes\n",
    "            results = pd.concat([data_with_indicators, regimes], axis=1)\n",
    "            results.to_csv(output_file)\n",
    "            logger.info(f\"\\nResults saved to: {output_file}\")\n",
    "        \n",
    "        return regimes\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in regime analysis: {e}\")\n",
    "        raise\n",
    "\n",
    "def run_optimization(filepath: str,\n",
    "                    timeframe: str = '15min',\n",
    "                    optimize_window: bool = True,\n",
    "                    walk_forward: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Run regime optimization\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to CSV data file\n",
    "        timeframe: Data timeframe\n",
    "        optimize_window: Whether to optimize window size\n",
    "        walk_forward: Whether to use walk-forward validation\n",
    "        \n",
    "    Returns:\n",
    "        Optimization results\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"STARTING REGIME OPTIMIZATION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Import optimization modules (lazy import to avoid circular dependencies)\n",
    "        from optimization.multi_objective import MultiObjectiveRegimeOptimizer\n",
    "        from optimization.window_optimizer import optimize_window_size\n",
    "        from optimization.walk_forward import WalkForwardOptimizer\n",
    "        \n",
    "        # Load and prepare data\n",
    "        data = load_csv_data(filepath, timeframe=timeframe)\n",
    "        data = prepare_data_for_analysis(data)\n",
    "        data_with_indicators = calculate_all_indicators(data)\n",
    "        \n",
    "        # Step 1: Window optimization (if requested)\n",
    "        optimal_window = DEFAULT_WINDOW_HOURS\n",
    "        if optimize_window:\n",
    "            logger.info(\"\\nStep 1: Optimizing window size...\")\n",
    "            window_results = optimize_window_size(\n",
    "                data_with_indicators,\n",
    "                timeframe=timeframe,\n",
    "                window_sizes_hours=[12, 24, 36, 48, 72]\n",
    "            )\n",
    "            optimal_window = window_results['best_window']\n",
    "            logger.info(f\"Optimal window: {optimal_window} hours\")\n",
    "        \n",
    "        # Step 2: Regime optimization\n",
    "        if walk_forward:\n",
    "            logger.info(\"\\nStep 2: Running walk-forward optimization...\")\n",
    "            wf_optimizer = WalkForwardOptimizer(\n",
    "                n_windows=WALK_FORWARD_WINDOWS,\n",
    "                train_ratio=0.67\n",
    "            )\n",
    "            results = wf_optimizer.run_walk_forward(\n",
    "                data_with_indicators,\n",
    "                window_hours=optimal_window,\n",
    "                timeframe=timeframe,\n",
    "                max_iterations=OPTIMIZATION_ITERATIONS\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"\\nStep 2: Running single optimization...\")\n",
    "            classifier = RollingRegimeClassifier(window_hours=optimal_window, timeframe=timeframe)\n",
    "            optimizer = MultiObjectiveRegimeOptimizer(classifier, data_with_indicators)\n",
    "            results = optimizer.optimize_regime_thresholds(\n",
    "                method='differential_evolution',\n",
    "                max_iterations=OPTIMIZATION_ITERATIONS\n",
    "            )\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"OPTIMIZATION RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Best Score: {results.get('best_score', 0):.4f}\")\n",
    "        print(f\"Sharpe Ratio: {results.get('sharpe_ratio', 0):.4f}\")\n",
    "        print(f\"Max Drawdown: {results.get('max_drawdown', 0):.4f}\")\n",
    "        print(f\"Regime Persistence: {results.get('regime_persistence', 0):.4f}\")\n",
    "        \n",
    "        if 'best_params' in results:\n",
    "            print(\"\\nOptimized Parameters:\")\n",
    "            for param, value in results['best_params'].items():\n",
    "                print(f\"  {param}: {value:.4f}\")\n",
    "        \n",
    "        # Save results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_file = os.path.join(RESULTS_DIR, f\"optimization_results_{timestamp}.json\")\n",
    "        \n",
    "        import json\n",
    "        with open(results_file, 'w') as f:\n",
    "            # Convert non-serializable objects\n",
    "            save_results = {k: v for k, v in results.items() \n",
    "                          if not isinstance(v, (pd.DataFrame, pd.Series))}\n",
    "            json.dump(save_results, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"\\nResults saved to: {results_file}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in optimization: {e}\")\n",
    "        raise\n",
    "\n",
    "def run_backtesting(filepath: str,\n",
    "                   regime_file: Optional[str] = None,\n",
    "                   timeframe: str = '15min') -> Dict:\n",
    "    \"\"\"\n",
    "    Run backtesting with regime-based strategies\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to CSV data file\n",
    "        regime_file: Path to saved regime classifications (optional)\n",
    "        timeframe: Data timeframe\n",
    "        \n",
    "    Returns:\n",
    "        Backtesting results\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"STARTING REGIME BACKTESTING\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Import backtesting module\n",
    "        from backtesting.strategies import EnhancedRegimeStrategyBacktester\n",
    "        \n",
    "        # Load data\n",
    "        data = load_csv_data(filepath, timeframe=timeframe)\n",
    "        data = prepare_data_for_analysis(data)\n",
    "        data_with_indicators = calculate_all_indicators(data)\n",
    "        \n",
    "        # Load or calculate regimes\n",
    "        if regime_file and os.path.exists(regime_file):\n",
    "            logger.info(f\"Loading regimes from: {regime_file}\")\n",
    "            all_data = pd.read_csv(regime_file, index_col=0, parse_dates=True)\n",
    "            regime_columns = [col for col in all_data.columns if 'Regime' in col or 'Confidence' in col]\n",
    "            regimes = all_data[regime_columns]\n",
    "        else:\n",
    "            logger.info(\"Calculating regimes...\")\n",
    "            classifier = RollingRegimeClassifier(window_hours=DEFAULT_WINDOW_HOURS, timeframe=timeframe)\n",
    "            regimes = classifier.classify_regimes(data_with_indicators)\n",
    "        \n",
    "        # Run backtesting\n",
    "        logger.info(\"\\nRunning backtesting...\")\n",
    "        backtester = EnhancedRegimeStrategyBacktester()\n",
    "        \n",
    "        # Test adaptive strategy\n",
    "        returns = backtester.adaptive_regime_strategy_enhanced(data_with_indicators, regimes)\n",
    "        metrics = backtester.calculate_performance_metrics(returns)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"BACKTESTING RESULTS - Adaptive Regime Strategy\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Total Return: {metrics['total_return']:.2%}\")\n",
    "        print(f\"Sharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "        print(f\"Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "        print(f\"Win Rate: {metrics['win_rate']:.2%}\")\n",
    "        print(f\"Calmar Ratio: {metrics['calmar_ratio']:.4f}\")\n",
    "        print(f\"Sortino Ratio: {metrics['sortino_ratio']:.4f}\")\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in backtesting: {e}\")\n",
    "        raise\n",
    "\n",
    "# =============================================================================\n",
    "# COMMAND LINE INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main CLI entry point\"\"\"\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Regime System - Institutional Grade Analysis')\n",
    "    parser.add_argument('command', choices=['analyze', 'optimize', 'backtest'],\n",
    "                       help='Command to run')\n",
    "    parser.add_argument('--data', required=True, help='Path to CSV data file')\n",
    "    parser.add_argument('--window', type=float, default=DEFAULT_WINDOW_HOURS,\n",
    "                       help='Window size in hours')\n",
    "    parser.add_argument('--timeframe', default='15min',\n",
    "                       choices=['5min', '15min', '30min', '1H', '4H', 'Daily'],\n",
    "                       help='Data timeframe')\n",
    "    parser.add_argument('--optimize-window', action='store_true',\n",
    "                       help='Optimize window size')\n",
    "    parser.add_argument('--walk-forward', action='store_true',\n",
    "                       help='Use walk-forward validation')\n",
    "    parser.add_argument('--regime-file', help='Path to saved regime classifications')\n",
    "    parser.add_argument('--no-save', action='store_true',\n",
    "                       help='Do not save results')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    try:\n",
    "        if args.command == 'analyze':\n",
    "            run_regime_analysis(\n",
    "                args.data,\n",
    "                window_hours=args.window,\n",
    "                timeframe=args.timeframe,\n",
    "                save_results=not args.no_save\n",
    "            )\n",
    "        \n",
    "        elif args.command == 'optimize':\n",
    "            run_optimization(\n",
    "                args.data,\n",
    "                timeframe=args.timeframe,\n",
    "                optimize_window=args.optimize_window,\n",
    "                walk_forward=args.walk_forward\n",
    "            )\n",
    "        \n",
    "        elif args.command == 'backtest':\n",
    "            run_backtesting(\n",
    "                args.data,\n",
    "                regime_file=args.regime_file,\n",
    "                timeframe=args.timeframe\n",
    "            )\n",
    "        \n",
    "        logger.info(\"\\nProcess completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "def example_usage():\n",
    "    \"\"\"Show example usage of the regime system\"\"\"\n",
    "    print(\"\"\"\n",
    "    # Example Usage:\n",
    "    \n",
    "    # 1. Basic regime analysis\n",
    "    python main.py analyze --data \"path/to/data.csv\" --timeframe 15min\n",
    "    \n",
    "    # 2. Optimize with window size optimization\n",
    "    python main.py optimize --data \"path/to/data.csv\" --optimize-window\n",
    "    \n",
    "    # 3. Walk-forward optimization\n",
    "    python main.py optimize --data \"path/to/data.csv\" --walk-forward\n",
    "    \n",
    "    # 4. Backtest with saved regimes\n",
    "    python main.py backtest --data \"path/to/data.csv\" --regime-file \"results/regimes.csv\"\n",
    "    \n",
    "    # 5. Custom window analysis\n",
    "    python main.py analyze --data \"path/to/data.csv\" --window 48 --timeframe 1H\n",
    "    \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if no arguments provided\n",
    "    if len(sys.argv) == 1:\n",
    "        example_usage()\n",
    "    else:\n",
    "        main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
