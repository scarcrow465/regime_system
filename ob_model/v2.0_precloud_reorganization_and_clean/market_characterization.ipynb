{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Market Behavioral Fingerprint System\n",
    "Save this as: market_characterizer.py\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class MarketProfile:\n",
    "    \"\"\"Stores market behavioral characteristics\"\"\"\n",
    "    instrument: str\n",
    "    timeframe: str\n",
    "    \n",
    "    # Directional bias\n",
    "    long_edge: float  # Sharpe of buy & hold\n",
    "    short_edge: float  # Sharpe of short & hold\n",
    "    directional_bias: str  # 'long', 'short', 'neutral'\n",
    "    \n",
    "    # Behavioral type\n",
    "    trend_persistence: float  # Momentum strategy sharpe\n",
    "    mean_reversion: float  # Fade strategy sharpe\n",
    "    volatility_expansion: float  # Breakout strategy sharpe\n",
    "    primary_behavior: str  # 'trending', 'mean_reverting', 'breakout'\n",
    "    \n",
    "    # Optimal parameters\n",
    "    optimal_holding_period: int  # Bars\n",
    "    edge_half_life: int  # Bars until edge decays 50%\n",
    "    \n",
    "    # Random baseline\n",
    "    random_long_sharpe: float\n",
    "    random_short_sharpe: float\n",
    "    \n",
    "    # Statistical significance\n",
    "    sample_size: int\n",
    "    confidence_level: float\n",
    "\n",
    "\n",
    "class MarketCharacterizer:\n",
    "    \"\"\"Characterizes market behavior to establish baseline edge\"\"\"\n",
    "    \n",
    "    def __init__(self, transaction_cost: float = 0.0001):\n",
    "        self.transaction_cost = transaction_cost\n",
    "    \n",
    "    def characterize_market(self, data: pd.DataFrame, \n",
    "                          instrument: str, \n",
    "                          timeframe: str) -> MarketProfile:\n",
    "        \"\"\"Complete market characterization\"\"\"\n",
    "        logger.info(f\"Characterizing {instrument} {timeframe}\")\n",
    "        \n",
    "        # 1. Test directional bias\n",
    "        long_edge, short_edge, bias = self._test_directional_bias(data)\n",
    "        \n",
    "        # 2. Test behavioral patterns\n",
    "        trend_score = self._test_trend_persistence(data)\n",
    "        mr_score = self._test_mean_reversion(data)\n",
    "        breakout_score = self._test_volatility_expansion(data)\n",
    "        \n",
    "        # 3. Determine primary behavior\n",
    "        behaviors = {\n",
    "            'trending': trend_score,\n",
    "            'mean_reverting': mr_score,\n",
    "            'breakout': breakout_score\n",
    "        }\n",
    "        primary_behavior = max(behaviors, key=behaviors.get)\n",
    "        \n",
    "        # 4. Find optimal holding period\n",
    "        optimal_period = self._find_optimal_holding_period(data, bias)\n",
    "        \n",
    "        # 5. Test edge decay\n",
    "        edge_half_life = self._test_edge_decay(data, primary_behavior)\n",
    "        \n",
    "        # 6. Establish random baseline\n",
    "        random_long, random_short = self._test_random_baseline(data)\n",
    "        \n",
    "        # 7. Calculate confidence\n",
    "        confidence = self._calculate_confidence(data, behaviors[primary_behavior])\n",
    "        \n",
    "        return MarketProfile(\n",
    "            instrument=instrument,\n",
    "            timeframe=timeframe,\n",
    "            long_edge=long_edge,\n",
    "            short_edge=short_edge,\n",
    "            directional_bias=bias,\n",
    "            trend_persistence=trend_score,\n",
    "            mean_reversion=mr_score,\n",
    "            volatility_expansion=breakout_score,\n",
    "            primary_behavior=primary_behavior,\n",
    "            optimal_holding_period=optimal_period,\n",
    "            edge_half_life=edge_half_life,\n",
    "            random_long_sharpe=random_long,\n",
    "            random_short_sharpe=random_short,\n",
    "            sample_size=len(data),\n",
    "            confidence_level=confidence\n",
    "        )\n",
    "    \n",
    "    def _test_directional_bias(self, data: pd.DataFrame) -> Tuple[float, float, str]:\n",
    "        \"\"\"Test if market has inherent directional bias\"\"\"\n",
    "        returns = data['close'].pct_change().dropna()\n",
    "        \n",
    "        # Buy and hold\n",
    "        long_returns = returns\n",
    "        long_sharpe = self._calculate_sharpe(long_returns)\n",
    "        \n",
    "        # Short and hold\n",
    "        short_returns = -returns\n",
    "        short_sharpe = self._calculate_sharpe(short_returns)\n",
    "        \n",
    "        # Determine bias\n",
    "        if long_sharpe > 0.5 and long_sharpe > short_sharpe + 0.3:\n",
    "            bias = 'long'\n",
    "        elif short_sharpe > 0.5 and short_sharpe > long_sharpe + 0.3:\n",
    "            bias = 'short'\n",
    "        else:\n",
    "            bias = 'neutral'\n",
    "        \n",
    "        logger.info(f\"Directional bias: {bias} (Long: {long_sharpe:.3f}, Short: {short_sharpe:.3f})\")\n",
    "        return long_sharpe, short_sharpe, bias\n",
    "    \n",
    "    def _test_trend_persistence(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Test if trends persist (momentum works)\"\"\"\n",
    "        # Simple momentum: buy if price > 20-period SMA\n",
    "        sma = data['close'].rolling(20).mean()\n",
    "        signal = (data['close'] > sma).astype(int).diff()\n",
    "        \n",
    "        # Calculate returns\n",
    "        position = signal.fillna(0).cumsum()\n",
    "        returns = position.shift(1) * data['close'].pct_change()\n",
    "        returns = returns - abs(signal) * self.transaction_cost\n",
    "        \n",
    "        return self._calculate_sharpe(returns)\n",
    "    \n",
    "    def _test_mean_reversion(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Test if market mean reverts\"\"\"\n",
    "        # Simple mean reversion: buy when RSI < 30, sell when RSI > 70\n",
    "        if 'RSI_14' in data.columns:\n",
    "            rsi = data['RSI_14']\n",
    "        else:\n",
    "            # Calculate RSI if not present\n",
    "            delta = data['close'].diff()\n",
    "            gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "            rs = gain / loss\n",
    "            rsi = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Generate signals\n",
    "        long_signal = (rsi < 30).astype(int)\n",
    "        short_signal = (rsi > 70).astype(int)\n",
    "        position = long_signal - short_signal\n",
    "        \n",
    "        # Calculate returns\n",
    "        returns = position.shift(1) * data['close'].pct_change()\n",
    "        returns = returns - abs(position.diff()) * self.transaction_cost\n",
    "        \n",
    "        return self._calculate_sharpe(returns)\n",
    "    \n",
    "    def _test_volatility_expansion(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Test if volatility breakouts work\"\"\"\n",
    "        # Simple breakout: buy on 20-bar high, sell on 20-bar low\n",
    "        if 'high' in data.columns and 'low' in data.columns:\n",
    "            high_20 = data['high'].rolling(20).max()\n",
    "            low_20 = data['low'].rolling(20).min()\n",
    "        else:\n",
    "            # Use close if high/low not available\n",
    "            high_20 = data['close'].rolling(20).max()\n",
    "            low_20 = data['close'].rolling(20).min()\n",
    "        \n",
    "        long_signal = (data['close'] > high_20.shift(1)).astype(int)\n",
    "        short_signal = (data['close'] < low_20.shift(1)).astype(int)\n",
    "        position = long_signal - short_signal\n",
    "        \n",
    "        # Calculate returns\n",
    "        returns = position.shift(1) * data['close'].pct_change()\n",
    "        returns = returns - abs(position.diff()) * self.transaction_cost\n",
    "        \n",
    "        return self._calculate_sharpe(returns)\n",
    "    \n",
    "    def _find_optimal_holding_period(self, data: pd.DataFrame, bias: str) -> int:\n",
    "        \"\"\"Find optimal holding period for the market\"\"\"\n",
    "        best_sharpe = -999\n",
    "        best_period = 1\n",
    "        \n",
    "        for period in [1, 5, 10, 20, 50, 100, 200]:\n",
    "            if period > len(data) / 10:  # Skip if period too large for data\n",
    "                continue\n",
    "                \n",
    "            # Test buy/sell and hold for 'period' bars\n",
    "            if bias == 'long' or bias == 'neutral':\n",
    "                signal = data['close'] > data['close'].shift(period)\n",
    "            else:\n",
    "                signal = data['close'] < data['close'].shift(period)\n",
    "            \n",
    "            # Hold for 'period' bars\n",
    "            returns = signal.shift(period) * data['close'].pct_change().rolling(period).sum()\n",
    "            sharpe = self._calculate_sharpe(returns.dropna())\n",
    "            \n",
    "            if sharpe > best_sharpe:\n",
    "                best_sharpe = sharpe\n",
    "                best_period = period\n",
    "        \n",
    "        logger.info(f\"Optimal holding period: {best_period} bars (Sharpe: {best_sharpe:.3f})\")\n",
    "        return best_period\n",
    "    \n",
    "    def _test_edge_decay(self, data: pd.DataFrame, behavior: str) -> int:\n",
    "        \"\"\"Test how quickly edge decays over time\"\"\"\n",
    "        # Split data into chunks and test strategy performance\n",
    "        chunk_size = max(1000, len(data) // 10)  # At least 1000 bars per chunk\n",
    "        sharpes = []\n",
    "        \n",
    "        for i in range(min(10, len(data) // chunk_size)):\n",
    "            chunk = data.iloc[i*chunk_size:(i+1)*chunk_size]\n",
    "            if len(chunk) < 100:  # Skip tiny chunks\n",
    "                continue\n",
    "                \n",
    "            if behavior == 'trending':\n",
    "                sharpe = self._test_trend_persistence(chunk)\n",
    "            elif behavior == 'mean_reverting':\n",
    "                sharpe = self._test_mean_reversion(chunk)\n",
    "            else:\n",
    "                sharpe = self._test_volatility_expansion(chunk)\n",
    "            sharpes.append(sharpe)\n",
    "        \n",
    "        if not sharpes:\n",
    "            return len(data) // 2  # Default to half the data\n",
    "        \n",
    "        # Find where performance drops 50%\n",
    "        peak_sharpe = max(sharpes)\n",
    "        half_sharpe = peak_sharpe / 2\n",
    "        \n",
    "        half_life_chunks = len(sharpes)  # Default if no decay\n",
    "        for i, sharpe in enumerate(sharpes):\n",
    "            if sharpe < half_sharpe:\n",
    "                half_life_chunks = i + 1\n",
    "                break\n",
    "        \n",
    "        half_life_bars = half_life_chunks * chunk_size\n",
    "        logger.info(f\"Edge half-life: {half_life_bars} bars\")\n",
    "        return half_life_bars\n",
    "    \n",
    "    def _test_random_baseline(self, data: pd.DataFrame) -> Tuple[float, float]:\n",
    "        \"\"\"Establish random entry baseline\"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Random long entries\n",
    "        random_long = np.random.choice([0, 1], size=len(data), p=[0.5, 0.5])\n",
    "        long_returns = random_long * data['close'].pct_change()\n",
    "        long_returns = long_returns - abs(np.diff(random_long, prepend=0)) * self.transaction_cost\n",
    "        random_long_sharpe = self._calculate_sharpe(long_returns)\n",
    "        \n",
    "        # Random short entries\n",
    "        random_short = np.random.choice([0, -1], size=len(data), p=[0.5, 0.5])\n",
    "        short_returns = random_short * data['close'].pct_change()\n",
    "        short_returns = short_returns - abs(np.diff(random_short, prepend=0)) * self.transaction_cost\n",
    "        random_short_sharpe = self._calculate_sharpe(short_returns)\n",
    "        \n",
    "        logger.info(f\"Random baseline - Long: {random_long_sharpe:.3f}, Short: {random_short_sharpe:.3f}\")\n",
    "        return random_long_sharpe, random_short_sharpe\n",
    "    \n",
    "    def _calculate_sharpe(self, returns: pd.Series) -> float:\n",
    "        \"\"\"Calculate Sharpe ratio\"\"\"\n",
    "        if len(returns) < 20:\n",
    "            return -999\n",
    "        \n",
    "        clean_returns = returns.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if len(clean_returns) == 0 or clean_returns.std() == 0:\n",
    "            return -999\n",
    "        \n",
    "        # Annualized Sharpe for 15-min bars\n",
    "        periods_per_year = 252 * 26  # 26 fifteen-minute periods per day\n",
    "        sharpe = clean_returns.mean() / clean_returns.std() * np.sqrt(periods_per_year)\n",
    "        return sharpe\n",
    "    \n",
    "    def _calculate_confidence(self, data: pd.DataFrame, score: float) -> float:\n",
    "        \"\"\"Calculate statistical confidence in the edge\"\"\"\n",
    "        # Simple confidence based on sample size and score magnitude\n",
    "        sample_factor = min(1.0, len(data) / 10000)  # Full confidence at 10k+ samples\n",
    "        score_factor = min(1.0, abs(score) / 0.5)  # Full confidence at 0.5+ Sharpe\n",
    "        \n",
    "        confidence = sample_factor * score_factor\n",
    "        return confidence"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
