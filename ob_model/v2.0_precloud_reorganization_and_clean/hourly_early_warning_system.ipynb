{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1-Hour Early Warning System for Daily Regime Changes\n",
    "Detects when hourly regimes diverge from daily, signaling potential transitions\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class RegimeDivergence:\n",
    "    \"\"\"Represents a divergence between hourly and daily regimes\"\"\"\n",
    "    timestamp: pd.Timestamp\n",
    "    daily_regime: str\n",
    "    hourly_regime: str\n",
    "    divergence_type: str  # 'direction', 'strength', 'volatility', 'character'\n",
    "    divergence_strength: float  # 0-1 score\n",
    "    hours_persisted: int\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "class HourlyEarlyWarningSystem:\n",
    "    \"\"\"\n",
    "    Detects early warning signals from 1-hour regime divergences\n",
    "    Optimized for NQ futures based on market characterization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, daily_classifier, lookback_hours: int = 168):  # 168 hours = 7 days\n",
    "        \"\"\"\n",
    "        Initialize early warning system\n",
    "        \n",
    "        Args:\n",
    "            daily_classifier: Instance of NQDailyRegimeClassifier\n",
    "            lookback_hours: Hours of history for hourly analysis\n",
    "        \"\"\"\n",
    "        self.daily_classifier = daily_classifier\n",
    "        self.lookback_hours = lookback_hours\n",
    "        \n",
    "        # NQ-specific parameters for hourly data\n",
    "        self.hourly_thresholds = {\n",
    "            # More sensitive than daily for early detection\n",
    "            'direction_strong': 0.2,      # Lower than daily 0.3\n",
    "            'direction_neutral': 0.1,     \n",
    "            \n",
    "            'strength_strong': 0.35,      # Lower than daily 0.38\n",
    "            'strength_moderate': 0.2,     \n",
    "            \n",
    "            'vol_low': 20,               # More sensitive to vol changes\n",
    "            'vol_normal': 70,\n",
    "            'vol_high': 85,\n",
    "            \n",
    "            'efficiency_trending': 0.2,   # Lower than daily\n",
    "            'efficiency_ranging': 0.12,   \n",
    "            \n",
    "            # Faster regime detection\n",
    "            'smoothing_hours': 6,         # 6 hours vs 5-7 days\n",
    "            'min_divergence_hours': 4,    # Minimum hours to confirm divergence\n",
    "        }\n",
    "        \n",
    "        # Warning thresholds\n",
    "        self.warning_levels = {\n",
    "            'weak': 0.3,      # 30% of hourly periods diverging\n",
    "            'moderate': 0.5,  # 50% diverging\n",
    "            'strong': 0.7,    # 70% diverging\n",
    "            'critical': 0.85  # 85% diverging = regime change imminent\n",
    "        }\n",
    "        \n",
    "        # Store divergence history\n",
    "        self.divergence_history = []\n",
    "        \n",
    "    def calculate_hourly_regimes(self, hourly_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate regimes on hourly data with more sensitive parameters\n",
    "        Similar to daily but adapted for faster timeframe\n",
    "        \"\"\"\n",
    "        df = hourly_data.copy()\n",
    "        \n",
    "        # Calculate same indicators but on hourly timeframe\n",
    "        df = self._calculate_hourly_indicators(df)\n",
    "        \n",
    "        # Initialize regime columns\n",
    "        df['direction_regime'] = 'Sideways'\n",
    "        df['strength_regime'] = 'Weak'\n",
    "        df['volatility_regime'] = 'Normal'\n",
    "        df['character_regime'] = 'Ranging'\n",
    "        \n",
    "        # Classify with hourly parameters\n",
    "        df = self._classify_hourly_direction(df)\n",
    "        df = self._classify_hourly_strength(df)\n",
    "        df = self._classify_hourly_volatility(df)\n",
    "        df = self._classify_hourly_character(df)\n",
    "        \n",
    "        # Apply faster smoothing\n",
    "        df = self._smooth_hourly_regimes(df)\n",
    "        \n",
    "        # Create composite regime\n",
    "        df['composite_regime'] = (\n",
    "            df['strength_regime'] + '_' + \n",
    "            df['direction_regime'] + '_' + \n",
    "            df['volatility_regime'] + '_Vol'\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def detect_divergences(self, daily_regimes: pd.DataFrame, \n",
    "                        hourly_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Detect divergences between daily and hourly regimes\n",
    "        Returns dataframe with divergence signals\n",
    "        \"\"\"\n",
    "        logger.info(\"Detecting regime divergences...\")\n",
    "        \n",
    "        # Calculate hourly regimes\n",
    "        hourly_regimes = self.calculate_hourly_regimes(hourly_data)\n",
    "        \n",
    "        # Reset index to avoid ambiguity with 'date' column\n",
    "        hourly_regimes = hourly_regimes.reset_index()\n",
    "        \n",
    "        # Align hourly to daily based on trading session (18:00 ET prior day to 16:00 ET current day)\n",
    "        def get_trading_session_date(dt):\n",
    "            if dt.hour >= 18:\n",
    "                return dt.date() + pd.Timedelta(days=1)\n",
    "            return dt.date()\n",
    "        \n",
    "        hourly_regimes['date'] = hourly_regimes['datetime'].apply(get_trading_session_date)\n",
    "        \n",
    "        # Create a copy of daily regimes with date as a regular column\n",
    "        daily_for_merge = daily_regimes.copy().reset_index()\n",
    "        daily_for_merge['date'] = daily_for_merge['datetime'].dt.date\n",
    "        \n",
    "        # Merge to compare\n",
    "        merged = hourly_regimes.merge(\n",
    "            daily_for_merge[['date', 'direction_regime', 'strength_regime', \n",
    "                            'volatility_regime', 'character_regime', 'composite_regime']],\n",
    "            on='date',\n",
    "            how='left',\n",
    "            suffixes=('_hourly', '_daily')\n",
    "        )\n",
    "        \n",
    "        # Set index back to datetime\n",
    "        merged.set_index('datetime', inplace=True)\n",
    "        \n",
    "        # Calculate divergences\n",
    "        divergences = pd.DataFrame(index=merged.index)\n",
    "        \n",
    "        # Direction divergence\n",
    "        divergences['direction_divergence'] = (\n",
    "            merged['direction_regime_hourly'] != merged['direction_regime_daily']\n",
    "        ).astype(int)\n",
    "        \n",
    "        # Strength divergence\n",
    "        divergences['strength_divergence'] = (\n",
    "            merged['strength_regime_hourly'] != merged['strength_regime_daily']\n",
    "        ).astype(int)\n",
    "        \n",
    "        # Volatility divergence\n",
    "        divergences['volatility_divergence'] = (\n",
    "            merged['volatility_regime_hourly'] != merged['volatility_regime_daily']\n",
    "        ).astype(int)\n",
    "        \n",
    "        # Character divergence\n",
    "        divergences['character_divergence'] = (\n",
    "            merged['character_regime_hourly'] != merged['character_regime_daily']\n",
    "        ).astype(int)\n",
    "        \n",
    "        # Calculate divergence persistence (consecutive hours)\n",
    "        for col in ['direction', 'strength', 'volatility', 'character']:\n",
    "            div_col = f'{col}_divergence'\n",
    "            pers_col = f'{col}_divergence_hours'\n",
    "            \n",
    "            # Count consecutive diverging hours\n",
    "            divergences[pers_col] = divergences[div_col].groupby(\n",
    "                (divergences[div_col] != divergences[div_col].shift()).cumsum()\n",
    "            ).cumsum() * divergences[div_col]\n",
    "        \n",
    "        # Add regime information\n",
    "        divergences['hourly_regime'] = merged['composite_regime_hourly']\n",
    "        divergences['daily_regime'] = merged['composite_regime_daily']\n",
    "        \n",
    "        # Calculate overall divergence strength\n",
    "        divergences['divergence_score'] = (\n",
    "            divergences['direction_divergence'] * 0.4 +  # Direction most important\n",
    "            divergences['strength_divergence'] * 0.2 +\n",
    "            divergences['volatility_divergence'] * 0.2 +\n",
    "            divergences['character_divergence'] * 0.2\n",
    "        )\n",
    "        \n",
    "        return divergences\n",
    "    \n",
    "    def generate_warnings(self, divergences: pd.DataFrame, \n",
    "                         lookback_hours: int = 24) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Generate early warning signals based on divergence patterns\n",
    "        \"\"\"\n",
    "        warnings = []\n",
    "        \n",
    "        # Get latest data\n",
    "        latest = divergences.iloc[-lookback_hours:]\n",
    "        \n",
    "        # Check each type of divergence\n",
    "        for div_type in ['direction', 'strength', 'volatility', 'character']:\n",
    "            div_col = f'{div_type}_divergence'\n",
    "            pers_col = f'{div_type}_divergence_hours'\n",
    "            \n",
    "            # Calculate divergence percentage in lookback window\n",
    "            div_pct = latest[div_col].mean()\n",
    "            max_persistence = latest[pers_col].max()\n",
    "            \n",
    "            # Determine warning level\n",
    "            warning_level = None\n",
    "            if div_pct >= self.warning_levels['critical']:\n",
    "                warning_level = 'CRITICAL'\n",
    "            elif div_pct >= self.warning_levels['strong']:\n",
    "                warning_level = 'STRONG'\n",
    "            elif div_pct >= self.warning_levels['moderate']:\n",
    "                warning_level = 'MODERATE'\n",
    "            elif div_pct >= self.warning_levels['weak']:\n",
    "                warning_level = 'WEAK'\n",
    "            \n",
    "            if warning_level:\n",
    "                # Get specific regime details\n",
    "                latest_hourly = latest['hourly_regime'].iloc[-1]\n",
    "                latest_daily = latest['daily_regime'].iloc[-1]\n",
    "                \n",
    "                warning = {\n",
    "                    'timestamp': latest.index[-1],\n",
    "                    'type': div_type,\n",
    "                    'level': warning_level,\n",
    "                    'divergence_pct': div_pct * 100,\n",
    "                    'max_persistence_hours': max_persistence,\n",
    "                    'hourly_regime': latest_hourly,\n",
    "                    'daily_regime': latest_daily,\n",
    "                    'message': self._generate_warning_message(\n",
    "                        div_type, warning_level, div_pct, \n",
    "                        latest_hourly, latest_daily, max_persistence\n",
    "                    )\n",
    "                }\n",
    "                warnings.append(warning)\n",
    "        \n",
    "        # Check for composite warnings (multiple divergences)\n",
    "        total_divergence = latest['divergence_score'].mean()\n",
    "        if total_divergence >= 0.6:  # 60% overall divergence\n",
    "            warnings.append({\n",
    "                'timestamp': latest.index[-1],\n",
    "                'type': 'composite',\n",
    "                'level': 'CRITICAL',\n",
    "                'divergence_pct': total_divergence * 100,\n",
    "                'message': f\"CRITICAL: Multiple regime divergences detected! \"\n",
    "                          f\"Overall divergence: {total_divergence*100:.1f}%. \"\n",
    "                          f\"Daily regime change likely within 1-2 days.\"\n",
    "            })\n",
    "        \n",
    "        return warnings\n",
    "    \n",
    "    def _generate_warning_message(self, div_type: str, level: str, \n",
    "                                 div_pct: float, hourly: str, daily: str,\n",
    "                                 persistence: int) -> str:\n",
    "        \"\"\"Generate human-readable warning message\"\"\"\n",
    "        \n",
    "        messages = {\n",
    "            'direction': {\n",
    "                'WEAK': f\"Early direction divergence: Hourly showing {hourly.split('_')[1]} while daily remains {daily.split('_')[1]}\",\n",
    "                'MODERATE': f\"Growing direction divergence: {div_pct*100:.0f}% of hours conflicting with daily trend\",\n",
    "                'STRONG': f\"Strong direction warning: Hourly trend shift persisting {persistence} hours\",\n",
    "                'CRITICAL': f\"CRITICAL direction change: Daily regime likely shifting to {hourly.split('_')[1]} soon\"\n",
    "            },\n",
    "            'strength': {\n",
    "                'WEAK': f\"Trend strength diverging: Hourly {hourly.split('_')[0]} vs daily {daily.split('_')[0]}\",\n",
    "                'MODERATE': f\"Trend strength weakening/strengthening: {div_pct*100:.0f}% divergence\",\n",
    "                'STRONG': f\"Significant strength change developing over {persistence} hours\",\n",
    "                'CRITICAL': f\"Trend strength regime change imminent\"\n",
    "            },\n",
    "            'volatility': {\n",
    "                'WEAK': f\"Volatility regime shifting on hourly\",\n",
    "                'MODERATE': f\"Volatility divergence: {div_pct*100:.0f}% of hours differ from daily\",\n",
    "                'STRONG': f\"Major volatility shift detected over {persistence} hours\",\n",
    "                'CRITICAL': f\"Volatility regime change imminent - adjust position sizing\"\n",
    "            },\n",
    "            'character': {\n",
    "                'WEAK': f\"Market character starting to shift\",\n",
    "                'MODERATE': f\"Character divergence: Hourly {hourly} vs daily {daily}\",\n",
    "                'STRONG': f\"Market behavior changing significantly\",\n",
    "                'CRITICAL': f\"Complete character regime change likely\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return messages.get(div_type, {}).get(level, \"Divergence detected\")\n",
    "    \n",
    "    def _calculate_hourly_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate indicators adapted for hourly timeframe\"\"\"\n",
    "        \n",
    "        # Similar to daily but with faster periods\n",
    "        # Price vs moving averages (8h and 40h instead of 50d and 200d)\n",
    "        if 'close' in df.columns:\n",
    "            df['SMA_8'] = df['close'].rolling(8).mean()  # 8 hours\n",
    "            df['SMA_40'] = df['close'].rolling(40).mean()  # 40 hours ~ 1 week\n",
    "            df['price_vs_sma8'] = (df['close'] - df['SMA_8']) / df['SMA_8']\n",
    "            df['price_vs_sma40'] = (df['close'] - df['SMA_40']) / df['SMA_40']\n",
    "            df['sma8_vs_sma40'] = (df['SMA_8'] - df['SMA_40']) / df['SMA_40']\n",
    "        \n",
    "        # Trend slopes (faster)\n",
    "        df['trend_slope_4'] = (df['close'] - df['close'].shift(4)) / df['close'].shift(4)\n",
    "        df['trend_slope_12'] = (df['close'] - df['close'].shift(12)) / df['close'].shift(12)\n",
    "        \n",
    "        # ADX for hourly (if available in indicators)\n",
    "        # This would come from calculate_all_indicators()\n",
    "        \n",
    "        # Efficiency ratio (10 hour period)\n",
    "        df['efficiency_ratio'] = self._calculate_efficiency_ratio(df['close'], 10)\n",
    "        \n",
    "        # Realized volatility (hourly)\n",
    "        df['realized_vol'] = df['close'].pct_change().rolling(24).std() * np.sqrt(252 * 6.5) * 100\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _calculate_efficiency_ratio(self, price_series: pd.Series, period: int) -> pd.Series:\n",
    "        \"\"\"Calculate Kaufman's Efficiency Ratio for hourly data\"\"\"\n",
    "        net_change = abs(price_series - price_series.shift(period))\n",
    "        total_change = price_series.diff().abs().rolling(period).sum()\n",
    "        efficiency_ratio = net_change / total_change\n",
    "        return efficiency_ratio.fillna(0.5)\n",
    "    \n",
    "    # Classification methods adapted for hourly...\n",
    "    def _classify_hourly_direction(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Classify direction with hourly thresholds\"\"\"\n",
    "        \n",
    "        direction_score = 0\n",
    "        signal_count = 0\n",
    "        \n",
    "        if 'price_vs_sma8' in df.columns:\n",
    "            direction_score += np.sign(df['price_vs_sma8']) * 0.3\n",
    "            signal_count += 1\n",
    "        \n",
    "        if 'price_vs_sma40' in df.columns:\n",
    "            direction_score += np.sign(df['price_vs_sma40']) * 0.4\n",
    "            signal_count += 1\n",
    "            \n",
    "        if 'trend_slope_4' in df.columns:\n",
    "            direction_score += np.tanh(df['trend_slope_4'] * 20) * 0.3\n",
    "            signal_count += 1\n",
    "        \n",
    "        if signal_count > 0:\n",
    "            df['direction_score'] = direction_score\n",
    "        \n",
    "        # Classify with hourly thresholds\n",
    "        df.loc[df['direction_score'] > self.hourly_thresholds['direction_strong'], 'direction_regime'] = 'Uptrend'\n",
    "        df.loc[df['direction_score'] < -self.hourly_thresholds['direction_strong'], 'direction_regime'] = 'Downtrend'\n",
    "        df.loc[abs(df['direction_score']) < self.hourly_thresholds['direction_neutral'], 'direction_regime'] = 'Sideways'\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _classify_hourly_strength(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Simplified strength classification for hourly\"\"\"\n",
    "        \n",
    "        # Use trend consistency over shorter window\n",
    "        df['trend_consistency'] = df['close'].pct_change().rolling(12).apply(\n",
    "            lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0.5\n",
    "        )\n",
    "        \n",
    "        strength_score = abs(df['trend_consistency'] - 0.5) * 2\n",
    "        df['strength_score'] = strength_score\n",
    "        \n",
    "        df.loc[df['strength_score'] > self.hourly_thresholds['strength_strong'], 'strength_regime'] = 'Strong'\n",
    "        df.loc[\n",
    "            (df['strength_score'] > self.hourly_thresholds['strength_moderate']) & \n",
    "            (df['strength_score'] <= self.hourly_thresholds['strength_strong']), \n",
    "            'strength_regime'\n",
    "        ] = 'Moderate'\n",
    "        df.loc[df['strength_score'] <= self.hourly_thresholds['strength_moderate'], 'strength_regime'] = 'Weak'\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _classify_hourly_volatility(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Classify volatility for hourly data\"\"\"\n",
    "        \n",
    "        if 'realized_vol' in df.columns:\n",
    "            # Use 7-day rolling window for percentile\n",
    "            df['vol_percentile'] = df['realized_vol'].rolling(\n",
    "                24 * 7, min_periods=24\n",
    "            ).rank(pct=True) * 100\n",
    "            \n",
    "            df['volatility_score'] = df['vol_percentile'] / 100\n",
    "            \n",
    "            df.loc[df['vol_percentile'] < self.hourly_thresholds['vol_low'], 'volatility_regime'] = 'Low'\n",
    "            df.loc[\n",
    "                (df['vol_percentile'] >= self.hourly_thresholds['vol_low']) & \n",
    "                (df['vol_percentile'] < self.hourly_thresholds['vol_normal']), \n",
    "                'volatility_regime'\n",
    "            ] = 'Normal'\n",
    "            df.loc[\n",
    "                (df['vol_percentile'] >= self.hourly_thresholds['vol_normal']) & \n",
    "                (df['vol_percentile'] < self.hourly_thresholds['vol_high']), \n",
    "                'volatility_regime'\n",
    "            ] = 'High'\n",
    "            df.loc[df['vol_percentile'] >= self.hourly_thresholds['vol_high'], 'volatility_regime'] = 'Extreme'\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _classify_hourly_character(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Classify market character for hourly\"\"\"\n",
    "        \n",
    "        if 'efficiency_ratio' in df.columns:\n",
    "            df['character_score'] = df['efficiency_ratio']\n",
    "            \n",
    "            trending_mask = (\n",
    "                (df['efficiency_ratio'] > self.hourly_thresholds['efficiency_trending']) & \n",
    "                (df['direction_regime'] != 'Sideways')\n",
    "            )\n",
    "            df.loc[trending_mask, 'character_regime'] = 'Trending'\n",
    "            \n",
    "            ranging_mask = df['efficiency_ratio'] < self.hourly_thresholds['efficiency_ranging']\n",
    "            df.loc[ranging_mask, 'character_regime'] = 'Ranging'\n",
    "            \n",
    "            volatile_mask = df['volatility_regime'].isin(['High', 'Extreme'])\n",
    "            df.loc[volatile_mask, 'character_regime'] = 'Volatile'\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _smooth_hourly_regimes(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply smoothing appropriate for hourly data\"\"\"\n",
    "        \n",
    "        smooth_window = self.hourly_thresholds['smoothing_hours']\n",
    "        \n",
    "        # Define regime mappings for smoothing\n",
    "        regime_maps = {\n",
    "            'direction_regime': {'Uptrend': 0, 'Downtrend': 1, 'Sideways': 2},\n",
    "            'strength_regime': {'Strong': 0, 'Moderate': 1, 'Weak': 2},\n",
    "            'volatility_regime': {'Low': 0, 'Normal': 1, 'High': 2, 'Extreme': 3},\n",
    "            'character_regime': {'Trending': 0, 'Ranging': 1, 'Volatile': 2}\n",
    "        }\n",
    "        \n",
    "        for col, mapping in regime_maps.items():\n",
    "            if col in df.columns:\n",
    "                # Map to numeric\n",
    "                df[f'{col}_num'] = df[col].map(mapping)\n",
    "                \n",
    "                # Apply rolling mode\n",
    "                df[f'{col}_smooth'] = df[f'{col}_num'].rolling(\n",
    "                    window=smooth_window,\n",
    "                    min_periods=1\n",
    "                ).apply(lambda x: pd.Series(x).mode()[0] if len(pd.Series(x).mode()) > 0 else x.iloc[-1])\n",
    "                \n",
    "                # Map back to labels\n",
    "                inv_mapping = {v: k for k, v in mapping.items()}\n",
    "                df[col] = df[f'{col}_smooth'].map(inv_mapping)\n",
    "                \n",
    "                # Clean up\n",
    "                df.drop([f'{col}_num', f'{col}_smooth'], axis=1, inplace=True)\n",
    "        \n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
