{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "Lower-Timeframe Early Warning System for Daily Regime Changes\n",
    "Detects when LTF regimes diverge from daily, signaling potential transitions\n",
    "Supports resampling 1H data to 4H, 8H, 12H, etc.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class RegimeDivergence:\n",
    "    \"\"\"Represents a divergence between LTF and daily regimes\"\"\"\n",
    "    timestamp: pd.Timestamp\n",
    "    daily_regime: str\n",
    "    ltf_regime: str\n",
    "    divergence_type: str  # 'direction', 'strength', 'volatility', 'character'\n",
    "    divergence_strength: float  # 0-1 score\n",
    "    periods_persisted: int\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "class LowerTimeframeEarlyWarningSystem:\n",
    "    \"\"\"\n",
    "    Detects early warning signals from LTF regime divergences\n",
    "    Optimized for NQ futures; supports multiple timeframes via resampling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        daily_classifier, \n",
    "        timeframe: str = '1H',  # e.g., '1H', '4H', '8H', '12H'\n",
    "        lookback_periods: int = 168,  # Periods in LTF (e.g., 168 for 1H ~7 days)\n",
    "        config: Optional[Dict] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize early warning system\n",
    "        \n",
    "        Args:\n",
    "            daily_classifier: Instance of NQDailyRegimeClassifier\n",
    "            timeframe: LTF timeframe (e.g., '4H')\n",
    "            lookback_periods: Periods of history for LTF analysis\n",
    "            config: Optional dict to override thresholds/weights\n",
    "        \"\"\"\n",
    "        self.daily_classifier = daily_classifier\n",
    "        self.timeframe = timeframe\n",
    "        self.lookback_periods = lookback_periods\n",
    "        self.multiplier = int(timeframe[:-1]) if timeframe != '1H' else 1  # Hours per period\n",
    "        \n",
    "        # Default config (scalable by multiplier where needed)\n",
    "        self.config = {\n",
    "            'thresholds': {\n",
    "                'direction_strong': 0.2,\n",
    "                'direction_neutral': 0.1,\n",
    "                'strength_strong': 0.35,\n",
    "                'strength_moderate': 0.2,\n",
    "                'vol_low': 20,\n",
    "                'vol_normal': 70,\n",
    "                'vol_high': 85,\n",
    "                'efficiency_trending': 0.2,\n",
    "                'efficiency_ranging': 0.12,\n",
    "                'smoothing_periods': 6 * self.multiplier,  # Scale smoothing\n",
    "                'min_divergence_periods': 4 * self.multiplier,\n",
    "            },\n",
    "            'warning_levels': {\n",
    "                'weak': 0.3,\n",
    "                'moderate': 0.5,\n",
    "                'strong': 0.7,\n",
    "                'critical': 0.85\n",
    "            },\n",
    "            'divergence_weights': {\n",
    "                'direction': 0.4,\n",
    "                'strength': 0.2,\n",
    "                'volatility': 0.2,\n",
    "                'character': 0.2\n",
    "            },\n",
    "            'indicator_periods': {\n",
    "                'sma_short': 8 * self.multiplier,  # Scale periods\n",
    "                'sma_long': 40 * self.multiplier,\n",
    "                'trend_slope_short': 4 * self.multiplier,\n",
    "                'trend_slope_long': 12 * self.multiplier,\n",
    "                'efficiency_period': 10 * self.multiplier,\n",
    "                'vol_window': 24 * self.multiplier,\n",
    "            }\n",
    "        }\n",
    "        if config:\n",
    "            self._update_config(self.config, config)\n",
    "        \n",
    "        # Stateful storage for walk-forward\n",
    "        self.ltf_data: pd.DataFrame = pd.DataFrame()\n",
    "        self.daily_regimes: pd.DataFrame = pd.DataFrame()\n",
    "        self.divergence_history: List[RegimeDivergence] = []\n",
    "    \n",
    "    def _update_config(self, base: Dict, updates: Dict):\n",
    "        \"\"\"Recursive config update\"\"\"\n",
    "        for key, value in updates.items():\n",
    "            if isinstance(value, dict) and key in base:\n",
    "                self._update_config(base[key], value)\n",
    "            else:\n",
    "                base[key] = value\n",
    "    \n",
    "    def resample_data(self, data: pd.DataFrame, timeframe: str) -> pd.DataFrame:\n",
    "        \"\"\"Resample 1H data to higher timeframe\"\"\"\n",
    "        if timeframe == '1H':\n",
    "            return data\n",
    "        try:\n",
    "            resampled = data.resample(timeframe).agg({\n",
    "                'open': 'first',\n",
    "                'high': 'max',\n",
    "                'low': 'min',\n",
    "                'close': 'last',\n",
    "                'volume': 'sum' if 'volume' in data else None\n",
    "            }).dropna()\n",
    "            logger.info(f\"Resampled to {timeframe}: {len(resampled)} bars\")\n",
    "            return resampled\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Resampling error: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def calculate_ltf_regimes(self, ltf_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate regimes on LTF data with sensitive parameters\n",
    "        Handles resampling if needed\n",
    "        \"\"\"\n",
    "        df = self.resample_data(ltf_data, self.timeframe).copy()\n",
    "        \n",
    "        # Calculate indicators\n",
    "        df = self._calculate_ltf_indicators(df)\n",
    "        \n",
    "        # Initialize regime columns\n",
    "        df['direction_regime'] = 'Sideways'\n",
    "        df['strength_regime'] = 'Weak'\n",
    "        df['volatility_regime'] = 'Normal'\n",
    "        df['character_regime'] = 'Ranging'\n",
    "        \n",
    "        # Classify\n",
    "        df = self._classify_ltf_direction(df)\n",
    "        df = self._classify_ltf_strength(df)\n",
    "        df = self._classify_ltf_volatility(df)\n",
    "        df = self._classify_ltf_character(df)\n",
    "        \n",
    "        # Smooth\n",
    "        df = self._smooth_ltf_regimes(df)\n",
    "        \n",
    "        # Composite\n",
    "        df['composite_regime'] = (\n",
    "            df['strength_regime'] + '_' + \n",
    "            df['direction_regime'] + '_' + \n",
    "            df['volatility_regime'] + '_Vol'\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def detect_divergences(self, daily_regimes: pd.DataFrame, \n",
    "                        ltf_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Detect divergences between daily and LTF regimes\n",
    "        \"\"\"\n",
    "        logger.info(\"Detecting regime divergences...\")\n",
    "        \n",
    "        # Calculate LTF regimes\n",
    "        ltf_regimes = self.calculate_ltf_regimes(ltf_data)\n",
    "        \n",
    "        if ltf_regimes.index.name is None:\n",
    "            ltf_regimes.index.name = 'date'\n",
    "        \n",
    "        ltf_regimes = ltf_regimes.reset_index()\n",
    "        \n",
    "        def get_trading_session_date(dt):\n",
    "            if dt.hour >= 18:\n",
    "                return dt.date() + pd.Timedelta(days=1)\n",
    "            return dt.date()\n",
    "        \n",
    "        ltf_regimes['session_date'] = ltf_regimes['date'].apply(get_trading_session_date)\n",
    "        \n",
    "        # Holiday list for U.S./CME (NQ futures) - add more years as needed\n",
    "        holidays = [\n",
    "            # 2023\n",
    "            pd.to_datetime('2023-01-02'),  # New Year's Day observed\n",
    "            pd.to_datetime('2023-01-16'),  # MLK Day\n",
    "            pd.to_datetime('2023-02-20'),  # Presidents' Day\n",
    "            pd.to_datetime('2023-04-07'),  # Good Friday\n",
    "            pd.to_datetime('2023-05-29'),  # Memorial Day\n",
    "            pd.to_datetime('2023-06-19'),  # Juneteenth\n",
    "            pd.to_datetime('2023-07-04'),  # Independence Day\n",
    "            pd.to_datetime('2023-09-04'),  # Labor Day\n",
    "            pd.to_datetime('2023-11-23'),  # Thanksgiving\n",
    "            pd.to_datetime('2023-12-25'),  # Christmas\n",
    "            # 2024\n",
    "            pd.to_datetime('2024-01-01'),  # New Year's Day\n",
    "            pd.to_datetime('2024-01-15'),  # MLK Day\n",
    "            pd.to_datetime('2024-02-19'),  # Presidents' Day\n",
    "            pd.to_datetime('2024-03-29'),  # Good Friday\n",
    "            pd.to_datetime('2024-05-27'),  # Memorial Day\n",
    "            pd.to_datetime('2024-06-19'),  # Juneteenth\n",
    "            pd.to_datetime('2024-07-04'),  # Independence Day\n",
    "            pd.to_datetime('2024-09-02'),  # Labor Day\n",
    "            pd.to_datetime('2024-11-28'),  # Thanksgiving\n",
    "            pd.to_datetime('2024-12-25'),  # Christmas\n",
    "            # 2025 (from CME schedule)\n",
    "            pd.to_datetime('2025-01-01'),  # New Year's Day\n",
    "            pd.to_datetime('2025-01-20'),  # MLK Day\n",
    "            pd.to_datetime('2025-02-17'),  # Presidents' Day\n",
    "            pd.to_datetime('2025-04-18'),  # Good Friday\n",
    "            pd.to_datetime('2025-05-26'),  # Memorial Day\n",
    "            pd.to_datetime('2025-06-19'),  # Juneteenth\n",
    "            pd.to_datetime('2025-07-04'),  # Independence Day\n",
    "            pd.to_datetime('2025-09-01'),  # Labor Day\n",
    "            pd.to_datetime('2025-11-27'),  # Thanksgiving\n",
    "            pd.to_datetime('2025-12-25'),  # Christmas\n",
    "        ]\n",
    "        \n",
    "        # Adjust for holidays: If session_date is holiday, shift to next non-holiday\n",
    "        def adjust_for_holiday(session_date):\n",
    "            while session_date in holidays:\n",
    "                session_date += pd.Timedelta(days=1)\n",
    "            return session_date\n",
    "        \n",
    "        ltf_regimes['session_date'] = ltf_regimes['session_date'].apply(adjust_for_holiday)\n",
    "        \n",
    "        if daily_regimes.index.name is None:\n",
    "            daily_regimes.index.name = 'date'\n",
    "        \n",
    "        daily_for_merge = daily_regimes.copy().reset_index()\n",
    "        daily_for_merge['session_date'] = daily_for_merge['date'].dt.date\n",
    "        daily_for_merge['session_date'] = daily_for_merge['session_date'].apply(adjust_for_holiday)\n",
    "        \n",
    "        # Fix type mismatch: Convert both session_date to datetime64[ns]\n",
    "        daily_for_merge['session_date'] = pd.to_datetime(daily_for_merge['session_date'])\n",
    "        ltf_regimes['session_date'] = pd.to_datetime(ltf_regimes['session_date'])\n",
    "        \n",
    "        unmatched = ltf_regimes[~ltf_regimes['session_date'].isin(daily_for_merge['session_date'])]['session_date'].unique()\n",
    "        if len(unmatched) > 0:\n",
    "            logger.warning(f\"Unmatched session dates: {unmatched}. Forward-filling daily regimes.\")\n",
    "            # Forward-fill daily for missing (handles holidays/closures)\n",
    "            daily_for_merge = daily_for_merge.set_index('session_date').reindex(\n",
    "                pd.date_range(daily_for_merge['session_date'].min(), daily_for_merge['session_date'].max())\n",
    "            ).ffill().reset_index().rename(columns={'index': 'session_date'})\n",
    "        \n",
    "        merged = ltf_regimes.merge(\n",
    "            daily_for_merge[['session_date', 'direction_regime', 'strength_regime', \n",
    "                            'volatility_regime', 'character_regime', 'composite_regime']],\n",
    "            on='session_date',\n",
    "            how='left',\n",
    "            suffixes=('_ltf', '_daily')\n",
    "        ).set_index('date')\n",
    "        \n",
    "        # Handle NaNs\n",
    "        merged = merged.fillna('Unknown')\n",
    "        \n",
    "        divergences = pd.DataFrame(index=merged.index)\n",
    "        \n",
    "        for aspect in ['direction', 'strength', 'volatility', 'character']:\n",
    "            divergences[f'{aspect}_divergence'] = (\n",
    "                merged[f'{aspect}_regime_ltf'] != merged[f'{aspect}_regime_daily']\n",
    "            ).astype(int)\n",
    "            \n",
    "            div_col = f'{aspect}_divergence'\n",
    "            pers_col = f'{aspect}_divergence_periods'\n",
    "            divergences[pers_col] = divergences[div_col].groupby(\n",
    "                (divergences[div_col] != divergences[div_col].shift()).cumsum()\n",
    "            ).cumsum() * divergences[div_col]\n",
    "        \n",
    "        divergences['ltf_regime'] = merged['composite_regime_ltf']\n",
    "        divergences['daily_regime'] = merged['composite_regime_daily']\n",
    "        \n",
    "        weights = self.config['divergence_weights']\n",
    "        divergences['divergence_score'] = (\n",
    "            divergences['direction_divergence'] * weights['direction'] +\n",
    "            divergences['strength_divergence'] * weights['strength'] +\n",
    "            divergences['volatility_divergence'] * weights['volatility'] +\n",
    "            divergences['character_divergence'] * weights['character']\n",
    "        )\n",
    "        \n",
    "        return divergences\n",
    "    \n",
    "    def generate_warnings(self, divergences: pd.DataFrame, \n",
    "                          lookback_periods: int = 24) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Generate early warning signals\n",
    "        \"\"\"\n",
    "        warnings = []\n",
    "        latest = divergences.iloc[-lookback_periods:]\n",
    "        \n",
    "        for div_type in ['direction', 'strength', 'volatility', 'character']:\n",
    "            div_col = f'{div_type}_divergence'\n",
    "            pers_col = f'{div_type}_divergence_periods'\n",
    "            \n",
    "            div_pct = latest[div_col].mean()\n",
    "            max_persistence = latest[pers_col].max()\n",
    "            \n",
    "            levels = self.config['warning_levels']\n",
    "            warning_level = None\n",
    "            if div_pct >= levels['critical']:\n",
    "                warning_level = 'CRITICAL'\n",
    "            elif div_pct >= levels['strong']:\n",
    "                warning_level = 'STRONG'\n",
    "            elif div_pct >= levels['moderate']:\n",
    "                warning_level = 'MODERATE'\n",
    "            elif div_pct >= levels['weak']:\n",
    "                warning_level = 'WEAK'\n",
    "            \n",
    "            if warning_level:\n",
    "                latest_ltf = latest['ltf_regime'].iloc[-1]\n",
    "                latest_daily = latest['daily_regime'].iloc[-1]\n",
    "                \n",
    "                warning = {\n",
    "                    'timestamp': latest.index[-1],\n",
    "                    'type': div_type,\n",
    "                    'level': warning_level,\n",
    "                    'divergence_pct': div_pct * 100,\n",
    "                    'max_persistence_periods': max_persistence,\n",
    "                    'ltf_regime': latest_ltf,\n",
    "                    'daily_regime': latest_daily,\n",
    "                    'message': self._generate_warning_message(\n",
    "                        div_type, warning_level, div_pct, \n",
    "                        latest_ltf, latest_daily, max_persistence\n",
    "                    )\n",
    "                }\n",
    "                warnings.append(warning)\n",
    "        \n",
    "        total_divergence = latest['divergence_score'].mean()\n",
    "        if total_divergence >= 0.6:\n",
    "            warnings.append({\n",
    "                'timestamp': latest.index[-1],\n",
    "                'type': 'composite',\n",
    "                'level': 'CRITICAL',\n",
    "                'divergence_pct': total_divergence * 100,\n",
    "                'message': f\"CRITICAL: Multiple divergences! Overall: {total_divergence*100:.1f}%. Change likely.\"\n",
    "            })\n",
    "        \n",
    "        return warnings\n",
    "    \n",
    "    def _generate_warning_message(self, div_type: str, level: str, \n",
    "                                div_pct: float, ltf: str, daily: str,\n",
    "                                persistence: int) -> str:\n",
    "        \"\"\"Generate human-readable warning message\"\"\"\n",
    "        \n",
    "        # Handle cases where daily or ltf regime is NaN\n",
    "        if not isinstance(daily, str) or pd.isna(daily):\n",
    "            daily = \"Unknown\"\n",
    "        if not isinstance(ltf, str) or pd.isna(ltf):\n",
    "            ltf = \"Unknown\"\n",
    "        \n",
    "        messages = {\n",
    "            'direction': {\n",
    "                'WEAK': f\"Early direction divergence: LTF showing {ltf.split('_')[1] if '_' in ltf else ltf} while daily remains {daily.split('_')[1] if '_' in daily else daily}\",\n",
    "                'MODERATE': f\"Growing direction divergence: {div_pct*100:.0f}% of periods conflicting with daily trend\",\n",
    "                'STRONG': f\"Strong direction warning: LTF trend shift persisting {persistence} periods\",\n",
    "                'CRITICAL': f\"CRITICAL direction change: Daily regime likely shifting to {ltf.split('_')[1] if '_' in ltf else ltf} soon\"\n",
    "            },\n",
    "            'strength': {\n",
    "                'WEAK': f\"Trend strength diverging: LTF {ltf.split('_')[0] if '_' in ltf else ltf} vs daily {daily.split('_')[0] if '_' in daily else daily}\",\n",
    "                'MODERATE': f\"Trend strength weakening/strengthening: {div_pct*100:.0f}% divergence\",\n",
    "                'STRONG': f\"Significant strength change developing over {persistence} periods\",\n",
    "                'CRITICAL': f\"Trend strength regime change imminent\"\n",
    "            },\n",
    "            'volatility': {\n",
    "                'WEAK': f\"Volatility regime shifting on LTF\",\n",
    "                'MODERATE': f\"Volatility divergence: {div_pct*100:.0f}% of periods differ from daily\",\n",
    "                'STRONG': f\"Major volatility shift detected over {persistence} periods\",\n",
    "                'CRITICAL': f\"Volatility regime change imminent - adjust position sizing\"\n",
    "            },\n",
    "            'character': {\n",
    "                'WEAK': f\"Market character starting to shift\",\n",
    "                'MODERATE': f\"Character divergence: LTF {ltf} vs daily {daily}\",\n",
    "                'STRONG': f\"Market behavior changing significantly\",\n",
    "                'CRITICAL': f\"Complete character regime change likely\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return messages.get(div_type, {}).get(level, \"Divergence detected\")\n",
    "    \n",
    "    def _calculate_ltf_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        periods = self.config['indicator_periods']\n",
    "        \n",
    "        if 'close' in df.columns:\n",
    "            df['SMA_short'] = df['close'].rolling(periods['sma_short']).mean()\n",
    "            df['SMA_long'] = df['close'].rolling(periods['sma_long']).mean()\n",
    "            df['price_vs_sma_short'] = (df['close'] - df['SMA_short']) / df['SMA_short']\n",
    "            df['price_vs_sma_long'] = (df['close'] - df['SMA_long']) / df['SMA_long']\n",
    "            df['sma_short_vs_long'] = (df['SMA_short'] - df['SMA_long']) / df['SMA_long']\n",
    "        \n",
    "        df['trend_slope_short'] = (df['close'] - df['close'].shift(periods['trend_slope_short'])) / df['close'].shift(periods['trend_slope_short'])\n",
    "        df['trend_slope_long'] = (df['close'] - df['close'].shift(periods['trend_slope_long'])) / df['close'].shift(periods['trend_slope_long'])\n",
    "        \n",
    "        df['efficiency_ratio'] = self._calculate_efficiency_ratio(df['close'], periods['efficiency_period'])\n",
    "        \n",
    "        df['realized_vol'] = df['close'].pct_change().rolling(periods['vol_window']).std() * np.sqrt(252 * 6.5) * 100\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _calculate_efficiency_ratio(self, price_series: pd.Series, period: int) -> pd.Series:\n",
    "        net_change = abs(price_series - price_series.shift(period))\n",
    "        total_change = price_series.diff().abs().rolling(period).sum()\n",
    "        return (net_change / total_change).fillna(0.5)\n",
    "    \n",
    "    # _classify_ltf_* methods: Similar to original, but use self.config['thresholds']\n",
    "    def _classify_ltf_direction(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        thresh = self.config['thresholds']\n",
    "        direction_score = 0\n",
    "        signal_count = 0\n",
    "        \n",
    "        if 'price_vs_sma_short' in df.columns:\n",
    "            direction_score += np.sign(df['price_vs_sma_short']) * 0.3\n",
    "            signal_count += 1\n",
    "        \n",
    "        if 'price_vs_sma_long' in df.columns:\n",
    "            direction_score += np.sign(df['price_vs_sma_long']) * 0.4\n",
    "            signal_count += 1\n",
    "            \n",
    "        if 'trend_slope_short' in df.columns:\n",
    "            direction_score += np.tanh(df['trend_slope_short'] * 20) * 0.3\n",
    "            signal_count += 1\n",
    "        \n",
    "        if signal_count > 0:\n",
    "            df['direction_score'] = direction_score\n",
    "        \n",
    "        df.loc[df['direction_score'] > thresh['direction_strong'], 'direction_regime'] = 'Uptrend'\n",
    "        df.loc[df['direction_score'] < -thresh['direction_strong'], 'direction_regime'] = 'Downtrend'\n",
    "        df.loc[abs(df['direction_score']) < thresh['direction_neutral'], 'direction_regime'] = 'Sideways'\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _classify_ltf_strength(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Classify strength with LTF thresholds\"\"\"\n",
    "        \n",
    "        thresh = self.config['thresholds']\n",
    "        \n",
    "        # Use trend consistency over shorter window\n",
    "        df['trend_consistency'] = df['close'].pct_change().rolling(12 * self.multiplier).apply(\n",
    "            lambda x: (x > 0).sum() / len(x) if len(x) > 0 else 0.5\n",
    "        )\n",
    "        \n",
    "        strength_score = abs(df['trend_consistency'] - 0.5) * 2\n",
    "        df['strength_score'] = strength_score\n",
    "        \n",
    "        df.loc[df['strength_score'] > thresh['strength_strong'], 'strength_regime'] = 'Strong'\n",
    "        df.loc[\n",
    "            (df['strength_score'] > thresh['strength_moderate']) & \n",
    "            (df['strength_score'] <= thresh['strength_strong']), \n",
    "            'strength_regime'\n",
    "        ] = 'Moderate'\n",
    "        df.loc[df['strength_score'] <= thresh['strength_moderate'], 'strength_regime'] = 'Weak'\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _classify_ltf_volatility(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Classify volatility for LTF data\"\"\"\n",
    "        \n",
    "        thresh = self.config['thresholds']\n",
    "        \n",
    "        if 'realized_vol' in df.columns:\n",
    "            # Use rolling window scaled by multiplier for percentile\n",
    "            df['vol_percentile'] = df['realized_vol'].rolling(\n",
    "                24 * 7 * self.multiplier, min_periods=24 * self.multiplier\n",
    "            ).rank(pct=True) * 100\n",
    "            \n",
    "            df['volatility_score'] = df['vol_percentile'] / 100\n",
    "            \n",
    "            df.loc[df['vol_percentile'] < thresh['vol_low'], 'volatility_regime'] = 'Low'\n",
    "            df.loc[\n",
    "                (df['vol_percentile'] >= thresh['vol_low']) & \n",
    "                (df['vol_percentile'] < thresh['vol_normal']), \n",
    "                'volatility_regime'\n",
    "            ] = 'Normal'\n",
    "            df.loc[\n",
    "                (df['vol_percentile'] >= thresh['vol_normal']) & \n",
    "                (df['vol_percentile'] < thresh['vol_high']), \n",
    "                'volatility_regime'\n",
    "            ] = 'High'\n",
    "            df.loc[df['vol_percentile'] >= thresh['vol_high'], 'volatility_regime'] = 'Extreme'\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _classify_ltf_character(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Classify market character for LTF\"\"\"\n",
    "        \n",
    "        thresh = self.config['thresholds']\n",
    "        \n",
    "        if 'efficiency_ratio' in df.columns:\n",
    "            df['character_score'] = df['efficiency_ratio']\n",
    "            \n",
    "            trending_mask = (\n",
    "                (df['efficiency_ratio'] > thresh['efficiency_trending']) & \n",
    "                (df['direction_regime'] != 'Sideways')\n",
    "            )\n",
    "            df.loc[trending_mask, 'character_regime'] = 'Trending'\n",
    "            \n",
    "            ranging_mask = df['efficiency_ratio'] < thresh['efficiency_ranging']\n",
    "            df.loc[ranging_mask, 'character_regime'] = 'Ranging'\n",
    "            \n",
    "            volatile_mask = df['volatility_regime'].isin(['High', 'Extreme'])\n",
    "            df.loc[volatile_mask, 'character_regime'] = 'Volatile'\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _smooth_ltf_regimes(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply smoothing appropriate for LTF data\"\"\"\n",
    "        \n",
    "        smooth_window = self.config['thresholds']['smoothing_periods']\n",
    "        \n",
    "        # Define regime mappings for smoothing\n",
    "        regime_maps = {\n",
    "            'direction_regime': {'Uptrend': 0, 'Downtrend': 1, 'Sideways': 2},\n",
    "            'strength_regime': {'Strong': 0, 'Moderate': 1, 'Weak': 2},\n",
    "            'volatility_regime': {'Low': 0, 'Normal': 1, 'High': 2, 'Extreme': 3},\n",
    "            'character_regime': {'Trending': 0, 'Ranging': 1, 'Volatile': 2}\n",
    "        }\n",
    "        \n",
    "        for col, mapping in regime_maps.items():\n",
    "            if col in df.columns:\n",
    "                # Map to numeric\n",
    "                df[f'{col}_num'] = df[col].map(mapping)\n",
    "                \n",
    "                # Apply rolling mode (avoid look-ahead with closed='left')\n",
    "                df[f'{col}_smooth'] = df[f'{col}_num'].rolling(\n",
    "                    window=smooth_window,\n",
    "                    min_periods=1,\n",
    "                    closed='left'\n",
    "                ).apply(lambda x: pd.Series(x).mode()[0] if len(pd.Series(x).mode()) > 0 else x.iloc[-1])\n",
    "                \n",
    "                # Map back to labels\n",
    "                inv_mapping = {v: k for k, v in mapping.items()}\n",
    "                df[col] = df[f'{col}_smooth'].map(inv_mapping)\n",
    "                \n",
    "                # Clean up\n",
    "                df.drop([f'{col}_num', f'{col}_smooth'], axis=1, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # (Omit other _classify_* for brevity; update similarly with self.config['thresholds'])\n",
    "    \n",
    "    def _smooth_ltf_regimes(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        smooth_window = self.config['thresholds']['smoothing_periods']\n",
    "        \n",
    "        regime_maps = {\n",
    "            'direction_regime': {'Uptrend': 0, 'Downtrend': 1, 'Sideways': 2},\n",
    "            # ... (same as original)\n",
    "        }\n",
    "        \n",
    "        for col, mapping in regime_maps.items():\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_num'] = df[col].map(mapping)\n",
    "                df[f'{col}_smooth'] = df[f'{col}_num'].rolling(\n",
    "                    window=smooth_window, min_periods=1, closed='left'  # Avoid look-ahead\n",
    "                ).apply(lambda x: pd.Series(x).mode()[0] if len(pd.Series(x).mode()) > 0 else x.iloc[-1])\n",
    "                inv_mapping = {v: k for k, v in mapping.items()}\n",
    "                df[col] = df[f'{col}_smooth'].map(inv_mapping)\n",
    "                df.drop([f'{col}_num', f'{col}_smooth'], axis=1, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def update(self, new_ltf_bar: pd.Series, new_daily_bar: Optional[pd.Series] = None) -> tuple:\n",
    "        \"\"\"Incremental update for walk-forward\"\"\"\n",
    "        self.ltf_data = pd.concat([self.ltf_data, new_ltf_bar.to_frame().T])\n",
    "        \n",
    "        recent_ltf = self.ltf_data.iloc[-self.lookback_periods:]\n",
    "        ltf_regimes = self.calculate_ltf_regimes(recent_ltf)\n",
    "        \n",
    "        if new_daily_bar is not None:\n",
    "            self.daily_regimes = pd.concat([self.daily_regimes, new_daily_bar.to_frame().T])\n",
    "        \n",
    "        divergences = self.detect_divergences(self.daily_regimes, recent_ltf)\n",
    "        warnings = self.generate_warnings(divergences)\n",
    "        \n",
    "        return warnings, divergences"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
