{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Add paths\n",
    "sys.path.insert(0, r'C:\\Users\\rs\\GitProjects\\regime_system\\ob_model\\v2.0_precloud_reorganization_and_clean')\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "from core.data_loader import load_csv_data\n",
    "from core.indicators import calculate_all_indicators\n",
    "from daily_regime_classifier import NQDailyRegimeClassifier\n",
    "from hourly_early_warning_system import HourlyEarlyWarningSystem\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"1-HOUR EARLY WARNING SYSTEM TEST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Define U.S. market holidays\n",
    "holidays = [\n",
    "    '2023-05-29',  # Memorial Day\n",
    "    '2023-06-19',  # Juneteenth\n",
    "    '2023-07-04',  # Independence Day\n",
    "    '2023-09-04',  # Labor Day\n",
    "    '2023-11-23',  # Thanksgiving\n",
    "    '2024-01-15',  # Martin Luther King Jr. Day\n",
    "    '2024-02-19',  # Presidents' Day\n",
    "    '2024-05-27',  # Memorial Day\n",
    "    '2024-06-19',  # Juneteenth\n",
    "    '2024-07-04',  # Independence Day\n",
    "    '2024-09-02',  # Labor Day\n",
    "    '2024-11-28',  # Thanksgiving\n",
    "    '2025-01-20',  # Martin Luther King Jr. Day\n",
    "    '2025-02-17',  # Presidents' Day\n",
    "    '2025-04-02'   # Good Friday (partial trading day or data anomaly)\n",
    "]\n",
    "\n",
    "# Convert holidays to datetime.date objects\n",
    "holidays = [pd.to_datetime(d).date() for d in holidays]\n",
    "\n",
    "# Load daily data\n",
    "print(\"\\nLoading daily data...\")\n",
    "daily_data = load_csv_data(r'combined_NQ_daily_data.csv', timeframe='1d')\n",
    "daily_data = daily_data.tail(252 * 2)  # Last 2 years for testing\n",
    "daily_data = daily_data[~daily_data.index.date.isin(holidays)]  # Filter out holidays\n",
    "print(f\"Loaded {len(daily_data)} daily bars\")\n",
    "\n",
    "# Load hourly data\n",
    "print(\"\\nLoading hourly data...\")\n",
    "hourly_data = load_csv_data(r'combined_NQ_1h_data.csv', timeframe='60min')\n",
    "# Align hourly data to match daily date range\n",
    "hourly_data = hourly_data[hourly_data.index.date >= daily_data.index[0].date()]\n",
    "hourly_data = hourly_data[hourly_data.index.date <= daily_data.index[-1].date()]\n",
    "hourly_data = hourly_data[~hourly_data.index.date.isin(holidays)]  # Filter out holidays\n",
    "print(f\"Loaded {len(hourly_data)} hourly bars\")\n",
    "\n",
    "# Calculate indicators\n",
    "print(\"\\nCalculating daily indicators...\")\n",
    "daily_with_indicators = calculate_all_indicators(daily_data, verbose=False)\n",
    "\n",
    "print(\"Calculating hourly indicators...\")\n",
    "hourly_with_indicators = calculate_all_indicators(hourly_data, verbose=False)\n",
    "\n",
    "# Initialize classifiers\n",
    "print(\"\\nInitializing regime classifiers...\")\n",
    "daily_classifier = NQDailyRegimeClassifier(lookback_days=252, direction_strong_threshold=0.35, trending_threshold=0.3)\n",
    "early_warning = HourlyEarlyWarningSystem(daily_classifier, lookback_hours=168)\n",
    "\n",
    "# Calculate daily regimes\n",
    "print(\"Classifying daily regimes...\")\n",
    "daily_regimes = daily_classifier.classify_regimes(daily_with_indicators)\n",
    "\n",
    "# Detect divergences\n",
    "print(\"Detecting hourly-daily divergences...\")\n",
    "divergences = early_warning.detect_divergences(daily_regimes, hourly_with_indicators)\n",
    "\n",
    "# Analyze divergence patterns\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIVERGENCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall divergence statistics\n",
    "total_hours = len(divergences)\n",
    "direction_div_pct = divergences['direction_divergence'].mean() * 100\n",
    "strength_div_pct = divergences['strength_divergence'].mean() * 100\n",
    "volatility_div_pct = divergences['volatility_divergence'].mean() * 100\n",
    "character_div_pct = divergences['character_divergence'].mean() * 100\n",
    "\n",
    "print(f\"\\nOverall Divergence Rates:\")\n",
    "print(f\"  Direction: {direction_div_pct:.1f}% of hours\")\n",
    "print(f\"  Strength: {strength_div_pct:.1f}% of hours\")\n",
    "print(f\"  Volatility: {volatility_div_pct:.1f}% of hours\")\n",
    "print(f\"  Character: {character_div_pct:.1f}% of hours\")\n",
    "\n",
    "# Summarize high divergence periods\n",
    "high_div_threshold = 0.7  # Increased from 0.5\n",
    "recent_window = 24 * 7  # Last week\n",
    "\n",
    "print(f\"\\nSummary of High Divergence Periods (>{high_div_threshold*100}% in {recent_window}h window):\")\n",
    "divergences['rolling_div_score'] = divergences['divergence_score'].rolling(recent_window).mean()\n",
    "# Calculate persistence\n",
    "divergences['divergence_hours'] = divergences['divergence_score'].gt(high_div_threshold).groupby(\n",
    "    (divergences['divergence_score'].gt(high_div_threshold) != \n",
    "     divergences['divergence_score'].gt(high_div_threshold).shift()).cumsum()).cumcount() + 1\n",
    "high_div_periods = divergences[divergences['rolling_div_score'] > high_div_threshold]\n",
    "\n",
    "# Apply volume filter if volume column exists\n",
    "if 'volume' in hourly_with_indicators.columns:\n",
    "    hourly_with_indicators['volume_zscore'] = (hourly_with_indicators['volume'] - hourly_with_indicators['volume'].rolling(20).mean()) / hourly_with_indicators['volume'].rolling(20).std()\n",
    "    # Merge volume_zscore with high_div_periods\n",
    "    high_div_periods = high_div_periods.merge(\n",
    "        hourly_with_indicators[['volume_zscore']], \n",
    "        left_index=True, right_index=True, how='left')\n",
    "    high_div_periods = high_div_periods[high_div_periods['volume_zscore'] > 1.0]\n",
    "else:\n",
    "    print(\"  Warning: 'volume' column not found in hourly data. Skipping volume filter.\")\n",
    "\n",
    "# Apply persistence and multi-divergence filters\n",
    "high_div_periods = high_div_periods[high_div_periods['divergence_hours'] >= 12]\n",
    "high_div_periods = high_div_periods[\n",
    "    (high_div_periods['direction_divergence'] > 0.7) & \n",
    "    (high_div_periods[['strength_divergence', 'volatility_divergence', \n",
    "                      'character_divergence']].gt(0.5).sum(axis=1) >= 2)]\n",
    "\n",
    "if len(high_div_periods) > 0:\n",
    "    # Group consecutive periods\n",
    "    high_div_periods['group'] = (high_div_periods.index.to_series().diff() > pd.Timedelta(hours=1)).cumsum()\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    num_periods = high_div_periods['group'].nunique()\n",
    "    avg_div_score = high_div_periods['divergence_score'].mean() * 100\n",
    "    div_score_std = high_div_periods['divergence_score'].std() * 100\n",
    "    div_score_percentiles = high_div_periods['divergence_score'].quantile([0.25, 0.5, 0.75]) * 100\n",
    "    \n",
    "    # Count successful predictions\n",
    "    successful_predictions = 0\n",
    "    for group_id, group in high_div_periods.groupby('group'):\n",
    "        start = group.index[0]\n",
    "        daily_date = start.date()\n",
    "        if daily_date in daily_regimes.index.date:\n",
    "            daily_idx = daily_regimes.index.get_loc(pd.Timestamp(daily_date))\n",
    "            if daily_idx < len(daily_regimes) - 1:\n",
    "                current_regime = daily_regimes.iloc[daily_idx]['composite_regime']\n",
    "                next_regime = daily_regimes.iloc[daily_idx + 1]['composite_regime']\n",
    "                if current_regime != next_regime:\n",
    "                    successful_predictions += 1\n",
    "    \n",
    "    success_rate = (successful_predictions / num_periods * 100) if num_periods > 0 else 0\n",
    "    \n",
    "    print(f\"  Total High Divergence Periods: {num_periods}\")\n",
    "    print(f\"  Average Divergence Score: {avg_div_score:.1f}%\")\n",
    "    print(f\"  Divergence Score Std Dev: {div_score_std:.1f}%\")\n",
    "    print(f\"  Divergence Score Percentiles: 25%={div_score_percentiles[0.25]:.1f}%, 50%={div_score_percentiles[0.5]:.1f}%, 75%={div_score_percentiles[0.75]:.1f}%\")\n",
    "    print(f\"  Periods Leading to Regime Change: {successful_predictions} ({success_rate:.1f}%)\")\n",
    "else:\n",
    "    print(\"  No high divergence periods found.\")\n",
    "\n",
    "# Analyze regime change prediction accuracy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGIME CHANGE PREDICTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find all daily regime changes\n",
    "daily_regime_changes = daily_regimes['composite_regime'] != daily_regimes['composite_regime'].shift(1)\n",
    "change_dates = daily_regimes[daily_regime_changes].index[1:]  # Skip first\n",
    "\n",
    "print(f\"\\nFound {len(change_dates)} daily regime changes\")\n",
    "\n",
    "# Check if hourly divergences preceded each change\n",
    "lead_times = []\n",
    "prediction_success = []\n",
    "\n",
    "for change_date in change_dates[-10:]:  # Last 10 changes\n",
    "    # Look at 48 hours before the change\n",
    "    start_check = change_date - pd.Timedelta(hours=48)\n",
    "    end_check = change_date\n",
    "    \n",
    "    # Get divergences in this window\n",
    "    window_div = divergences[(divergences.index >= start_check) & (divergences.index < end_check)]\n",
    "    \n",
    "    if len(window_div) > 0:\n",
    "        # Calculate average divergence in windows\n",
    "        div_24h = window_div.iloc[-24:]['divergence_score'].mean() if len(window_div) >= 24 else 0\n",
    "        div_48h = window_div['divergence_score'].mean()\n",
    "        \n",
    "        # Find first significant divergence\n",
    "        significant_div = window_div[window_div['divergence_score'] > 0.4]\n",
    "        if len(significant_div) > 0:\n",
    "            first_warning = significant_div.index[0]\n",
    "            lead_time = (change_date - first_warning).total_seconds() / 3600\n",
    "            lead_times.append(lead_time)\n",
    "            prediction_success.append(True)\n",
    "            \n",
    "            print(f\"\\n  {change_date.strftime('%Y-%m-%d')}:\")\n",
    "            print(f\"    Lead time: {lead_time:.1f} hours\")\n",
    "            print(f\"    24h divergence: {div_24h*100:.0f}%\")\n",
    "            print(f\"    48h divergence: {div_48h*100:.0f}%\")\n",
    "        else:\n",
    "            prediction_success.append(False)\n",
    "            print(f\"\\n  {change_date.strftime('%Y-%m-%d')}: No significant warning\")\n",
    "\n",
    "if lead_times:\n",
    "    print(f\"\\nPrediction Statistics:\")\n",
    "    print(f\"  Success rate: {sum(prediction_success)/len(prediction_success)*100:.0f}%\")\n",
    "    print(f\"  Average lead time: {np.mean(lead_times):.1f} hours\")\n",
    "    print(f\"  Median lead time: {np.median(lead_times):.1f} hours\")\n",
    "\n",
    "# Generate current warnings\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CURRENT WARNINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "current_warnings = early_warning.generate_warnings(divergences, lookback_hours=24)\n",
    "\n",
    "if current_warnings:\n",
    "    for warning in current_warnings:\n",
    "        print(f\"\\n{warning['level']} WARNING - {warning['type'].upper()}:\")\n",
    "        print(f\"  {warning['message']}\")\n",
    "        if 'divergence_pct' in warning:\n",
    "            print(f\"  Divergence: {warning['divergence_pct']:.0f}%\")\n",
    "else:\n",
    "    print(\"\\nNo significant warnings at this time\")\n",
    "\n",
    "# Create visualization\n",
    "print(\"\\nCreating visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# Plot 1: Price with regime changes\n",
    "ax1 = axes[0]\n",
    "ax1.plot(hourly_data.index, hourly_data['close'], 'k-', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Mark daily regime changes\n",
    "for change_date in change_dates:\n",
    "    ax1.axvline(x=change_date, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.set_title('NQ Hourly Price with Daily Regime Changes (Red Lines)')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Plot 2: Direction divergence\n",
    "ax2 = axes[1]\n",
    "ax2.fill_between(divergences.index, 0, divergences['direction_divergence'], \n",
    "                 alpha=0.5, color='blue', label='Direction Divergence')\n",
    "ax2.set_ylabel('Divergence')\n",
    "ax2.set_title('Direction Regime Divergence (Hourly vs Daily)')\n",
    "ax2.set_ylim(-0.1, 1.1)\n",
    "\n",
    "# Plot 3: Strength divergence\n",
    "ax3 = axes[2]\n",
    "ax3.fill_between(divergences.index, 0, divergences['strength_divergence'], \n",
    "                 alpha=0.5, color='orange', label='Strength Divergence')\n",
    "ax3.set_ylabel('Divergence')\n",
    "ax3.set_title('Strength Regime Divergence')\n",
    "ax3.set_ylim(-0.1, 1.1)\n",
    "\n",
    "# Plot 4: Volatility divergence\n",
    "ax4 = axes[3]\n",
    "ax4.fill_between(divergences.index, 0, divergences['volatility_divergence'], \n",
    "                 alpha=0.5, color='red', label='Volatility Divergence')\n",
    "ax4.set_ylabel('Divergence')\n",
    "ax4.set_title('Volatility Regime Divergence')\n",
    "ax4.set_ylim(-0.1, 1.1)\n",
    "\n",
    "# Plot 5: Composite divergence score\n",
    "ax5 = axes[4]\n",
    "ax5.plot(divergences.index, divergences['divergence_score'], 'purple', linewidth=1)\n",
    "ax5.fill_between(divergences.index, 0, divergences['divergence_score'], \n",
    "                 alpha=0.3, color='purple')\n",
    "\n",
    "# Add warning level lines\n",
    "ax5.axhline(y=0.3, color='yellow', linestyle='--', alpha=0.5, label='Weak Warning')\n",
    "ax5.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Moderate Warning')\n",
    "ax5.axhline(y=0.7, color='red', linestyle='--', alpha=0.5, label='Strong Warning')\n",
    "\n",
    "ax5.set_ylabel('Score')\n",
    "ax5.set_xlabel('Date')\n",
    "ax5.set_title('Composite Divergence Score')\n",
    "ax5.set_ylim(0, 1)\n",
    "ax5.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'hourly_early_warning_{datetime.now().strftime(\"%Y%m%d\")}.png', dpi=150)\n",
    "print(\"✓ Saved divergence chart\")\n",
    "\n",
    "# Save divergence data\n",
    "output_file = f'hourly_divergences_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "divergences.to_csv(output_file)\n",
    "print(f\"\\n✓ Divergence data saved to: {output_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EARLY WARNING SYSTEM INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DIVERGENCE PATTERNS:\")\n",
    "print(\"   - Normal divergence rate: 20-30% is healthy\")\n",
    "print(\"   - >50% sustained divergence often precedes regime change\")\n",
    "print(\"   - Direction divergence is most predictive\")\n",
    "\n",
    "print(\"\\n2. TYPICAL LEAD TIMES:\")\n",
    "print(\"   - Minor regime adjustments: 6-12 hours warning\")\n",
    "print(\"   - Major regime changes: 24-48 hours warning\")\n",
    "print(\"   - Crisis/volatile transitions: Can be sudden (<6 hours)\")\n",
    "\n",
    "print(\"\\n3. USAGE RECOMMENDATIONS:\")\n",
    "print(\"   - Monitor composite score >0.5 for potential changes\")\n",
    "print(\"   - Direction divergence >70% = high probability of trend change\")\n",
    "print(\"   - Multiple divergences = higher confidence signal\")\n",
    "\n",
    "print(f\"\\nCompleted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
