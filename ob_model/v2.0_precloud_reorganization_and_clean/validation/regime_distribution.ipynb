{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regime distribution validation module\n",
    "Analyzes regime distributions, transitions, and stability\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from scipy import stats\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from config.settings import (\n",
    "    REGIME_DIMENSIONS, RESULTS_DIR, REGIME_SMOOTHING_PERIODS,\n",
    "    FIGURE_SIZE, FIGURE_DPI, PLOT_STYLE\n",
    ")\n",
    "from utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "\n",
    "# =============================================================================\n",
    "# REGIME DISTRIBUTION ANALYZER\n",
    "# =============================================================================\n",
    "\n",
    "class RegimeDistributionAnalyzer:\n",
    "    \"\"\"Analyze regime distributions and validate classifications\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.distribution_stats = {}\n",
    "        self.transition_matrix = {}\n",
    "        self.persistence_metrics = {}\n",
    "        \n",
    "    def analyze_distributions(self, regimes: pd.DataFrame, \n",
    "                            min_regime_pct: float = 1.0) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze regime distributions across all dimensions\n",
    "        \n",
    "        Args:\n",
    "            regimes: DataFrame with regime classifications\n",
    "            min_regime_pct: Minimum percentage for a regime to be considered significant\n",
    "            \n",
    "        Returns:\n",
    "            Distribution analysis results\n",
    "        \"\"\"\n",
    "        logger.info(\"Analyzing regime distributions\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            regime_col = f'{dimension}_Regime'\n",
    "            confidence_col = f'{dimension}_Confidence'\n",
    "            \n",
    "            if regime_col not in regimes.columns:\n",
    "                logger.warning(f\"Regime column {regime_col} not found\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate distribution\n",
    "            distribution = regimes[regime_col].value_counts()\n",
    "            distribution_pct = (distribution / len(regimes)) * 100\n",
    "            \n",
    "            # Get confidence statistics\n",
    "            confidence_stats = {}\n",
    "            if confidence_col in regimes.columns:\n",
    "                confidence_stats = {\n",
    "                    'mean': regimes[confidence_col].mean(),\n",
    "                    'std': regimes[confidence_col].std(),\n",
    "                    'min': regimes[confidence_col].min(),\n",
    "                    'max': regimes[confidence_col].max()\n",
    "                }\n",
    "            \n",
    "            # Check for rare regimes\n",
    "            rare_regimes = distribution_pct[distribution_pct < min_regime_pct].to_dict()\n",
    "            \n",
    "            # Check for dominant regimes (>80%)\n",
    "            dominant_regimes = distribution_pct[distribution_pct > 80].to_dict()\n",
    "            \n",
    "            results[dimension] = {\n",
    "                'distribution': distribution.to_dict(),\n",
    "                'distribution_pct': distribution_pct.to_dict(),\n",
    "                'confidence_stats': confidence_stats,\n",
    "                'rare_regimes': rare_regimes,\n",
    "                'dominant_regimes': dominant_regimes,\n",
    "                'balance_score': self._calculate_balance_score(distribution_pct)\n",
    "            }\n",
    "            \n",
    "            self.distribution_stats[dimension] = results[dimension]\n",
    "        \n",
    "        # Overall assessment\n",
    "        results['overall'] = self._assess_overall_distributions(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_balance_score(self, distribution_pct: pd.Series) -> float:\n",
    "        \"\"\"Calculate how balanced the regime distribution is (0-1)\"\"\"\n",
    "        # Use entropy as balance measure\n",
    "        if len(distribution_pct) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Normalize to probabilities\n",
    "        probs = distribution_pct / 100\n",
    "        \n",
    "        # Calculate entropy\n",
    "        entropy = -np.sum(probs * np.log(probs + 1e-10))\n",
    "        \n",
    "        # Normalize by maximum possible entropy\n",
    "        max_entropy = np.log(len(distribution_pct))\n",
    "        \n",
    "        if max_entropy > 0:\n",
    "            return entropy / max_entropy\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def _assess_overall_distributions(self, dimension_results: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Assess overall distribution health\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Check each dimension\n",
    "        for dimension, stats in dimension_results.items():\n",
    "            if dimension == 'overall':\n",
    "                continue\n",
    "            \n",
    "            # Check for imbalance\n",
    "            if stats['balance_score'] < 0.5:\n",
    "                issues.append(f\"{dimension} has poor regime balance (score: {stats['balance_score']:.2f})\")\n",
    "            \n",
    "            # Check for dominant regimes\n",
    "            if stats['dominant_regimes']:\n",
    "                for regime, pct in stats['dominant_regimes'].items():\n",
    "                    issues.append(f\"{dimension} dominated by {regime} ({pct:.1f}%)\")\n",
    "            \n",
    "            # Check confidence levels\n",
    "            if stats['confidence_stats'] and stats['confidence_stats']['mean'] < 0.4:\n",
    "                issues.append(f\"{dimension} has low average confidence ({stats['confidence_stats']['mean']:.2f})\")\n",
    "        \n",
    "        # Calculate overall health score\n",
    "        health_score = max(0, 1 - len(issues) / 10)\n",
    "        \n",
    "        return {\n",
    "            'health_score': health_score,\n",
    "            'issues': issues,\n",
    "            'recommendation': self._generate_distribution_recommendations(issues)\n",
    "        }\n",
    "    \n",
    "    def _generate_distribution_recommendations(self, issues: List[str]) -> List[str]:\n",
    "        \"\"\"Generate recommendations based on distribution issues\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if any('dominated by' in issue for issue in issues):\n",
    "            recommendations.append(\n",
    "                \"Review threshold parameters - some regimes are dominating\"\n",
    "            )\n",
    "        \n",
    "        if any('poor regime balance' in issue for issue in issues):\n",
    "            recommendations.append(\n",
    "                \"Consider adjusting classification thresholds for better balance\"\n",
    "            )\n",
    "        \n",
    "        if any('low average confidence' in issue for issue in issues):\n",
    "            recommendations.append(\n",
    "                \"Review indicator weights and thresholds to improve confidence\"\n",
    "            )\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# =============================================================================\n",
    "# REGIME TRANSITION ANALYZER\n",
    "# =============================================================================\n",
    "\n",
    "class RegimeTransitionAnalyzer:\n",
    "    \"\"\"Analyze regime transitions and stability\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.transition_matrices = {}\n",
    "        self.transition_stats = {}\n",
    "        \n",
    "    def analyze_transitions(self, regimes: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze regime transitions for all dimensions\n",
    "        \n",
    "        Args:\n",
    "            regimes: DataFrame with regime classifications\n",
    "            \n",
    "        Returns:\n",
    "            Transition analysis results\n",
    "        \"\"\"\n",
    "        logger.info(\"Analyzing regime transitions\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            regime_col = f'{dimension}_Regime'\n",
    "            \n",
    "            if regime_col not in regimes.columns:\n",
    "                continue\n",
    "            \n",
    "            # Calculate transition matrix\n",
    "            transition_matrix = self._calculate_transition_matrix(regimes[regime_col])\n",
    "            self.transition_matrices[dimension] = transition_matrix\n",
    "            \n",
    "            # Calculate transition statistics\n",
    "            transitions = self._calculate_transition_stats(regimes[regime_col])\n",
    "            \n",
    "            # Calculate stability metrics\n",
    "            stability = self._calculate_stability_metrics(regimes[regime_col])\n",
    "            \n",
    "            results[dimension] = {\n",
    "                'transition_matrix': transition_matrix.to_dict(),\n",
    "                'transition_stats': transitions,\n",
    "                'stability_metrics': stability,\n",
    "                'persistence': self._calculate_persistence(regimes[regime_col])\n",
    "            }\n",
    "            \n",
    "            self.transition_stats[dimension] = results[dimension]\n",
    "        \n",
    "        # Overall transition assessment\n",
    "        results['overall'] = self._assess_overall_transitions(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_transition_matrix(self, regime_series: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"Calculate regime transition probability matrix\"\"\"\n",
    "        # Get unique regimes\n",
    "        unique_regimes = regime_series.unique()\n",
    "        \n",
    "        # Initialize transition counts\n",
    "        transition_counts = pd.DataFrame(\n",
    "            0, \n",
    "            index=unique_regimes, \n",
    "            columns=unique_regimes\n",
    "        )\n",
    "        \n",
    "        # Count transitions\n",
    "        for i in range(1, len(regime_series)):\n",
    "            from_regime = regime_series.iloc[i-1]\n",
    "            to_regime = regime_series.iloc[i]\n",
    "            transition_counts.loc[from_regime, to_regime] += 1\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        transition_probs = transition_counts.div(\n",
    "            transition_counts.sum(axis=1), \n",
    "            axis=0\n",
    "        ).fillna(0)\n",
    "        \n",
    "        return transition_probs\n",
    "    \n",
    "    def _calculate_transition_stats(self, regime_series: pd.Series) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate transition statistics\"\"\"\n",
    "        # Count regime changes\n",
    "        regime_changes = (regime_series != regime_series.shift()).sum() - 1\n",
    "        \n",
    "        # Calculate average regime duration\n",
    "        regime_runs = []\n",
    "        current_regime = regime_series.iloc[0]\n",
    "        run_length = 1\n",
    "        \n",
    "        for i in range(1, len(regime_series)):\n",
    "            if regime_series.iloc[i] == current_regime:\n",
    "                run_length += 1\n",
    "            else:\n",
    "                regime_runs.append(run_length)\n",
    "                current_regime = regime_series.iloc[i]\n",
    "                run_length = 1\n",
    "        \n",
    "        regime_runs.append(run_length)\n",
    "        \n",
    "        return {\n",
    "            'total_transitions': regime_changes,\n",
    "            'transition_rate': regime_changes / len(regime_series),\n",
    "            'avg_regime_duration': np.mean(regime_runs),\n",
    "            'min_regime_duration': np.min(regime_runs),\n",
    "            'max_regime_duration': np.max(regime_runs),\n",
    "            'regime_run_distribution': np.histogram(regime_runs, bins=10)[0].tolist()\n",
    "        }\n",
    "    \n",
    "    def _calculate_stability_metrics(self, regime_series: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"Calculate regime stability metrics\"\"\"\n",
    "        # Persistence (probability of staying in same regime)\n",
    "        persistence_probs = []\n",
    "        \n",
    "        transition_matrix = self._calculate_transition_matrix(regime_series)\n",
    "        for regime in transition_matrix.index:\n",
    "            if regime in transition_matrix.columns:\n",
    "                persistence_probs.append(transition_matrix.loc[regime, regime])\n",
    "        \n",
    "        # Entropy of transitions\n",
    "        transition_entropy = 0\n",
    "        for _, row in transition_matrix.iterrows():\n",
    "            probs = row[row > 0]\n",
    "            if len(probs) > 0:\n",
    "                transition_entropy -= np.sum(probs * np.log(probs + 1e-10))\n",
    "        \n",
    "        return {\n",
    "            'avg_persistence': np.mean(persistence_probs) if persistence_probs else 0,\n",
    "            'min_persistence': np.min(persistence_probs) if persistence_probs else 0,\n",
    "            'transition_entropy': transition_entropy,\n",
    "            'stability_score': np.mean(persistence_probs) if persistence_probs else 0\n",
    "        }\n",
    "    \n",
    "    def _calculate_persistence(self, regime_series: pd.Series) -> float:\n",
    "        \"\"\"Calculate overall regime persistence\"\"\"\n",
    "        # Count consecutive periods in same regime\n",
    "        same_regime = (regime_series == regime_series.shift()).sum()\n",
    "        total_periods = len(regime_series) - 1\n",
    "        \n",
    "        return same_regime / total_periods if total_periods > 0 else 0\n",
    "    \n",
    "    def _assess_overall_transitions(self, dimension_results: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Assess overall transition patterns\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        for dimension, stats in dimension_results.items():\n",
    "            if dimension == 'overall':\n",
    "                continue\n",
    "            \n",
    "            # Check for excessive transitions\n",
    "            if stats['transition_stats']['transition_rate'] > 0.2:\n",
    "                issues.append(\n",
    "                    f\"{dimension} has excessive transitions \"\n",
    "                    f\"({stats['transition_stats']['transition_rate']:.1%})\"\n",
    "                )\n",
    "            \n",
    "            # Check for stuck regimes\n",
    "            if stats['stability_metrics']['avg_persistence'] > 0.95:\n",
    "                issues.append(\n",
    "                    f\"{dimension} regimes are too sticky \"\n",
    "                    f\"(persistence: {stats['stability_metrics']['avg_persistence']:.1%})\"\n",
    "                )\n",
    "            \n",
    "            # Check for whipsaws\n",
    "            if stats['transition_stats']['avg_regime_duration'] < REGIME_SMOOTHING_PERIODS:\n",
    "                issues.append(\n",
    "                    f\"{dimension} has regime whipsaws \"\n",
    "                    f\"(avg duration: {stats['transition_stats']['avg_regime_duration']:.1f})\"\n",
    "                )\n",
    "        \n",
    "        return {\n",
    "            'issues': issues,\n",
    "            'recommendation': self._generate_transition_recommendations(issues)\n",
    "        }\n",
    "    \n",
    "    def _generate_transition_recommendations(self, issues: List[str]) -> List[str]:\n",
    "        \"\"\"Generate recommendations for transition issues\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if any('excessive transitions' in issue for issue in issues):\n",
    "            recommendations.append(\n",
    "                f\"Increase regime smoothing periods (current: {REGIME_SMOOTHING_PERIODS})\"\n",
    "            )\n",
    "        \n",
    "        if any('too sticky' in issue for issue in issues):\n",
    "            recommendations.append(\n",
    "                \"Review rolling window size - may be too large\"\n",
    "            )\n",
    "        \n",
    "        if any('whipsaws' in issue for issue in issues):\n",
    "            recommendations.append(\n",
    "                \"Consider increasing confirmation periods for regime changes\"\n",
    "            )\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# =============================================================================\n",
    "# TEMPORAL ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "class RegimeTemporalAnalyzer:\n",
    "    \"\"\"Analyze regime patterns over time\"\"\"\n",
    "    \n",
    "    def analyze_temporal_patterns(self, regimes: pd.DataFrame,\n",
    "                                data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze temporal patterns in regime classifications\n",
    "        \n",
    "        Args:\n",
    "            regimes: DataFrame with regime classifications\n",
    "            data: Original data with timestamps\n",
    "            \n",
    "        Returns:\n",
    "            Temporal analysis results\n",
    "        \"\"\"\n",
    "        logger.info(\"Analyzing temporal regime patterns\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Add time-based features\n",
    "        if regimes.index.dtype == 'datetime64[ns]':\n",
    "            regimes['hour'] = regimes.index.hour\n",
    "            regimes['day_of_week'] = regimes.index.dayofweek\n",
    "            regimes['month'] = regimes.index.month\n",
    "        \n",
    "        # Analyze patterns by time of day\n",
    "        if 'hour' in regimes.columns:\n",
    "            results['hourly_patterns'] = self._analyze_hourly_patterns(regimes)\n",
    "        \n",
    "        # Analyze patterns by day of week\n",
    "        if 'day_of_week' in regimes.columns:\n",
    "            results['weekly_patterns'] = self._analyze_weekly_patterns(regimes)\n",
    "        \n",
    "        # Analyze regime duration patterns\n",
    "        results['duration_patterns'] = self._analyze_duration_patterns(regimes)\n",
    "        \n",
    "        # Check for regime clustering\n",
    "        results['clustering'] = self._analyze_regime_clustering(regimes)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _analyze_hourly_patterns(self, regimes: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze regime patterns by hour of day\"\"\"\n",
    "        hourly_stats = {}\n",
    "        \n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            regime_col = f'{dimension}_Regime'\n",
    "            if regime_col not in regimes.columns:\n",
    "                continue\n",
    "            \n",
    "            # Calculate regime distribution by hour\n",
    "            hourly_dist = pd.crosstab(regimes['hour'], regimes[regime_col], normalize='index')\n",
    "            \n",
    "            # Find hours with unusual patterns\n",
    "            unusual_hours = []\n",
    "            for hour in hourly_dist.index:\n",
    "                hour_dist = hourly_dist.loc[hour]\n",
    "                # Check if distribution differs significantly from overall\n",
    "                overall_dist = regimes[regime_col].value_counts(normalize=True)\n",
    "                \n",
    "                for regime in hour_dist.index:\n",
    "                    if regime in overall_dist.index:\n",
    "                        diff = abs(hour_dist[regime] - overall_dist[regime])\n",
    "                        if diff > 0.2:  # 20% difference threshold\n",
    "                            unusual_hours.append({\n",
    "                                'hour': hour,\n",
    "                                'regime': regime,\n",
    "                                'difference': diff\n",
    "                            })\n",
    "            \n",
    "            hourly_stats[dimension] = {\n",
    "                'distribution': hourly_dist.to_dict(),\n",
    "                'unusual_hours': unusual_hours[:5]  # Top 5\n",
    "            }\n",
    "        \n",
    "        return hourly_stats\n",
    "    \n",
    "    def _analyze_weekly_patterns(self, regimes: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze regime patterns by day of week\"\"\"\n",
    "        weekly_stats = {}\n",
    "        \n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            regime_col = f'{dimension}_Regime'\n",
    "            if regime_col not in regimes.columns:\n",
    "                continue\n",
    "            \n",
    "            # Calculate regime distribution by day\n",
    "            weekly_dist = pd.crosstab(regimes['day_of_week'], regimes[regime_col], normalize='index')\n",
    "            \n",
    "            weekly_stats[dimension] = {\n",
    "                'distribution': weekly_dist.to_dict(),\n",
    "                'weekend_effect': self._check_weekend_effect(regimes, regime_col)\n",
    "            }\n",
    "        \n",
    "        return weekly_stats\n",
    "    \n",
    "    def _check_weekend_effect(self, regimes: pd.DataFrame, regime_col: str) -> bool:\n",
    "        \"\"\"Check if there's a weekend effect in regimes\"\"\"\n",
    "        if 'day_of_week' not in regimes.columns:\n",
    "            return False\n",
    "        \n",
    "        # Weekend = Saturday (5) and Sunday (6)\n",
    "        weekend_mask = regimes['day_of_week'].isin([5, 6])\n",
    "        \n",
    "        if weekend_mask.sum() == 0:\n",
    "            return False\n",
    "        \n",
    "        # Compare weekend vs weekday distributions\n",
    "        weekend_dist = regimes[weekend_mask][regime_col].value_counts(normalize=True)\n",
    "        weekday_dist = regimes[~weekend_mask][regime_col].value_counts(normalize=True)\n",
    "        \n",
    "        # Check for significant differences\n",
    "        for regime in weekend_dist.index:\n",
    "            if regime in weekday_dist.index:\n",
    "                diff = abs(weekend_dist[regime] - weekday_dist[regime])\n",
    "                if diff > 0.15:  # 15% difference threshold\n",
    "                    return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _analyze_duration_patterns(self, regimes: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze patterns in regime durations\"\"\"\n",
    "        duration_stats = {}\n",
    "        \n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            regime_col = f'{dimension}_Regime'\n",
    "            if regime_col not in regimes.columns:\n",
    "                continue\n",
    "            \n",
    "            # Calculate durations for each regime type\n",
    "            regime_durations = {}\n",
    "            \n",
    "            for regime in regimes[regime_col].unique():\n",
    "                durations = []\n",
    "                in_regime = False\n",
    "                duration = 0\n",
    "                \n",
    "                for i in range(len(regimes)):\n",
    "                    if regimes[regime_col].iloc[i] == regime:\n",
    "                        if not in_regime:\n",
    "                            in_regime = True\n",
    "                            duration = 1\n",
    "                        else:\n",
    "                            duration += 1\n",
    "                    else:\n",
    "                        if in_regime:\n",
    "                            durations.append(duration)\n",
    "                            in_regime = False\n",
    "                            duration = 0\n",
    "                \n",
    "                if in_regime:\n",
    "                    durations.append(duration)\n",
    "                \n",
    "                if durations:\n",
    "                    regime_durations[regime] = {\n",
    "                        'mean': np.mean(durations),\n",
    "                        'std': np.std(durations),\n",
    "                        'min': np.min(durations),\n",
    "                        'max': np.max(durations)\n",
    "                    }\n",
    "            \n",
    "            duration_stats[dimension] = regime_durations\n",
    "        \n",
    "        return duration_stats\n",
    "    \n",
    "    def _analyze_regime_clustering(self, regimes: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Check for regime clustering (autocorrelation)\"\"\"\n",
    "        clustering_stats = {}\n",
    "        \n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            regime_col = f'{dimension}_Regime'\n",
    "            if regime_col not in regimes.columns:\n",
    "                continue\n",
    "            \n",
    "            # Convert to numeric for autocorrelation\n",
    "            regime_numeric = pd.Categorical(regimes[regime_col]).codes\n",
    "            \n",
    "            # Calculate autocorrelation at different lags\n",
    "            autocorr = {}\n",
    "            for lag in [1, 5, 10, 20]:\n",
    "                if len(regime_numeric) > lag:\n",
    "                    autocorr[f'lag_{lag}'] = regime_numeric.autocorr(lag=lag)\n",
    "            \n",
    "            clustering_stats[dimension] = {\n",
    "                'autocorrelation': autocorr,\n",
    "                'has_clustering': any(abs(v) > 0.5 for v in autocorr.values())\n",
    "            }\n",
    "        \n",
    "        return clustering_stats\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_regime_distributions(distribution_stats: Dict[str, Any],\n",
    "                            save_path: Optional[str] = None):\n",
    "    \"\"\"Plot regime distribution charts\"\"\"\n",
    "    n_dims = len([d for d in distribution_stats.keys() if d != 'overall'])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (dimension, stats) in enumerate(distribution_stats.items()):\n",
    "        if dimension == 'overall' or i >= len(axes):\n",
    "            continue\n",
    "        \n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Get distribution data\n",
    "        dist_pct = stats['distribution_pct']\n",
    "        \n",
    "        # Create bar plot\n",
    "        regimes = list(dist_pct.keys())\n",
    "        percentages = list(dist_pct.values())\n",
    "        \n",
    "        bars = ax.bar(regimes, percentages)\n",
    "        \n",
    "        # Color bars based on percentage\n",
    "        for j, (bar, pct) in enumerate(zip(bars, percentages)):\n",
    "            if pct > 80:\n",
    "                bar.set_color('red')\n",
    "            elif pct < 5:\n",
    "                bar.set_color('orange')\n",
    "            else:\n",
    "                bar.set_color('steelblue')\n",
    "        \n",
    "        ax.set_title(f'{dimension} Regime Distribution')\n",
    "        ax.set_ylabel('Percentage (%)')\n",
    "        ax.set_xlabel('Regime')\n",
    "        \n",
    "        # Rotate x labels if needed\n",
    "        if len(regimes) > 4:\n",
    "            ax.set_xticklabels(regimes, rotation=45, ha='right')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for bar, pct in zip(bars, percentages):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{pct:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        # Add balance score\n",
    "        balance_score = stats['balance_score']\n",
    "        ax.text(0.02, 0.98, f'Balance: {balance_score:.2f}',\n",
    "               transform=ax.transAxes, va='top', ha='left',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_dims, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Regime Distributions Across Dimensions', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=FIGURE_DPI, bbox_inches='tight')\n",
    "        logger.info(f\"Regime distribution plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "def plot_transition_matrices(transition_matrices: Dict[str, pd.DataFrame],\n",
    "                           save_path: Optional[str] = None):\n",
    "    \"\"\"Plot regime transition matrices\"\"\"\n",
    "    n_dims = len(transition_matrices)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (dimension, matrix) in enumerate(transition_matrices.items()):\n",
    "        if i >= len(axes):\n",
    "            continue\n",
    "        \n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(matrix, \n",
    "                   annot=True, \n",
    "                   fmt='.2f',\n",
    "                   cmap='YlOrRd',\n",
    "                   vmin=0,\n",
    "                   vmax=1,\n",
    "                   square=True,\n",
    "                   cbar_kws={'label': 'Transition Probability'},\n",
    "                   ax=ax)\n",
    "        \n",
    "        ax.set_title(f'{dimension} Regime Transitions')\n",
    "        ax.set_xlabel('To Regime')\n",
    "        ax.set_ylabel('From Regime')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_dims, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Regime Transition Probability Matrices', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=FIGURE_DPI, bbox_inches='tight')\n",
    "        logger.info(f\"Transition matrix plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN VALIDATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def validate_regime_distributions(regimes: pd.DataFrame,\n",
    "                                data: pd.DataFrame,\n",
    "                                save_report: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run complete regime distribution validation\n",
    "    \n",
    "    Args:\n",
    "        regimes: DataFrame with regime classifications\n",
    "        data: Original data with indicators\n",
    "        save_report: Whether to save validation report\n",
    "        \n",
    "    Returns:\n",
    "        Complete validation results\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting regime distribution validation\")\n",
    "    \n",
    "    # Initialize analyzers\n",
    "    dist_analyzer = RegimeDistributionAnalyzer()\n",
    "    trans_analyzer = RegimeTransitionAnalyzer()\n",
    "    temporal_analyzer = RegimeTemporalAnalyzer()\n",
    "    \n",
    "    # Run analyses\n",
    "    results = {\n",
    "        'distribution_analysis': dist_analyzer.analyze_distributions(regimes),\n",
    "        'transition_analysis': trans_analyzer.analyze_transitions(regimes),\n",
    "        'temporal_analysis': temporal_analyzer.analyze_temporal_patterns(regimes, data),\n",
    "        'validation_passed': True,\n",
    "        'issues': [],\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # Collect all issues\n",
    "    all_issues = []\n",
    "    \n",
    "    # Distribution issues\n",
    "    dist_issues = results['distribution_analysis']['overall'].get('issues', [])\n",
    "    all_issues.extend(dist_issues)\n",
    "    \n",
    "    # Transition issues\n",
    "    trans_issues = results['transition_analysis']['overall'].get('issues', [])\n",
    "    all_issues.extend(trans_issues)\n",
    "    \n",
    "    results['issues'] = all_issues\n",
    "    \n",
    "    # Determine if validation passed\n",
    "    if len(all_issues) > 5:\n",
    "        results['validation_passed'] = False\n",
    "    \n",
    "    # Generate recommendations\n",
    "    all_recommendations = []\n",
    "    \n",
    "    # From distribution analysis\n",
    "    dist_recs = results['distribution_analysis']['overall'].get('recommendation', [])\n",
    "    all_recommendations.extend(dist_recs)\n",
    "    \n",
    "    # From transition analysis\n",
    "    trans_recs = results['transition_analysis']['overall'].get('recommendation', [])\n",
    "    all_recommendations.extend(trans_recs)\n",
    "    \n",
    "    results['recommendations'] = list(set(all_recommendations))  # Remove duplicates\n",
    "    \n",
    "    # Save report if requested\n",
    "    if save_report:\n",
    "        save_regime_validation_report(\n",
    "            results, \n",
    "            dist_analyzer.distribution_stats,\n",
    "            trans_analyzer.transition_matrices\n",
    "        )\n",
    "    \n",
    "    logger.info(f\"Regime validation complete. Passed: {results['validation_passed']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_regime_validation_report(results: Dict[str, Any],\n",
    "                                distribution_stats: Dict[str, Any],\n",
    "                                transition_matrices: Dict[str, pd.DataFrame]):\n",
    "    \"\"\"Save regime validation report\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create validation directory\n",
    "    validation_dir = os.path.join(RESULTS_DIR, 'regime_validation')\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "    \n",
    "    # Save plots\n",
    "    plot_regime_distributions(\n",
    "        distribution_stats,\n",
    "        save_path=os.path.join(validation_dir, f'regime_distributions_{timestamp}.png')\n",
    "    )\n",
    "    \n",
    "    plot_transition_matrices(\n",
    "        transition_matrices,\n",
    "        save_path=os.path.join(validation_dir, f'transition_matrices_{timestamp}.png')\n",
    "    )\n",
    "    \n",
    "    # Save text report\n",
    "    report_path = os.path.join(validation_dir, f'regime_validation_report_{timestamp}.txt')\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"REGIME DISTRIBUTION VALIDATION REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Validation Status: {'PASSED' if results['validation_passed'] else 'FAILED'}\\n\")\n",
    "        f.write(f\"Total Issues Found: {len(results['issues'])}\\n\\n\")\n",
    "        \n",
    "        f.write(\"1. DISTRIBUTION ANALYSIS\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        \n",
    "        dist_overall = results['distribution_analysis']['overall']\n",
    "        f.write(f\"Health Score: {dist_overall['health_score']:.2f}/1.0\\n\")\n",
    "        \n",
    "        # Write distribution summaries\n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            if dimension in results['distribution_analysis']:\n",
    "                stats = results['distribution_analysis'][dimension]\n",
    "                f.write(f\"\\n{dimension} Distribution:\\n\")\n",
    "                for regime, pct in stats['distribution_pct'].items():\n",
    "                    f.write(f\"  {regime}: {pct:.1f}%\\n\")\n",
    "                f.write(f\"  Balance Score: {stats['balance_score']:.2f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n2. TRANSITION ANALYSIS\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        \n",
    "        # Write transition summaries\n",
    "        for dimension in REGIME_DIMENSIONS:\n",
    "            if dimension in results['transition_analysis']:\n",
    "                stats = results['transition_analysis'][dimension]\n",
    "                f.write(f\"\\n{dimension} Transitions:\\n\")\n",
    "                f.write(f\"  Total Transitions: {stats['transition_stats']['total_transitions']}\\n\")\n",
    "                f.write(f\"  Transition Rate: {stats['transition_stats']['transition_rate']:.1%}\\n\")\n",
    "                f.write(f\"  Avg Duration: {stats['transition_stats']['avg_regime_duration']:.1f} periods\\n\")\n",
    "                f.write(f\"  Persistence: {stats['persistence']:.1%}\\n\")\n",
    "        \n",
    "        f.write(\"\\n3. TEMPORAL PATTERNS\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        \n",
    "        temporal = results['temporal_analysis']\n",
    "        \n",
    "        # Check for clustering\n",
    "        if 'clustering' in temporal:\n",
    "            f.write(\"\\nRegime Clustering:\\n\")\n",
    "            for dimension, cluster_stats in temporal['clustering'].items():\n",
    "                if cluster_stats['has_clustering']:\n",
    "                    f.write(f\"  {dimension}: Shows significant clustering\\n\")\n",
    "        \n",
    "        f.write(\"\\n4. ISSUES FOUND\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        for i, issue in enumerate(results['issues'], 1):\n",
    "            f.write(f\"{i}. {issue}\\n\")\n",
    "        \n",
    "        f.write(\"\\n5. RECOMMENDATIONS\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        for i, rec in enumerate(results['recommendations'], 1):\n",
    "            f.write(f\"{i}. {rec}\\n\")\n",
    "    \n",
    "    logger.info(f\"Regime validation report saved to: {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
