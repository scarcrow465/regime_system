{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d3009b-7543-4821-8138-1d8153285c23",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Any\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m differential_evolution, minimize\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\optimize\\__init__.py:424\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 424\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root_scalar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minpack_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\optimize\\_root.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoizeJac, OptimizeResult, _check_unknown_options\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minpack_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _root_hybr, leastsq\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_spectral\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _root_df_sane\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _nonlin \u001b[38;5;28;01mas\u001b[39;00m nonlin\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\optimize\\_minpack_py.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfullargspec_no_self \u001b[38;5;28;01mas\u001b[39;00m _getfullargspec\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptimizeResult, _check_unknown_options, OptimizeWarning\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lsq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m least_squares\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# from ._lsq.common import make_strictly_feasible\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lsq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mleast_squares\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare_bounds\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\optimize\\_lsq\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This module contains least-squares algorithms.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mleast_squares\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m least_squares\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlsq_linear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lsq_linear\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleast_squares\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlsq_linear\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\optimize\\_lsq\\lsq_linear.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bounds\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m in_bounds, compute_grad\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrf_linear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trf_linear\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbvls\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bvls\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprepare_bounds\u001b[39m(bounds, n):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\optimize\\_lsq\\trf_linear.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lsmr\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptimizeResult\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgivens_elimination\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m givens_elimination\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     EPS, step_size_to_bound, find_active_constraints, in_bounds,\n\u001b[0;32m     12\u001b[0m     make_strictly_feasible, build_quadratic_1d, evaluate_quadratic,\n\u001b[0;32m     13\u001b[0m     minimize_quadratic_1d, CL_scaling_vector, reflective_transformation,\n\u001b[0;32m     14\u001b[0m     print_header_linear, print_iteration_linear, compute_grad,\n\u001b[0;32m     15\u001b[0m     regularized_lsq_operator, right_multiplied_operator)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregularized_lsq_with_qr\u001b[39m(m, n, R, QTb, perm, diag, copy_R\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:645\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MULTI-OBJECTIVE REGIME OPTIMIZATION FRAMEWORK\n",
    "# Optimize regime classification thresholds for: Sharpe + Drawdown + Persistence\n",
    "# Based on your original Week 1 plan for institutional-level optimization\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from scipy.optimize import differential_evolution, minimize\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class OptimizationResults:\n",
    "    \"\"\"Results from multi-objective optimization\"\"\"\n",
    "    best_params: Dict[str, float]\n",
    "    best_score: float\n",
    "    sharpe_ratio: float\n",
    "    max_drawdown: float\n",
    "    regime_persistence: float\n",
    "    strategy_returns: pd.Series\n",
    "    regime_classifications: pd.DataFrame\n",
    "    optimization_history: List[Dict]\n",
    "\n",
    "class RegimeStrategyBacktester:\n",
    "    \"\"\"\n",
    "    Simple strategy backtesting for regime validation\n",
    "    Tests basic strategies on each regime to measure performance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.strategies = {\n",
    "            # Direction-based strategies\n",
    "            'up_trending_momentum': self.momentum_strategy,\n",
    "            'down_trending_short': self.short_momentum_strategy,\n",
    "            'sideways_mean_reversion': self.mean_reversion_strategy,\n",
    "            \n",
    "            # Volatility-based strategies\n",
    "            'high_vol_breakout': self.volatility_breakout_strategy,\n",
    "            'low_vol_trend': self.trend_following_strategy,\n",
    "            \n",
    "            # Composite strategies\n",
    "            'regime_adaptive': self.adaptive_regime_strategy\n",
    "        }\n",
    "    \n",
    "    def momentum_strategy(self, data: pd.DataFrame, regime_mask: pd.Series) -> pd.Series:\n",
    "        \"\"\"Simple momentum strategy for trending regimes\"\"\"\n",
    "        try:\n",
    "            returns = data['close'].pct_change()\n",
    "            \n",
    "            # Simple momentum: buy when EMA12 > EMA26\n",
    "            signal = (data['EMA_12'] > data['EMA_26']).astype(int)\n",
    "            \n",
    "            # Apply only during specified regime\n",
    "            signal = signal * regime_mask\n",
    "            \n",
    "            # Calculate strategy returns\n",
    "            strategy_returns = signal.shift(1) * returns\n",
    "            return strategy_returns.fillna(0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Momentum strategy error: {e}\")\n",
    "            return pd.Series(0, index=data.index)\n",
    "    \n",
    "    def short_momentum_strategy(self, data: pd.DataFrame, regime_mask: pd.Series) -> pd.Series:\n",
    "        \"\"\"Short momentum for down trending periods\"\"\"\n",
    "        try:\n",
    "            returns = data['close'].pct_change()\n",
    "            \n",
    "            # Short when EMA12 < EMA26\n",
    "            signal = (data['EMA_12'] < data['EMA_26']).astype(int) * -1\n",
    "            \n",
    "            # Apply only during specified regime\n",
    "            signal = signal * regime_mask\n",
    "            \n",
    "            strategy_returns = signal.shift(1) * returns\n",
    "            return strategy_returns.fillna(0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Short momentum strategy error: {e}\")\n",
    "            return pd.Series(0, index=data.index)\n",
    "    \n",
    "    def mean_reversion_strategy(self, data: pd.DataFrame, regime_mask: pd.Series) -> pd.Series:\n",
    "        \"\"\"Mean reversion strategy for sideways markets\"\"\"\n",
    "        try:\n",
    "            returns = data['close'].pct_change()\n",
    "            \n",
    "            # Mean reversion using RSI\n",
    "            signal = np.where(data['RSI'] < 30, 1,  # Buy oversold\n",
    "                             np.where(data['RSI'] > 70, -1, 0))  # Sell overbought\n",
    "            \n",
    "            signal = pd.Series(signal, index=data.index) * regime_mask\n",
    "            \n",
    "            strategy_returns = signal.shift(1) * returns\n",
    "            return strategy_returns.fillna(0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Mean reversion strategy error: {e}\")\n",
    "            return pd.Series(0, index=data.index)\n",
    "    \n",
    "    def volatility_breakout_strategy(self, data: pd.DataFrame, regime_mask: pd.Series) -> pd.Series:\n",
    "        \"\"\"Volatility breakout for high volatility periods\"\"\"\n",
    "        try:\n",
    "            returns = data['close'].pct_change()\n",
    "            \n",
    "            # Buy breakouts during high volatility\n",
    "            price_change = data['close'].pct_change()\n",
    "            signal = np.where(abs(price_change) > data['ATR'] / data['close'] * 0.5, \n",
    "                            np.sign(price_change), 0)\n",
    "            \n",
    "            signal = pd.Series(signal, index=data.index) * regime_mask\n",
    "            \n",
    "            strategy_returns = signal.shift(1) * returns\n",
    "            return strategy_returns.fillna(0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Volatility breakout strategy error: {e}\")\n",
    "            return pd.Series(0, index=data.index)\n",
    "    \n",
    "    def trend_following_strategy(self, data: pd.DataFrame, regime_mask: pd.Series) -> pd.Series:\n",
    "        \"\"\"Trend following for low volatility periods\"\"\"\n",
    "        try:\n",
    "            returns = data['close'].pct_change()\n",
    "            \n",
    "            # Follow longer-term trend during low volatility\n",
    "            signal = np.where(data['SMA_20'] > data['SMA_50'], 1,\n",
    "                            np.where(data['SMA_20'] < data['SMA_50'], -1, 0))\n",
    "            \n",
    "            signal = pd.Series(signal, index=data.index) * regime_mask\n",
    "            \n",
    "            strategy_returns = signal.shift(1) * returns\n",
    "            return strategy_returns.fillna(0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Trend following strategy error: {e}\")\n",
    "            return pd.Series(0, index=data.index)\n",
    "    \n",
    "    def adaptive_regime_strategy(self, data: pd.DataFrame, regimes: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Adaptive strategy that switches based on regime combination\"\"\"\n",
    "        try:\n",
    "            total_returns = pd.Series(0, index=data.index)\n",
    "            \n",
    "            # Define regime-specific strategies\n",
    "            regime_strategies = {\n",
    "                'Up_Trending': ('momentum', 1.0),\n",
    "                'Down_Trending': ('short_momentum', 1.0),\n",
    "                'Sideways': ('mean_reversion', 0.5),\n",
    "                'High_Vol': ('volatility_breakout', 0.8),\n",
    "                'Low_Vol': ('trend_following', 1.0)\n",
    "            }\n",
    "            \n",
    "            # Apply strategies based on regimes\n",
    "            for regime_type, (strategy_name, weight) in regime_strategies.items():\n",
    "                if regime_type in ['Up_Trending', 'Down_Trending', 'Sideways']:\n",
    "                    mask = regimes['Direction_Regime'] == regime_type\n",
    "                elif regime_type in ['High_Vol', 'Low_Vol']:\n",
    "                    mask = regimes['Volatility_Regime'].str.contains(regime_type.replace('_', '_Vol'))\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                if strategy_name == 'momentum':\n",
    "                    strategy_returns = self.momentum_strategy(data, mask) * weight\n",
    "                elif strategy_name == 'short_momentum':\n",
    "                    strategy_returns = self.short_momentum_strategy(data, mask) * weight\n",
    "                elif strategy_name == 'mean_reversion':\n",
    "                    strategy_returns = self.mean_reversion_strategy(data, mask) * weight\n",
    "                elif strategy_name == 'volatility_breakout':\n",
    "                    strategy_returns = self.volatility_breakout_strategy(data, mask) * weight\n",
    "                elif strategy_name == 'trend_following':\n",
    "                    strategy_returns = self.trend_following_strategy(data, mask) * weight\n",
    "                \n",
    "                total_returns += strategy_returns\n",
    "            \n",
    "            return total_returns\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Adaptive regime strategy error: {e}\")\n",
    "            return pd.Series(0, index=data.index)\n",
    "\n",
    "class MultiObjectiveRegimeOptimizer:\n",
    "    \"\"\"\n",
    "    Multi-Objective Optimization Framework for Regime Classification\n",
    "    Optimizes thresholds for: Sharpe Ratio + Max Drawdown + Regime Persistence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, regime_classifier, data: pd.DataFrame):\n",
    "        self.classifier = regime_classifier\n",
    "        self.data = data\n",
    "        self.backtester = RegimeStrategyBacktester()\n",
    "        self.optimization_history = []\n",
    "        self.max_iterations = 100  # Default value\n",
    "        self.function_call_count = 0  # Add this counter\n",
    "        \n",
    "        # Define parameter bounds for optimization\n",
    "        self.param_bounds = {\n",
    "            # Direction thresholds\n",
    "            'direction_strong_slope': (0.01, 0.05),  # 1% to 5%\n",
    "            'direction_weak_slope': (0.002, 0.01),   # 0.2% to 1%\n",
    "            \n",
    "            # Trend strength thresholds\n",
    "            'trend_strong_alignment': (0.005, 0.02), # 0.5% to 2%\n",
    "            'trend_moderate_alignment': (0.002, 0.01), # 0.2% to 1%\n",
    "            \n",
    "            # Velocity thresholds\n",
    "            'velocity_acceleration': (0.01, 0.03),   # 1% to 3%\n",
    "            'velocity_stable_range': (0.002, 0.01),  # 0.2% to 1%\n",
    "            \n",
    "            # Volatility percentile thresholds\n",
    "            'volatility_high_percentile': (70, 90),  # 70th to 90th percentile\n",
    "            'volatility_low_percentile': (10, 40),   # 10th to 40th percentile\n",
    "            \n",
    "            # Microstructure thresholds\n",
    "            'microstructure_institutional': (1.2, 2.0), # Volume ratio thresholds\n",
    "            'microstructure_retail': (0.5, 0.9)\n",
    "        }\n",
    "        \n",
    "        # Optimization weights\n",
    "        self.objective_weights = {\n",
    "            'sharpe_ratio': 0.4,\n",
    "            'max_drawdown': 0.3,  # Want to minimize this\n",
    "            'regime_persistence': 0.3\n",
    "        }\n",
    "    \n",
    "    def update_classifier_thresholds(self, params: Dict[str, float]):\n",
    "        \"\"\"Update classifier thresholds with new parameters\"\"\"\n",
    "        try:\n",
    "            # Update direction thresholds\n",
    "            self.classifier.dimension_thresholds['direction']['strong_trend_slope'] = params['direction_strong_slope']\n",
    "            self.classifier.dimension_thresholds['direction']['weak_trend_slope'] = params['direction_weak_slope']\n",
    "            \n",
    "            # Update trend strength thresholds\n",
    "            self.classifier.dimension_thresholds['trend_strength']['strong_alignment'] = params['trend_strong_alignment']\n",
    "            self.classifier.dimension_thresholds['trend_strength']['moderate_alignment'] = params['trend_moderate_alignment']\n",
    "            \n",
    "            # Update velocity thresholds\n",
    "            self.classifier.dimension_thresholds['velocity']['acceleration_threshold'] = params['velocity_acceleration']\n",
    "            self.classifier.dimension_thresholds['velocity']['stable_range'] = params['velocity_stable_range']\n",
    "            \n",
    "            # Update volatility thresholds\n",
    "            self.classifier.dimension_thresholds['volatility']['high_vol_percentile'] = params['volatility_high_percentile']\n",
    "            self.classifier.dimension_thresholds['volatility']['low_vol_percentile'] = params['volatility_low_percentile']\n",
    "            \n",
    "            # Update microstructure thresholds\n",
    "            self.classifier.dimension_thresholds['microstructure']['institutional_volume_threshold'] = params['microstructure_institutional']\n",
    "            self.classifier.dimension_thresholds['microstructure']['retail_volume_threshold'] = params['microstructure_retail']\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating classifier thresholds: {e}\")\n",
    "    \n",
    "    def calculate_regime_persistence(self, regimes: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate regime persistence score - higher is better\"\"\"\n",
    "        try:\n",
    "            persistence_scores = []\n",
    "            \n",
    "            # Calculate persistence for each dimension\n",
    "            for dimension in ['Direction_Regime', 'TrendStrength_Regime', 'Velocity_Regime', \n",
    "                            'Volatility_Regime', 'Microstructure_Regime']:\n",
    "                if dimension in regimes.columns:\n",
    "                    # Count regime changes\n",
    "                    regime_changes = (regimes[dimension] != regimes[dimension].shift()).sum()\n",
    "                    total_periods = len(regimes)\n",
    "                    \n",
    "                    # Persistence = 1 - (changes / total_periods)\n",
    "                    persistence = 1 - (regime_changes / total_periods)\n",
    "                    persistence_scores.append(persistence)\n",
    "            \n",
    "            # Return average persistence across all dimensions\n",
    "            return np.mean(persistence_scores) if persistence_scores else 0.0\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error calculating regime persistence: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def calculate_performance_metrics(self, returns: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"Calculate strategy performance metrics\"\"\"\n",
    "        try:\n",
    "            if len(returns) == 0 or returns.sum() == 0:\n",
    "                return {'sharpe_ratio': 0.0, 'max_drawdown': -1.0, 'total_return': 0.0}\n",
    "            \n",
    "            # Remove NaN values\n",
    "            clean_returns = returns.dropna()\n",
    "            \n",
    "            if len(clean_returns) == 0:\n",
    "                return {'sharpe_ratio': 0.0, 'max_drawdown': -1.0, 'total_return': 0.0}\n",
    "            \n",
    "            # Calculate Sharpe ratio (annualized)\n",
    "            mean_return = clean_returns.mean()\n",
    "            std_return = clean_returns.std()\n",
    "            sharpe_ratio = (mean_return / std_return) * np.sqrt(252 * 24 * 4) if std_return > 0 else 0  # 15-min periods\n",
    "            \n",
    "            # Calculate maximum drawdown\n",
    "            cumulative_returns = (1 + clean_returns).cumprod()\n",
    "            rolling_max = cumulative_returns.expanding().max()\n",
    "            drawdown = (cumulative_returns - rolling_max) / rolling_max\n",
    "            max_drawdown = drawdown.min()\n",
    "            \n",
    "            # Total return\n",
    "            total_return = cumulative_returns.iloc[-1] - 1 if len(cumulative_returns) > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'total_return': total_return\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error calculating performance metrics: {e}\")\n",
    "            return {'sharpe_ratio': 0.0, 'max_drawdown': -1.0, 'total_return': 0.0}\n",
    "    \n",
    "    def objective_function(self, params_array: np.ndarray) -> float:\n",
    "        try:\n",
    "            # Increment and check function call count\n",
    "            self.function_call_count += 1\n",
    "            if self.function_call_count > self.max_iterations:\n",
    "                print(f\"STOPPING: Reached {self.max_iterations} function calls\")\n",
    "                return 1.0\n",
    "            \n",
    "            print(f\"Function call {self.function_call_count}/{self.max_iterations}\")\n",
    "            # Convert parameter array to dictionary\n",
    "            param_names = list(self.param_bounds.keys())\n",
    "            params = dict(zip(param_names, params_array))\n",
    "            \n",
    "            # Update classifier with new parameters\n",
    "            self.update_classifier_thresholds(params)\n",
    "            \n",
    "            # Re-classify regimes with new thresholds\n",
    "            regimes_df = self.classifier.classify_multidimensional_regime(self.data.copy())\n",
    "            \n",
    "            # Test adaptive regime strategy\n",
    "            strategy_returns = self.backtester.adaptive_regime_strategy(self.data, regimes_df)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            performance = self.calculate_performance_metrics(strategy_returns)\n",
    "            \n",
    "            # Calculate regime persistence\n",
    "            persistence = self.calculate_regime_persistence(regimes_df)\n",
    "            \n",
    "            # Multi-objective score (convert to minimization problem)\n",
    "            sharpe_component = -performance['sharpe_ratio']  # Negative because we want to maximize\n",
    "            drawdown_component = -performance['max_drawdown']  # Negative drawdown is good\n",
    "            persistence_component = -persistence  # Negative because we want to maximize\n",
    "            \n",
    "            # Weighted combination\n",
    "            total_score = (\n",
    "                self.objective_weights['sharpe_ratio'] * sharpe_component +\n",
    "                self.objective_weights['max_drawdown'] * drawdown_component +\n",
    "                self.objective_weights['regime_persistence'] * persistence_component\n",
    "            )\n",
    "            \n",
    "            # Store optimization history\n",
    "            self.optimization_history.append({\n",
    "                'params': params.copy(),\n",
    "                'sharpe_ratio': performance['sharpe_ratio'],\n",
    "                'max_drawdown': performance['max_drawdown'],\n",
    "                'regime_persistence': persistence,\n",
    "                'total_score': -total_score,  # Convert back to maximization for reporting\n",
    "                'total_return': performance['total_return']\n",
    "            })\n",
    "            \n",
    "            # Log progress periodically and check for early stopping\n",
    "            if len(self.optimization_history) % 5 == 0:  # Log every 5 iterations\n",
    "                print(f\"Iteration {len(self.optimization_history)}: Score={-total_score:.4f}, Sharpe={performance['sharpe_ratio']:.4f}\")\n",
    "                logger.info(f\"Optimization iteration {len(self.optimization_history)}: \"\n",
    "                          f\"Score={-total_score:.4f}, Sharpe={performance['sharpe_ratio']:.4f}, \"\n",
    "                          f\"DD={performance['max_drawdown']:.4f}, Persistence={persistence:.4f}\")\n",
    "            \n",
    "            # Early stopping if we exceed expected iterations\n",
    "            if len(self.optimization_history) > 200:  # Fixed limit instead of max_iterations * 2\n",
    "                print(f\"WARNING: Exceeded 200 iterations, stopping optimization...\")\n",
    "                return 10.0\n",
    "            \n",
    "            return total_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in objective function: {e}\")\n",
    "            return 1000.0  # Return high penalty for errors\n",
    "    \n",
    "    def optimize_regime_thresholds(self, method: str = 'differential_evolution', \n",
    "                                 max_iterations: int = 100) -> OptimizationResults:\n",
    "        \"\"\"Run multi-objective optimization to find best regime thresholds\"\"\"\n",
    "        \n",
    "        # Store max_iterations for use in objective function\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "        logger.info(\"Starting multi-objective regime threshold optimization...\")\n",
    "        logger.info(f\"Optimizing for: {list(self.objective_weights.keys())} with weights {list(self.objective_weights.values())}\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare bounds for scipy\n",
    "            bounds = list(self.param_bounds.values())\n",
    "            param_names = list(self.param_bounds.keys())\n",
    "            \n",
    "            # Initial guess (midpoint of bounds)\n",
    "            initial_guess = [(b[0] + b[1]) / 2 for b in bounds]\n",
    "            \n",
    "            logger.info(f\"Parameter bounds: {dict(zip(param_names, bounds))}\")\n",
    "            logger.info(f\"Starting optimization with {len(bounds)} parameters...\")\n",
    "            \n",
    "            # Run optimization with strict limits\n",
    "            if method == 'differential_evolution':\n",
    "                result = differential_evolution(\n",
    "                    self.objective_function,\n",
    "                    bounds,\n",
    "                    maxiter=max_iterations,\n",
    "                    popsize=5,  # Reduced from 10 to 5\n",
    "                    seed=42,\n",
    "                    disp=True,\n",
    "                    workers=1,  # Force single-threaded\n",
    "                    updating='immediate'  # Faster convergence\n",
    "                )\n",
    "            else:\n",
    "                # Alternative: L-BFGS-B\n",
    "                result = minimize(\n",
    "                    self.objective_function,\n",
    "                    initial_guess,\n",
    "                    method='L-BFGS-B',\n",
    "                    bounds=bounds,\n",
    "                    options={'maxiter': max_iterations}\n",
    "                )\n",
    "            \n",
    "            # Extract best parameters\n",
    "            best_params = dict(zip(param_names, result.x))\n",
    "            \n",
    "            # Update classifier with best parameters\n",
    "            self.update_classifier_thresholds(best_params)\n",
    "            \n",
    "            # Generate final results with best parameters\n",
    "            final_regimes = self.classifier.classify_multidimensional_regime(self.data.copy())\n",
    "            final_returns = self.backtester.adaptive_regime_strategy(self.data, final_regimes)\n",
    "            final_performance = self.calculate_performance_metrics(final_returns)\n",
    "            final_persistence = self.calculate_regime_persistence(final_regimes)\n",
    "            \n",
    "            logger.info(\"Optimization completed!\")\n",
    "            logger.info(f\"Best Score: {-result.fun:.4f}\")\n",
    "            logger.info(f\"Best Sharpe: {final_performance['sharpe_ratio']:.4f}\")\n",
    "            logger.info(f\"Best Max Drawdown: {final_performance['max_drawdown']:.4f}\")\n",
    "            logger.info(f\"Best Regime Persistence: {final_persistence:.4f}\")\n",
    "            \n",
    "            return OptimizationResults(\n",
    "                best_params=best_params,\n",
    "                best_score=-result.fun,\n",
    "                sharpe_ratio=final_performance['sharpe_ratio'],\n",
    "                max_drawdown=final_performance['max_drawdown'],\n",
    "                regime_persistence=final_persistence,\n",
    "                strategy_returns=final_returns,\n",
    "                regime_classifications=final_regimes,\n",
    "                optimization_history=self.optimization_history\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Optimization failed: {e}\")\n",
    "            # Return default results\n",
    "            return OptimizationResults(\n",
    "                best_params={},\n",
    "                best_score=0.0,\n",
    "                sharpe_ratio=0.0,\n",
    "                max_drawdown=-1.0,\n",
    "                regime_persistence=0.0,\n",
    "                strategy_returns=pd.Series(),\n",
    "                regime_classifications=pd.DataFrame(),\n",
    "                optimization_history=self.optimization_history\n",
    "            )\n",
    "\n",
    "def optimize_window_size(data: pd.DataFrame, classifier, timeframe: str = '15min', \n",
    "                        window_sizes_hours: List[float] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Optimize rolling window size for a specific timeframe\n",
    "    \"\"\"\n",
    "    import multidimensional_regime_system as mds\n",
    "    \n",
    "    # Convert hours to periods based on timeframe\n",
    "    timeframe_multipliers = {\n",
    "        '5min': 12,   # 12 periods per hour\n",
    "        '15min': 4,   # 4 periods per hour  \n",
    "        '1H': 1,      # 1 period per hour\n",
    "        'D': 1/24     # 1 period per 24 hours\n",
    "    }\n",
    "    \n",
    "    if window_sizes_hours is None:\n",
    "        if timeframe == '5min':\n",
    "            window_sizes_hours = [1, 2, 3, 4, 6, 8]\n",
    "        elif timeframe == '15min':\n",
    "            window_sizes_hours = [2, 4, 6, 8, 12, 16, 24, 36]\n",
    "        elif timeframe == '1H':\n",
    "            window_sizes_hours = [24, 36, 48, 72, 96]\n",
    "        else:  # Daily\n",
    "            window_sizes_hours = [240, 360, 480, 720, 960]\n",
    "    \n",
    "    results = {}\n",
    "    multiplier = timeframe_multipliers.get(timeframe, 4)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"WINDOW SIZE OPTIMIZATION FOR {timeframe}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Save original window configuration\n",
    "    original_window_hours = mds.ROLLING_WINDOW_HOURS if hasattr(mds, 'ROLLING_WINDOW_HOURS') else 8\n",
    "    \n",
    "    for window_hours in window_sizes_hours:\n",
    "        window_periods = int(window_hours * multiplier)\n",
    "        print(f\"\\nTesting {window_hours} hour window ({window_periods} periods)...\")\n",
    "        \n",
    "        try:\n",
    "            # Update the global configuration\n",
    "            mds.ROLLING_WINDOW_HOURS = window_hours\n",
    "            \n",
    "            # Create a new classifier with the new window size\n",
    "            new_classifier = mds.MultiDimensionalRegimeClassifier(window_hours=window_hours)\n",
    "            print(f\"  Created classifier with {window_hours} hour window\")\n",
    "            \n",
    "            # Run classification\n",
    "            data_with_regimes = new_classifier.classify_multidimensional_regime(\n",
    "                data.copy(), \n",
    "                symbol='NQ'\n",
    "            )\n",
    "            \n",
    "            # Run simple backtest\n",
    "            backtester = RegimeStrategyBacktester()\n",
    "            strategy_returns = backtester.adaptive_regime_strategy(data, data_with_regimes)\n",
    "            \n",
    "            # Calculate metrics directly\n",
    "            # Sharpe Ratio\n",
    "            returns_mean = strategy_returns.mean()\n",
    "            returns_std = strategy_returns.std()\n",
    "            sharpe = (returns_mean / returns_std * np.sqrt(252 * 96)) if returns_std > 0 else 0  # Annualized for 15min data\n",
    "            \n",
    "            # Max Drawdown\n",
    "            cumulative_returns = (1 + strategy_returns).cumprod()\n",
    "            running_max = cumulative_returns.expanding().max()\n",
    "            drawdown = (cumulative_returns - running_max) / running_max\n",
    "            max_dd = drawdown.min()\n",
    "            \n",
    "            # Total Return\n",
    "            total_return = (1 + strategy_returns).prod() - 1\n",
    "            \n",
    "            # Calculate regime stability\n",
    "            regime_changes = 0\n",
    "            for col in data_with_regimes.columns:\n",
    "                if '_Regime' in col:\n",
    "                    regime_changes += (data_with_regimes[col] != data_with_regimes[col].shift()).sum()\n",
    "            \n",
    "            avg_regime_changes = regime_changes / 5  # 5 dimensions\n",
    "            regime_persistence = 1 - (avg_regime_changes / len(data_with_regimes))\n",
    "            \n",
    "            results[window_hours] = {\n",
    "                'window_periods': window_periods,\n",
    "                'sharpe_ratio': sharpe,\n",
    "                'max_drawdown': max_dd,\n",
    "                'total_return': total_return,\n",
    "                'regime_persistence': regime_persistence,\n",
    "                'combined_score': sharpe * 0.4 - max_dd * 0.3 + regime_persistence * 0.3\n",
    "            }\n",
    "            \n",
    "            print(f\"  Sharpe: {sharpe:.3f}, MaxDD: {max_dd:.1%}, Persistence: {regime_persistence:.1%}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error with {window_hours}h window: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            results[window_hours] = {'combined_score': -999}\n",
    "    \n",
    "    # Restore original configuration\n",
    "    mds.ROLLING_WINDOW_HOURS = original_window_hours\n",
    "    \n",
    "    # Find best window\n",
    "    valid_results = {k: v for k, v in results.items() if v['combined_score'] != -999}\n",
    "    if valid_results:\n",
    "        best_window = max(valid_results.keys(), key=lambda x: valid_results[x]['combined_score'])\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"OPTIMAL WINDOW: {best_window} hours\")\n",
    "        print(f\"Performance: {valid_results[best_window]}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'optimal_window_hours': best_window,\n",
    "            'optimal_window_periods': valid_results[best_window]['window_periods'],\n",
    "            'all_results': results\n",
    "        }\n",
    "    else:\n",
    "        print(\"\\nERROR: No valid results obtained!\")\n",
    "        return {\n",
    "            'optimal_window_hours': original_window_hours,\n",
    "            'optimal_window_periods': int(original_window_hours * multiplier),\n",
    "            'all_results': results\n",
    "        }\n",
    "\n",
    "def apply_params_to_classifier(classifier, params: Dict[str, float]):\n",
    "    \"\"\"Apply optimized parameters to a classifier instance\"\"\"\n",
    "    try:\n",
    "        # Update direction thresholds\n",
    "        if 'direction_strong_slope' in params:\n",
    "            classifier.dimension_thresholds['direction']['strong_trend_slope'] = params['direction_strong_slope']\n",
    "        if 'direction_weak_slope' in params:\n",
    "            classifier.dimension_thresholds['direction']['weak_trend_slope'] = params['direction_weak_slope']\n",
    "        \n",
    "        # Update trend strength thresholds\n",
    "        if 'trend_strong_alignment' in params:\n",
    "            classifier.dimension_thresholds['trend_strength']['strong_alignment'] = params['trend_strong_alignment']\n",
    "        if 'trend_moderate_alignment' in params:\n",
    "            classifier.dimension_thresholds['trend_strength']['moderate_alignment'] = params['trend_moderate_alignment']\n",
    "        \n",
    "        # Update velocity thresholds\n",
    "        if 'velocity_acceleration' in params:\n",
    "            classifier.dimension_thresholds['velocity']['acceleration_threshold'] = params['velocity_acceleration']\n",
    "        if 'velocity_stable_range' in params:\n",
    "            classifier.dimension_thresholds['velocity']['stable_range'] = params['velocity_stable_range']\n",
    "        \n",
    "        # Update volatility thresholds\n",
    "        if 'volatility_high_percentile' in params:\n",
    "            classifier.dimension_thresholds['volatility']['percentile']['high'] = params['volatility_high_percentile']\n",
    "        if 'volatility_low_percentile' in params:\n",
    "            classifier.dimension_thresholds['volatility']['percentile']['low'] = params['volatility_low_percentile']\n",
    "        \n",
    "        # Update microstructure thresholds\n",
    "        if 'microstructure_institutional' in params:\n",
    "            classifier.dimension_thresholds['microstructure']['institutional_volume_threshold'] = params['microstructure_institutional']\n",
    "        if 'microstructure_retail' in params:\n",
    "            classifier.dimension_thresholds['microstructure']['retail_volume_threshold'] = params['microstructure_retail']\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error applying parameters to classifier: {e}\")\n",
    "    \n",
    "class WalkForwardOptimizer:\n",
    "    \"\"\"\n",
    "    Walk-Forward Analysis for regime optimization\n",
    "    Prevents overfitting by training on past data and testing on future data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame, train_periods: int = 252*2, test_periods: int = 252):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: Full dataset\n",
    "            train_periods: Number of periods for training (default 2 years for daily)\n",
    "            test_periods: Number of periods for testing (default 1 year for daily)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.train_periods = train_periods\n",
    "        self.test_periods = test_periods\n",
    "        self.results = []\n",
    "        \n",
    "    def run_walk_forward_optimization(self, classifier, optimization_method: str = 'differential_evolution',\n",
    "                                    max_iterations: int = 20) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run walk-forward optimization\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"WALK-FORWARD OPTIMIZATION\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Train periods: {self.train_periods}, Test periods: {self.test_periods}\")\n",
    "        print(f\"Total windows: {self._calculate_windows()}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        results = []\n",
    "        window_num = 1\n",
    "        \n",
    "        # Calculate total possible windows\n",
    "        total_periods = len(self.data)\n",
    "        step_size = self.test_periods  # Non-overlapping test windows\n",
    "        \n",
    "        start_idx = 0\n",
    "        while start_idx + self.train_periods + self.test_periods <= total_periods:\n",
    "            print(f\"\\n--- Window {window_num} ---\")\n",
    "            \n",
    "            # Split data\n",
    "            train_end = start_idx + self.train_periods\n",
    "            test_end = train_end + self.test_periods\n",
    "            \n",
    "            train_data = self.data.iloc[start_idx:train_end].copy()\n",
    "            test_data = self.data.iloc[train_end:test_end].copy()\n",
    "            \n",
    "            train_dates = f\"{train_data.index[0].strftime('%Y-%m-%d')} to {train_data.index[-1].strftime('%Y-%m-%d')}\"\n",
    "            test_dates = f\"{test_data.index[0].strftime('%Y-%m-%d')} to {test_data.index[-1].strftime('%Y-%m-%d')}\"\n",
    "            \n",
    "            print(f\"Training: {train_dates} ({len(train_data)} periods)\")\n",
    "            print(f\"Testing: {test_dates} ({len(test_data)} periods)\")\n",
    "            \n",
    "            try:\n",
    "                # Optimize on training data\n",
    "                optimizer = MultiObjectiveRegimeOptimizer(classifier, train_data)\n",
    "                opt_results = optimizer.optimize_regime_thresholds(\n",
    "                    method=optimization_method,\n",
    "                    max_iterations=max_iterations\n",
    "                )\n",
    "                \n",
    "                # Test on out-of-sample data\n",
    "                classifier_copy = self._copy_classifier(classifier)\n",
    "                self._apply_parameters(classifier_copy, opt_results.best_params)\n",
    "\n",
    "                from multidimensional_regime_system import calculate_all_indicators\n",
    "                \n",
    "                # Calculate test performance\n",
    "                test_data_with_indicators = calculate_all_indicators(test_data.copy())\n",
    "                test_data_with_regimes = classifier_copy.classify_multidimensional_regime(test_data_with_indicators, symbol='NQ')  # or pass the appropriate symbol\n",
    "                \n",
    "                backtester = RegimeStrategyBacktester()\n",
    "                test_returns = backtester.adaptive_regime_strategy(test_data_with_regimes, test_data_with_regimes)\n",
    "                \n",
    "                optimizer = MultiObjectiveRegimeOptimizer(classifier, test_data_with_indicators)\n",
    "                performance_metrics = optimizer.calculate_performance_metrics(test_returns)\n",
    "                test_sharpe = performance_metrics['sharpe_ratio']\n",
    "                test_max_dd = performance_metrics['max_drawdown']\n",
    "                test_return = performance_metrics['total_return']\n",
    "                \n",
    "                window_result = {\n",
    "                    'window': window_num,\n",
    "                    'train_start': train_data.index[0],\n",
    "                    'train_end': train_data.index[-1],\n",
    "                    'test_start': test_data.index[0],\n",
    "                    'test_end': test_data.index[-1],\n",
    "                    'train_sharpe': opt_results.sharpe_ratio,\n",
    "                    'train_max_dd': opt_results.max_drawdown,\n",
    "                    'test_sharpe': test_sharpe,\n",
    "                    'test_max_dd': test_max_dd,\n",
    "                    'test_return': test_return,\n",
    "                    'overfit_ratio': opt_results.sharpe_ratio / test_sharpe if test_sharpe != 0 else 999\n",
    "                }\n",
    "                \n",
    "                results.append(window_result)\n",
    "                \n",
    "                print(f\"Train Sharpe: {opt_results.sharpe_ratio:.3f}, Test Sharpe: {test_sharpe:.3f}\")\n",
    "                print(f\"Overfit Ratio: {window_result['overfit_ratio']:.2f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in window {window_num}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            \n",
    "            # Move to next window\n",
    "            start_idx += step_size\n",
    "            window_num += 1\n",
    "        \n",
    "        # Create summary\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"WALK-FORWARD SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if len(results_df) > 0:\n",
    "            print(f\"Successful windows: {len(results_df)}\")\n",
    "            print(f\"Average Train Sharpe: {results_df['train_sharpe'].mean():.3f}\")\n",
    "            print(f\"Average Test Sharpe: {results_df['test_sharpe'].mean():.3f}\")\n",
    "            print(f\"Average Overfit Ratio: {results_df['overfit_ratio'].mean():.2f}\")\n",
    "            print(f\"Consistency (std of test sharpe): {results_df['test_sharpe'].std():.3f}\")\n",
    "        else:\n",
    "            print(\"No successful windows completed!\")\n",
    "            print(\"Check error messages above for issues.\")\n",
    "            \n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def _calculate_windows(self) -> int:\n",
    "        \"\"\"Calculate number of walk-forward windows\"\"\"\n",
    "        total_periods = len(self.data)\n",
    "        return (total_periods - self.train_periods) // self.test_periods\n",
    "    \n",
    "    def _copy_classifier(self, classifier):\n",
    "        \"\"\"Create a copy of the classifier\"\"\"\n",
    "        import copy\n",
    "        return copy.deepcopy(classifier)\n",
    "    \n",
    "    def _apply_parameters(self, classifier, params):\n",
    "        \"\"\"Apply optimized parameters to classifier\"\"\"\n",
    "        apply_params_to_classifier(classifier, params)\n",
    "\n",
    "def run_regime_optimization(classifier, data: pd.DataFrame, \n",
    "                          max_iterations: int = 50, \n",
    "                          method: str = 'differential_evolution') -> OptimizationResults:\n",
    "    \"\"\"\n",
    "    Main function to run regime optimization\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MULTI-OBJECTIVE REGIME OPTIMIZATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Optimizing regime classification thresholds for:\")\n",
    "    print(\"  • Sharpe Ratio (40% weight)\")\n",
    "    print(\"  • Maximum Drawdown (30% weight)\") \n",
    "    print(\"  • Regime Persistence (30% weight)\")\n",
    "    print(f\"  • Method: {method}\")\n",
    "    print(f\"  • Max Iterations: {max_iterations}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    optimizer = MultiObjectiveRegimeOptimizer(classifier, data)\n",
    "    results = optimizer.optimize_regime_thresholds(method=method, max_iterations=max_iterations)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_optimization_results(results: OptimizationResults):\n",
    "    \"\"\"Print comprehensive optimization results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OPTIMIZATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"📊 PERFORMANCE METRICS:\")\n",
    "    print(f\"   Final Score: {results.best_score:.4f}\")\n",
    "    print(f\"   Sharpe Ratio: {results.sharpe_ratio:.4f}\")\n",
    "    print(f\"   Max Drawdown: {results.max_drawdown:.2%}\")\n",
    "    print(f\"   Regime Persistence: {results.regime_persistence:.2%}\")\n",
    "    \n",
    "    if len(results.strategy_returns) > 0:\n",
    "        total_return = (1 + results.strategy_returns).prod() - 1\n",
    "        print(f\"   Total Return: {total_return:.2%}\")\n",
    "    \n",
    "    print(f\"\\n🎛️  OPTIMIZED PARAMETERS:\")\n",
    "    for param, value in results.best_params.items():\n",
    "        print(f\"   {param}: {value:.6f}\")\n",
    "    \n",
    "    print(f\"\\n📈 OPTIMIZATION HISTORY:\")\n",
    "    if results.optimization_history:\n",
    "        history_df = pd.DataFrame(results.optimization_history)\n",
    "        print(f\"   Total Iterations: {len(history_df)}\")\n",
    "        print(f\"   Best Score Achieved: {history_df['total_score'].max():.4f}\")\n",
    "        print(f\"   Score Improvement: {history_df['total_score'].max() - history_df['total_score'].iloc[0]:.4f}\")\n",
    "    \n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f191017-9435-4d31-9681-47dcf9828bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
